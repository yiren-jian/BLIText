(lavis) yiren@mms-large-2:~/LAVIS$ rm -rf lavis/output/BLIP-T/Pretrain_stage2/
(lavis) yiren@mms-large-2:~/LAVIS$ bash run_scripts/blip-T/train/pretrain_stage2.sh

WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
| distributed init (rank 3, world 8): env://
| distributed init (rank 0, world 8): env://
| distributed init (rank 7, world 8): env://
| distributed init (rank 2, world 8): env://
| distributed init (rank 6, world 8): env://
| distributed init (rank 1, world 8): env://
| distributed init (rank 4, world 8): env://
| distributed init (rank 5, world 8): env://
2023-04-20 22:11:23,984 [INFO]
=====  Running Parameters    =====
2023-04-20 22:11:23,985 [INFO] {
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 128,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 0.0001,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 10,
    "min_lr": 1e-05,
    "num_workers": 4,
    "output_dir": "output/BLIP-T/Pretrain_stage2",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "image_text_pretrain",
    "train_splits": [
        "train"
    ],
    "warmup_lr": 1e-06,
    "warmup_steps": 2000,
    "weight_decay": 0.05,
    "world_size": 8
}
2023-04-20 22:11:23,985 [INFO]
======  Dataset Attributes  ======
2023-04-20 22:11:23,985 [INFO]
======== coco_caption =======
2023-04-20 22:11:23,985 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2023-04-20 22:11:23,985 [INFO]
======== vg_caption =======
2023-04-20 22:11:23,986 [INFO] {
    "build_info": {
        "annotations": {
            "train": {
                "storage": "vg/annotations/vg_caption.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/visual_genome/vg_caption.json"
            }
        },
        "images": {
            "storage": "vg/images/"
        }
    },
    "data_type": "images",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2023-04-20 22:11:23,986 [INFO]
======== conceptual_caption_3m =======
2023-04-20 22:11:23,986 [INFO] {
    "build_info": {
        "annotations": {
            "train": {
                "storage": [
                    "conceptual_caption/annotations/cc3m.json"
                ],
                "url": [
                    "/export/home/workspace/datasets/cc3m.json"
                ]
            }
        },
        "images": {
            "storage": "conceptual_caption/images"
        }
    },
    "data_type": "images",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2023-04-20 22:11:23,986 [INFO]
======== sbu_caption =======
2023-04-20 22:11:23,987 [INFO] {
    "build_info": {
        "annotations": {
            "train": {
                "storage": [
                    "sbu_captions/annotations/sbu.json"
                ],
                "url": [
                    "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/sbu/sbu.json"
                ]
            }
        },
        "images": {
            "storage": "sbu_captions/images"
        }
    },
    "data_type": "images",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2023-04-20 22:11:23,987 [INFO]
======  Model Attributes  ======
2023-04-20 22:11:23,987 [INFO] {
    "arch": "blip2_darkformer_opt",
    "drop_path_rate": 0,
    "finetuned": "",
    "freeze_vit": true,
    "image_size": 224,
    "load_finetuned": false,
    "load_pretrained": true,
    "model_type": "pretrain_darkformer_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "/home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage1/20230418231/checkpoint_9.pth",
    "prompt": "",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
Using downloaded and verified file: /home/yiren/lavis_datasets/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /home/yiren/lavis_datasets/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /home/yiren/lavis_datasets/coco/annotations/coco_karpathy_test.json
2023-04-20 22:11:23,990 [INFO] Building datasets...
Using downloaded and verified file: /home/yiren/lavis_datasets/vg/annotations/vg_caption.json
2023-04-20 22:11:24,659 [INFO] Building datasets...
Using downloaded and verified file: /home/yiren/lavis_datasets/conceptual_caption/annotations/cc3m.json
2023-04-20 22:11:25,295 [INFO] Building datasets...
Using downloaded and verified file: /home/yiren/lavis_datasets/sbu_captions/annotations/sbu.json
2023-04-20 22:11:27,481 [INFO] Building datasets...
2023-04-20 22:11:44,569 [INFO] freeze vision encoder
2023-04-20 22:12:32,545 [INFO] Missing keys ['visual_encoder.cls_token', 'visual_encoder.pos_embed', 'visual_encoder.patch_embed.proj.weight', 'visual_encoder.patch_embed.proj.bias', 'visual_encoder.blocks.0.norm1.weight', 'visual_encoder.blocks.0.norm1.bias', 'visual_encoder.blocks.0.attn.q_bias', 'visual_encoder.blocks.0.attn.v_bias', 'visual_encoder.blocks.0.attn.qkv.weight', 'visual_encoder.blocks.0.attn.proj.weight', 'visual_encoder.blocks.0.attn.proj.bias', 'visual_encoder.blocks.0.norm2.weight', 'visual_encoder.blocks.0.norm2.bias', 'visual_encoder.blocks.0.mlp.fc1.weight', 'visual_encoder.blocks.0.mlp.fc1.bias', 'visual_encoder.blocks.0.mlp.fc2.weight', 'visual_encoder.blocks.0.mlp.fc2.bias', 'visual_encoder.blocks.1.norm1.weight', 'visual_encoder.blocks.1.norm1.bias', 'visual_encoder.blocks.1.attn.q_bias', 'visual_encoder.blocks.1.attn.v_bias', 'visual_encoder.blocks.1.attn.qkv.weight', 'visual_encoder.blocks.1.attn.proj.weight', 'visual_encoder.blocks.1.attn.proj.bias', 'visual_encoder.blocks.1.norm2.weight', 'visual_encoder.blocks.1.norm2.bias', 'visual_encoder.blocks.1.mlp.fc1.weight', 'visual_encoder.blocks.1.mlp.fc1.bias', 'visual_encoder.blocks.1.mlp.fc2.weight', 'visual_encoder.blocks.1.mlp.fc2.bias', 'visual_encoder.blocks.2.norm1.weight', 'visual_encoder.blocks.2.norm1.bias', 'visual_encoder.blocks.2.attn.q_bias', 'visual_encoder.blocks.2.attn.v_bias', 'visual_encoder.blocks.2.attn.qkv.weight', 'visual_encoder.blocks.2.attn.proj.weight', 'visual_encoder.blocks.2.attn.proj.bias', 'visual_encoder.blocks.2.norm2.weight', 'visual_encoder.blocks.2.norm2.bias', 'visual_encoder.blocks.2.mlp.fc1.weight', 'visual_encoder.blocks.2.mlp.fc1.bias', 'visual_encoder.blocks.2.mlp.fc2.weight', 'visual_encoder.blocks.2.mlp.fc2.bias', 'visual_encoder.blocks.3.norm1.weight', 'visual_encoder.blocks.3.norm1.bias', 'visual_encoder.blocks.3.attn.q_bias', 'visual_encoder.blocks.3.attn.v_bias', 'visual_encoder.blocks.3.attn.qkv.weight', 'visual_encoder.blocks.3.attn.proj.weight', 'visual_encoder.blocks.3.attn.proj.bias', 'visual_encoder.blocks.3.norm2.weight', 'visual_encoder.blocks.3.norm2.bias', 'visual_encoder.blocks.3.mlp.fc1.weight', 'visual_encoder.blocks.3.mlp.fc1.bias', 'visual_encoder.blocks.3.mlp.fc2.weight', 'visual_encoder.blocks.3.mlp.fc2.bias', 'visual_encoder.blocks.4.norm1.weight', 'visual_encoder.blocks.4.norm1.bias', 'visual_encoder.blocks.4.attn.q_bias', 'visual_encoder.blocks.4.attn.v_bias', 'visual_encoder.blocks.4.attn.qkv.weight', 'visual_encoder.blocks.4.attn.proj.weight', 'visual_encoder.blocks.4.attn.proj.bias', 'visual_encoder.blocks.4.norm2.weight', 'visual_encoder.blocks.4.norm2.bias', 'visual_encoder.blocks.4.mlp.fc1.weight', 'visual_encoder.blocks.4.mlp.fc1.bias', 'visual_encoder.blocks.4.mlp.fc2.weight', 'visual_encoder.blocks.4.mlp.fc2.bias', 'visual_encoder.blocks.5.norm1.weight', 'visual_encoder.blocks.5.norm1.bias', 'visual_encoder.blocks.5.attn.q_bias', 'visual_encoder.blocks.5.attn.v_bias', 'visual_encoder.blocks.5.attn.qkv.weight', 'visual_encoder.blocks.5.attn.proj.weight', 'visual_encoder.blocks.5.attn.proj.bias', 'visual_encoder.blocks.5.norm2.weight', 'visual_encoder.blocks.5.norm2.bias', 'visual_encoder.blocks.5.mlp.fc1.weight', 'visual_encoder.blocks.5.mlp.fc1.bias', 'visual_encoder.blocks.5.mlp.fc2.weight', 'visual_encoder.blocks.5.mlp.fc2.bias', 'visual_encoder.blocks.6.norm1.weight', 'visual_encoder.blocks.6.norm1.bias', 'visual_encoder.blocks.6.attn.q_bias', 'visual_encoder.blocks.6.attn.v_bias', 'visual_encoder.blocks.6.attn.qkv.weight', 'visual_encoder.blocks.6.attn.proj.weight', 'visual_encoder.blocks.6.attn.proj.bias', 'visual_encoder.blocks.6.norm2.weight', 'visual_encoder.blocks.6.norm2.bias', 'visual_encoder.blocks.6.mlp.fc1.weight', 'visual_encoder.blocks.6.mlp.fc1.bias', 'visual_encoder.blocks.6.mlp.fc2.weight', 'visual_encoder.blocks.6.mlp.fc2.bias', 'visual_encoder.blocks.7.norm1.weight', 'visual_encoder.blocks.7.norm1.bias', 'visual_encoder.blocks.7.attn.q_bias', 'visual_encoder.blocks.7.attn.v_bias', 'visual_encoder.blocks.7.attn.qkv.weight', 'visual_encoder.blocks.7.attn.proj.weight', 'visual_encoder.blocks.7.attn.proj.bias', 'visual_encoder.blocks.7.norm2.weight', 'visual_encoder.blocks.7.norm2.bias', 'visual_encoder.blocks.7.mlp.fc1.weight', 'visual_encoder.blocks.7.mlp.fc1.bias', 'visual_encoder.blocks.7.mlp.fc2.weight', 'visual_encoder.blocks.7.mlp.fc2.bias', 'visual_encoder.blocks.8.norm1.weight', 'visual_encoder.blocks.8.norm1.bias', 'visual_encoder.blocks.8.attn.q_bias', 'visual_encoder.blocks.8.attn.v_bias', 'visual_encoder.blocks.8.attn.qkv.weight', 'visual_encoder.blocks.8.attn.proj.weight', 'visual_encoder.blocks.8.attn.proj.bias', 'visual_encoder.blocks.8.norm2.weight', 'visual_encoder.blocks.8.norm2.bias', 'visual_encoder.blocks.8.mlp.fc1.weight', 'visual_encoder.blocks.8.mlp.fc1.bias', 'visual_encoder.blocks.8.mlp.fc2.weight', 'visual_encoder.blocks.8.mlp.fc2.bias', 'visual_encoder.blocks.9.norm1.weight', 'visual_encoder.blocks.9.norm1.bias', 'visual_encoder.blocks.9.attn.q_bias', 'visual_encoder.blocks.9.attn.v_bias', 'visual_encoder.blocks.9.attn.qkv.weight', 'visual_encoder.blocks.9.attn.proj.weight', 'visual_encoder.blocks.9.attn.proj.bias', 'visual_encoder.blocks.9.norm2.weight', 'visual_encoder.blocks.9.norm2.bias', 'visual_encoder.blocks.9.mlp.fc1.weight', 'visual_encoder.blocks.9.mlp.fc1.bias', 'visual_encoder.blocks.9.mlp.fc2.weight', 'visual_encoder.blocks.9.mlp.fc2.bias', 'visual_encoder.blocks.10.norm1.weight', 'visual_encoder.blocks.10.norm1.bias', 'visual_encoder.blocks.10.attn.q_bias', 'visual_encoder.blocks.10.attn.v_bias', 'visual_encoder.blocks.10.attn.qkv.weight', 'visual_encoder.blocks.10.attn.proj.weight', 'visual_encoder.blocks.10.attn.proj.bias', 'visual_encoder.blocks.10.norm2.weight', 'visual_encoder.blocks.10.norm2.bias', 'visual_encoder.blocks.10.mlp.fc1.weight', 'visual_encoder.blocks.10.mlp.fc1.bias', 'visual_encoder.blocks.10.mlp.fc2.weight', 'visual_encoder.blocks.10.mlp.fc2.bias', 'visual_encoder.blocks.11.norm1.weight', 'visual_encoder.blocks.11.norm1.bias', 'visual_encoder.blocks.11.attn.q_bias', 'visual_encoder.blocks.11.attn.v_bias', 'visual_encoder.blocks.11.attn.qkv.weight', 'visual_encoder.blocks.11.attn.proj.weight', 'visual_encoder.blocks.11.attn.proj.bias', 'visual_encoder.blocks.11.norm2.weight', 'visual_encoder.blocks.11.norm2.bias', 'visual_encoder.blocks.11.mlp.fc1.weight', 'visual_encoder.blocks.11.mlp.fc1.bias', 'visual_encoder.blocks.11.mlp.fc2.weight', 'visual_encoder.blocks.11.mlp.fc2.bias', 'visual_encoder.blocks.12.norm1.weight', 'visual_encoder.blocks.12.norm1.bias', 'visual_encoder.blocks.12.attn.q_bias', 'visual_encoder.blocks.12.attn.v_bias', 'visual_encoder.blocks.12.attn.qkv.weight', 'visual_encoder.blocks.12.attn.proj.weight', 'visual_encoder.blocks.12.attn.proj.bias', 'visual_encoder.blocks.12.norm2.weight', 'visual_encoder.blocks.12.norm2.bias', 'visual_encoder.blocks.12.mlp.fc1.weight', 'visual_encoder.blocks.12.mlp.fc1.bias', 'visual_encoder.blocks.12.mlp.fc2.weight', 'visual_encoder.blocks.12.mlp.fc2.bias', 'visual_encoder.blocks.13.norm1.weight', 'visual_encoder.blocks.13.norm1.bias', 'visual_encoder.blocks.13.attn.q_bias', 'visual_encoder.blocks.13.attn.v_bias', 'visual_encoder.blocks.13.attn.qkv.weight', 'visual_encoder.blocks.13.attn.proj.weight', 'visual_encoder.blocks.13.attn.proj.bias', 'visual_encoder.blocks.13.norm2.weight', 'visual_encoder.blocks.13.norm2.bias', 'visual_encoder.blocks.13.mlp.fc1.weight', 'visual_encoder.blocks.13.mlp.fc1.bias', 'visual_encoder.blocks.13.mlp.fc2.weight', 'visual_encoder.blocks.13.mlp.fc2.bias', 'visual_encoder.blocks.14.norm1.weight', 'visual_encoder.blocks.14.norm1.bias', 'visual_encoder.blocks.14.attn.q_bias', 'visual_encoder.blocks.14.attn.v_bias', 'visual_encoder.blocks.14.attn.qkv.weight', 'visual_encoder.blocks.14.attn.proj.weight', 'visual_encoder.blocks.14.attn.proj.bias', 'visual_encoder.blocks.14.norm2.weight', 'visual_encoder.blocks.14.norm2.bias', 'visual_encoder.blocks.14.mlp.fc1.weight', 'visual_encoder.blocks.14.mlp.fc1.bias', 'visual_encoder.blocks.14.mlp.fc2.weight', 'visual_encoder.blocks.14.mlp.fc2.bias', 'visual_encoder.blocks.15.norm1.weight', 'visual_encoder.blocks.15.norm1.bias', 'visual_encoder.blocks.15.attn.q_bias', 'visual_encoder.blocks.15.attn.v_bias', 'visual_encoder.blocks.15.attn.qkv.weight', 'visual_encoder.blocks.15.attn.proj.weight', 'visual_encoder.blocks.15.attn.proj.bias', 'visual_encoder.blocks.15.norm2.weight', 'visual_encoder.blocks.15.norm2.bias', 'visual_encoder.blocks.15.mlp.fc1.weight', 'visual_encoder.blocks.15.mlp.fc1.bias', 'visual_encoder.blocks.15.mlp.fc2.weight', 'visual_encoder.blocks.15.mlp.fc2.bias', 'visual_encoder.blocks.16.norm1.weight', 'visual_encoder.blocks.16.norm1.bias', 'visual_encoder.blocks.16.attn.q_bias', 'visual_encoder.blocks.16.attn.v_bias', 'visual_encoder.blocks.16.attn.qkv.weight', 'visual_encoder.blocks.16.attn.proj.weight', 'visual_encoder.blocks.16.attn.proj.bias', 'visual_encoder.blocks.16.norm2.weight', 'visual_encoder.blocks.16.norm2.bias', 'visual_encoder.blocks.16.mlp.fc1.weight', 'visual_encoder.blocks.16.mlp.fc1.bias', 'visual_encoder.blocks.16.mlp.fc2.weight', 'visual_encoder.blocks.16.mlp.fc2.bias', 'visual_encoder.blocks.17.norm1.weight', 'visual_encoder.blocks.17.norm1.bias', 'visual_encoder.blocks.17.attn.q_bias', 'visual_encoder.blocks.17.attn.v_bias', 'visual_encoder.blocks.17.attn.qkv.weight', 'visual_encoder.blocks.17.attn.proj.weight', 'visual_encoder.blocks.17.attn.proj.bias', 'visual_encoder.blocks.17.norm2.weight', 'visual_encoder.blocks.17.norm2.bias', 'visual_encoder.blocks.17.mlp.fc1.weight', 'visual_encoder.blocks.17.mlp.fc1.bias', 'visual_encoder.blocks.17.mlp.fc2.weight', 'visual_encoder.blocks.17.mlp.fc2.bias', 'visual_encoder.blocks.18.norm1.weight', 'visual_encoder.blocks.18.norm1.bias', 'visual_encoder.blocks.18.attn.q_bias', 'visual_encoder.blocks.18.attn.v_bias', 'visual_encoder.blocks.18.attn.qkv.weight', 'visual_encoder.blocks.18.attn.proj.weight', 'visual_encoder.blocks.18.attn.proj.bias', 'visual_encoder.blocks.18.norm2.weight', 'visual_encoder.blocks.18.norm2.bias', 'visual_encoder.blocks.18.mlp.fc1.weight', 'visual_encoder.blocks.18.mlp.fc1.bias', 'visual_encoder.blocks.18.mlp.fc2.weight', 'visual_encoder.blocks.18.mlp.fc2.bias', 'visual_encoder.blocks.19.norm1.weight', 'visual_encoder.blocks.19.norm1.bias', 'visual_encoder.blocks.19.attn.q_bias', 'visual_encoder.blocks.19.attn.v_bias', 'visual_encoder.blocks.19.attn.qkv.weight', 'visual_encoder.blocks.19.attn.proj.weight', 'visual_encoder.blocks.19.attn.proj.bias', 'visual_encoder.blocks.19.norm2.weight', 'visual_encoder.blocks.19.norm2.bias', 'visual_encoder.blocks.19.mlp.fc1.weight', 'visual_encoder.blocks.19.mlp.fc1.bias', 'visual_encoder.blocks.19.mlp.fc2.weight', 'visual_encoder.blocks.19.mlp.fc2.bias', 'visual_encoder.blocks.20.norm1.weight', 'visual_encoder.blocks.20.norm1.bias', 'visual_encoder.blocks.20.attn.q_bias', 'visual_encoder.blocks.20.attn.v_bias', 'visual_encoder.blocks.20.attn.qkv.weight', 'visual_encoder.blocks.20.attn.proj.weight', 'visual_encoder.blocks.20.attn.proj.bias', 'visual_encoder.blocks.20.norm2.weight', 'visual_encoder.blocks.20.norm2.bias', 'visual_encoder.blocks.20.mlp.fc1.weight', 'visual_encoder.blocks.20.mlp.fc1.bias', 'visual_encoder.blocks.20.mlp.fc2.weight', 'visual_encoder.blocks.20.mlp.fc2.bias', 'visual_encoder.blocks.21.norm1.weight', 'visual_encoder.blocks.21.norm1.bias', 'visual_encoder.blocks.21.attn.q_bias', 'visual_encoder.blocks.21.attn.v_bias', 'visual_encoder.blocks.21.attn.qkv.weight', 'visual_encoder.blocks.21.attn.proj.weight', 'visual_encoder.blocks.21.attn.proj.bias', 'visual_encoder.blocks.21.norm2.weight', 'visual_encoder.blocks.21.norm2.bias', 'visual_encoder.blocks.21.mlp.fc1.weight', 'visual_encoder.blocks.21.mlp.fc1.bias', 'visual_encoder.blocks.21.mlp.fc2.weight', 'visual_encoder.blocks.21.mlp.fc2.bias', 'visual_encoder.blocks.22.norm1.weight', 'visual_encoder.blocks.22.norm1.bias', 'visual_encoder.blocks.22.attn.q_bias', 'visual_encoder.blocks.22.attn.v_bias', 'visual_encoder.blocks.22.attn.qkv.weight', 'visual_encoder.blocks.22.attn.proj.weight', 'visual_encoder.blocks.22.attn.proj.bias', 'visual_encoder.blocks.22.norm2.weight', 'visual_encoder.blocks.22.norm2.bias', 'visual_encoder.blocks.22.mlp.fc1.weight', 'visual_encoder.blocks.22.mlp.fc1.bias', 'visual_encoder.blocks.22.mlp.fc2.weight', 'visual_encoder.blocks.22.mlp.fc2.bias', 'visual_encoder.blocks.23.norm1.weight', 'visual_encoder.blocks.23.norm1.bias', 'visual_encoder.blocks.23.attn.q_bias', 'visual_encoder.blocks.23.attn.v_bias', 'visual_encoder.blocks.23.attn.qkv.weight', 'visual_encoder.blocks.23.attn.proj.weight', 'visual_encoder.blocks.23.attn.proj.bias', 'visual_encoder.blocks.23.norm2.weight', 'visual_encoder.blocks.23.norm2.bias', 'visual_encoder.blocks.23.mlp.fc1.weight', 'visual_encoder.blocks.23.mlp.fc1.bias', 'visual_encoder.blocks.23.mlp.fc2.weight', 'visual_encoder.blocks.23.mlp.fc2.bias', 'visual_encoder.blocks.24.norm1.weight', 'visual_encoder.blocks.24.norm1.bias', 'visual_encoder.blocks.24.attn.q_bias', 'visual_encoder.blocks.24.attn.v_bias', 'visual_encoder.blocks.24.attn.qkv.weight', 'visual_encoder.blocks.24.attn.proj.weight', 'visual_encoder.blocks.24.attn.proj.bias', 'visual_encoder.blocks.24.norm2.weight', 'visual_encoder.blocks.24.norm2.bias', 'visual_encoder.blocks.24.mlp.fc1.weight', 'visual_encoder.blocks.24.mlp.fc1.bias', 'visual_encoder.blocks.24.mlp.fc2.weight', 'visual_encoder.blocks.24.mlp.fc2.bias', 'visual_encoder.blocks.25.norm1.weight', 'visual_encoder.blocks.25.norm1.bias', 'visual_encoder.blocks.25.attn.q_bias', 'visual_encoder.blocks.25.attn.v_bias', 'visual_encoder.blocks.25.attn.qkv.weight', 'visual_encoder.blocks.25.attn.proj.weight', 'visual_encoder.blocks.25.attn.proj.bias', 'visual_encoder.blocks.25.norm2.weight', 'visual_encoder.blocks.25.norm2.bias', 'visual_encoder.blocks.25.mlp.fc1.weight', 'visual_encoder.blocks.25.mlp.fc1.bias', 'visual_encoder.blocks.25.mlp.fc2.weight', 'visual_encoder.blocks.25.mlp.fc2.bias', 'visual_encoder.blocks.26.norm1.weight', 'visual_encoder.blocks.26.norm1.bias', 'visual_encoder.blocks.26.attn.q_bias', 'visual_encoder.blocks.26.attn.v_bias', 'visual_encoder.blocks.26.attn.qkv.weight', 'visual_encoder.blocks.26.attn.proj.weight', 'visual_encoder.blocks.26.attn.proj.bias', 'visual_encoder.blocks.26.norm2.weight', 'visual_encoder.blocks.26.norm2.bias', 'visual_encoder.blocks.26.mlp.fc1.weight', 'visual_encoder.blocks.26.mlp.fc1.bias', 'visual_encoder.blocks.26.mlp.fc2.weight', 'visual_encoder.blocks.26.mlp.fc2.bias', 'visual_encoder.blocks.27.norm1.weight', 'visual_encoder.blocks.27.norm1.bias', 'visual_encoder.blocks.27.attn.q_bias', 'visual_encoder.blocks.27.attn.v_bias', 'visual_encoder.blocks.27.attn.qkv.weight', 'visual_encoder.blocks.27.attn.proj.weight', 'visual_encoder.blocks.27.attn.proj.bias', 'visual_encoder.blocks.27.norm2.weight', 'visual_encoder.blocks.27.norm2.bias', 'visual_encoder.blocks.27.mlp.fc1.weight', 'visual_encoder.blocks.27.mlp.fc1.bias', 'visual_encoder.blocks.27.mlp.fc2.weight', 'visual_encoder.blocks.27.mlp.fc2.bias', 'visual_encoder.blocks.28.norm1.weight', 'visual_encoder.blocks.28.norm1.bias', 'visual_encoder.blocks.28.attn.q_bias', 'visual_encoder.blocks.28.attn.v_bias', 'visual_encoder.blocks.28.attn.qkv.weight', 'visual_encoder.blocks.28.attn.proj.weight', 'visual_encoder.blocks.28.attn.proj.bias', 'visual_encoder.blocks.28.norm2.weight', 'visual_encoder.blocks.28.norm2.bias', 'visual_encoder.blocks.28.mlp.fc1.weight', 'visual_encoder.blocks.28.mlp.fc1.bias', 'visual_encoder.blocks.28.mlp.fc2.weight', 'visual_encoder.blocks.28.mlp.fc2.bias', 'visual_encoder.blocks.29.norm1.weight', 'visual_encoder.blocks.29.norm1.bias', 'visual_encoder.blocks.29.attn.q_bias', 'visual_encoder.blocks.29.attn.v_bias', 'visual_encoder.blocks.29.attn.qkv.weight', 'visual_encoder.blocks.29.attn.proj.weight', 'visual_encoder.blocks.29.attn.proj.bias', 'visual_encoder.blocks.29.norm2.weight', 'visual_encoder.blocks.29.norm2.bias', 'visual_encoder.blocks.29.mlp.fc1.weight', 'visual_encoder.blocks.29.mlp.fc1.bias', 'visual_encoder.blocks.29.mlp.fc2.weight', 'visual_encoder.blocks.29.mlp.fc2.bias', 'visual_encoder.blocks.30.norm1.weight', 'visual_encoder.blocks.30.norm1.bias', 'visual_encoder.blocks.30.attn.q_bias', 'visual_encoder.blocks.30.attn.v_bias', 'visual_encoder.blocks.30.attn.qkv.weight', 'visual_encoder.blocks.30.attn.proj.weight', 'visual_encoder.blocks.30.attn.proj.bias', 'visual_encoder.blocks.30.norm2.weight', 'visual_encoder.blocks.30.norm2.bias', 'visual_encoder.blocks.30.mlp.fc1.weight', 'visual_encoder.blocks.30.mlp.fc1.bias', 'visual_encoder.blocks.30.mlp.fc2.weight', 'visual_encoder.blocks.30.mlp.fc2.bias', 'visual_encoder.blocks.31.norm1.weight', 'visual_encoder.blocks.31.norm1.bias', 'visual_encoder.blocks.31.attn.q_bias', 'visual_encoder.blocks.31.attn.v_bias', 'visual_encoder.blocks.31.attn.qkv.weight', 'visual_encoder.blocks.31.attn.proj.weight', 'visual_encoder.blocks.31.attn.proj.bias', 'visual_encoder.blocks.31.norm2.weight', 'visual_encoder.blocks.31.norm2.bias', 'visual_encoder.blocks.31.mlp.fc1.weight', 'visual_encoder.blocks.31.mlp.fc1.bias', 'visual_encoder.blocks.31.mlp.fc2.weight', 'visual_encoder.blocks.31.mlp.fc2.bias', 'visual_encoder.blocks.32.norm1.weight', 'visual_encoder.blocks.32.norm1.bias', 'visual_encoder.blocks.32.attn.q_bias', 'visual_encoder.blocks.32.attn.v_bias', 'visual_encoder.blocks.32.attn.qkv.weight', 'visual_encoder.blocks.32.attn.proj.weight', 'visual_encoder.blocks.32.attn.proj.bias', 'visual_encoder.blocks.32.norm2.weight', 'visual_encoder.blocks.32.norm2.bias', 'visual_encoder.blocks.32.mlp.fc1.weight', 'visual_encoder.blocks.32.mlp.fc1.bias', 'visual_encoder.blocks.32.mlp.fc2.weight', 'visual_encoder.blocks.32.mlp.fc2.bias', 'visual_encoder.blocks.33.norm1.weight', 'visual_encoder.blocks.33.norm1.bias', 'visual_encoder.blocks.33.attn.q_bias', 'visual_encoder.blocks.33.attn.v_bias', 'visual_encoder.blocks.33.attn.qkv.weight', 'visual_encoder.blocks.33.attn.proj.weight', 'visual_encoder.blocks.33.attn.proj.bias', 'visual_encoder.blocks.33.norm2.weight', 'visual_encoder.blocks.33.norm2.bias', 'visual_encoder.blocks.33.mlp.fc1.weight', 'visual_encoder.blocks.33.mlp.fc1.bias', 'visual_encoder.blocks.33.mlp.fc2.weight', 'visual_encoder.blocks.33.mlp.fc2.bias', 'visual_encoder.blocks.34.norm1.weight', 'visual_encoder.blocks.34.norm1.bias', 'visual_encoder.blocks.34.attn.q_bias', 'visual_encoder.blocks.34.attn.v_bias', 'visual_encoder.blocks.34.attn.qkv.weight', 'visual_encoder.blocks.34.attn.proj.weight', 'visual_encoder.blocks.34.attn.proj.bias', 'visual_encoder.blocks.34.norm2.weight', 'visual_encoder.blocks.34.norm2.bias', 'visual_encoder.blocks.34.mlp.fc1.weight', 'visual_encoder.blocks.34.mlp.fc1.bias', 'visual_encoder.blocks.34.mlp.fc2.weight', 'visual_encoder.blocks.34.mlp.fc2.bias', 'visual_encoder.blocks.35.norm1.weight', 'visual_encoder.blocks.35.norm1.bias', 'visual_encoder.blocks.35.attn.q_bias', 'visual_encoder.blocks.35.attn.v_bias', 'visual_encoder.blocks.35.attn.qkv.weight', 'visual_encoder.blocks.35.attn.proj.weight', 'visual_encoder.blocks.35.attn.proj.bias', 'visual_encoder.blocks.35.norm2.weight', 'visual_encoder.blocks.35.norm2.bias', 'visual_encoder.blocks.35.mlp.fc1.weight', 'visual_encoder.blocks.35.mlp.fc1.bias', 'visual_encoder.blocks.35.mlp.fc2.weight', 'visual_encoder.blocks.35.mlp.fc2.bias', 'visual_encoder.blocks.36.norm1.weight', 'visual_encoder.blocks.36.norm1.bias', 'visual_encoder.blocks.36.attn.q_bias', 'visual_encoder.blocks.36.attn.v_bias', 'visual_encoder.blocks.36.attn.qkv.weight', 'visual_encoder.blocks.36.attn.proj.weight', 'visual_encoder.blocks.36.attn.proj.bias', 'visual_encoder.blocks.36.norm2.weight', 'visual_encoder.blocks.36.norm2.bias', 'visual_encoder.blocks.36.mlp.fc1.weight', 'visual_encoder.blocks.36.mlp.fc1.bias', 'visual_encoder.blocks.36.mlp.fc2.weight', 'visual_encoder.blocks.36.mlp.fc2.bias', 'visual_encoder.blocks.37.norm1.weight', 'visual_encoder.blocks.37.norm1.bias', 'visual_encoder.blocks.37.attn.q_bias', 'visual_encoder.blocks.37.attn.v_bias', 'visual_encoder.blocks.37.attn.qkv.weight', 'visual_encoder.blocks.37.attn.proj.weight', 'visual_encoder.blocks.37.attn.proj.bias', 'visual_encoder.blocks.37.norm2.weight', 'visual_encoder.blocks.37.norm2.bias', 'visual_encoder.blocks.37.mlp.fc1.weight', 'visual_encoder.blocks.37.mlp.fc1.bias', 'visual_encoder.blocks.37.mlp.fc2.weight', 'visual_encoder.blocks.37.mlp.fc2.bias', 'visual_encoder.blocks.38.norm1.weight', 'visual_encoder.blocks.38.norm1.bias', 'visual_encoder.blocks.38.attn.q_bias', 'visual_encoder.blocks.38.attn.v_bias', 'visual_encoder.blocks.38.attn.qkv.weight', 'visual_encoder.blocks.38.attn.proj.weight', 'visual_encoder.blocks.38.attn.proj.bias', 'visual_encoder.blocks.38.norm2.weight', 'visual_encoder.blocks.38.norm2.bias', 'visual_encoder.blocks.38.mlp.fc1.weight', 'visual_encoder.blocks.38.mlp.fc1.bias', 'visual_encoder.blocks.38.mlp.fc2.weight', 'visual_encoder.blocks.38.mlp.fc2.bias', 'opt_model.model.decoder.embed_tokens.weight', 'opt_model.model.decoder.embed_positions.weight', 'opt_model.model.decoder.final_layer_norm.weight', 'opt_model.model.decoder.final_layer_norm.bias', 'opt_model.model.decoder.layers.0.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.0.fc1.weight', 'opt_model.model.decoder.layers.0.fc1.bias', 'opt_model.model.decoder.layers.0.fc2.weight', 'opt_model.model.decoder.layers.0.fc2.bias', 'opt_model.model.decoder.layers.0.final_layer_norm.weight', 'opt_model.model.decoder.layers.0.final_layer_norm.bias', 'opt_model.model.decoder.layers.1.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.1.fc1.weight', 'opt_model.model.decoder.layers.1.fc1.bias', 'opt_model.model.decoder.layers.1.fc2.weight', 'opt_model.model.decoder.layers.1.fc2.bias', 'opt_model.model.decoder.layers.1.final_layer_norm.weight', 'opt_model.model.decoder.layers.1.final_layer_norm.bias', 'opt_model.model.decoder.layers.2.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.2.fc1.weight', 'opt_model.model.decoder.layers.2.fc1.bias', 'opt_model.model.decoder.layers.2.fc2.weight', 'opt_model.model.decoder.layers.2.fc2.bias', 'opt_model.model.decoder.layers.2.final_layer_norm.weight', 'opt_model.model.decoder.layers.2.final_layer_norm.bias', 'opt_model.model.decoder.layers.3.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.3.fc1.weight', 'opt_model.model.decoder.layers.3.fc1.bias', 'opt_model.model.decoder.layers.3.fc2.weight', 'opt_model.model.decoder.layers.3.fc2.bias', 'opt_model.model.decoder.layers.3.final_layer_norm.weight', 'opt_model.model.decoder.layers.3.final_layer_norm.bias', 'opt_model.model.decoder.layers.4.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.4.fc1.weight', 'opt_model.model.decoder.layers.4.fc1.bias', 'opt_model.model.decoder.layers.4.fc2.weight', 'opt_model.model.decoder.layers.4.fc2.bias', 'opt_model.model.decoder.layers.4.final_layer_norm.weight', 'opt_model.model.decoder.layers.4.final_layer_norm.bias', 'opt_model.model.decoder.layers.5.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.5.fc1.weight', 'opt_model.model.decoder.layers.5.fc1.bias', 'opt_model.model.decoder.layers.5.fc2.weight', 'opt_model.model.decoder.layers.5.fc2.bias', 'opt_model.model.decoder.layers.5.final_layer_norm.weight', 'opt_model.model.decoder.layers.5.final_layer_norm.bias', 'opt_model.model.decoder.layers.6.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.6.fc1.weight', 'opt_model.model.decoder.layers.6.fc1.bias', 'opt_model.model.decoder.layers.6.fc2.weight', 'opt_model.model.decoder.layers.6.fc2.bias', 'opt_model.model.decoder.layers.6.final_layer_norm.weight', 'opt_model.model.decoder.layers.6.final_layer_norm.bias', 'opt_model.model.decoder.layers.7.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.7.fc1.weight', 'opt_model.model.decoder.layers.7.fc1.bias', 'opt_model.model.decoder.layers.7.fc2.weight', 'opt_model.model.decoder.layers.7.fc2.bias', 'opt_model.model.decoder.layers.7.final_layer_norm.weight', 'opt_model.model.decoder.layers.7.final_layer_norm.bias', 'opt_model.model.decoder.layers.8.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.8.fc1.weight', 'opt_model.model.decoder.layers.8.fc1.bias', 'opt_model.model.decoder.layers.8.fc2.weight', 'opt_model.model.decoder.layers.8.fc2.bias', 'opt_model.model.decoder.layers.8.final_layer_norm.weight', 'opt_model.model.decoder.layers.8.final_layer_norm.bias', 'opt_model.model.decoder.layers.9.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.9.fc1.weight', 'opt_model.model.decoder.layers.9.fc1.bias', 'opt_model.model.decoder.layers.9.fc2.weight', 'opt_model.model.decoder.layers.9.fc2.bias', 'opt_model.model.decoder.layers.9.final_layer_norm.weight', 'opt_model.model.decoder.layers.9.final_layer_norm.bias', 'opt_model.model.decoder.layers.10.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.10.fc1.weight', 'opt_model.model.decoder.layers.10.fc1.bias', 'opt_model.model.decoder.layers.10.fc2.weight', 'opt_model.model.decoder.layers.10.fc2.bias', 'opt_model.model.decoder.layers.10.final_layer_norm.weight', 'opt_model.model.decoder.layers.10.final_layer_norm.bias', 'opt_model.model.decoder.layers.11.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.11.fc1.weight', 'opt_model.model.decoder.layers.11.fc1.bias', 'opt_model.model.decoder.layers.11.fc2.weight', 'opt_model.model.decoder.layers.11.fc2.bias', 'opt_model.model.decoder.layers.11.final_layer_norm.weight', 'opt_model.model.decoder.layers.11.final_layer_norm.bias', 'opt_model.model.decoder.layers.12.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.12.fc1.weight', 'opt_model.model.decoder.layers.12.fc1.bias', 'opt_model.model.decoder.layers.12.fc2.weight', 'opt_model.model.decoder.layers.12.fc2.bias', 'opt_model.model.decoder.layers.12.final_layer_norm.weight', 'opt_model.model.decoder.layers.12.final_layer_norm.bias', 'opt_model.model.decoder.layers.13.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.13.fc1.weight', 'opt_model.model.decoder.layers.13.fc1.bias', 'opt_model.model.decoder.layers.13.fc2.weight', 'opt_model.model.decoder.layers.13.fc2.bias', 'opt_model.model.decoder.layers.13.final_layer_norm.weight', 'opt_model.model.decoder.layers.13.final_layer_norm.bias', 'opt_model.model.decoder.layers.14.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.14.fc1.weight', 'opt_model.model.decoder.layers.14.fc1.bias', 'opt_model.model.decoder.layers.14.fc2.weight', 'opt_model.model.decoder.layers.14.fc2.bias', 'opt_model.model.decoder.layers.14.final_layer_norm.weight', 'opt_model.model.decoder.layers.14.final_layer_norm.bias', 'opt_model.model.decoder.layers.15.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.15.fc1.weight', 'opt_model.model.decoder.layers.15.fc1.bias', 'opt_model.model.decoder.layers.15.fc2.weight', 'opt_model.model.decoder.layers.15.fc2.bias', 'opt_model.model.decoder.layers.15.final_layer_norm.weight', 'opt_model.model.decoder.layers.15.final_layer_norm.bias', 'opt_model.model.decoder.layers.16.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.16.fc1.weight', 'opt_model.model.decoder.layers.16.fc1.bias', 'opt_model.model.decoder.layers.16.fc2.weight', 'opt_model.model.decoder.layers.16.fc2.bias', 'opt_model.model.decoder.layers.16.final_layer_norm.weight', 'opt_model.model.decoder.layers.16.final_layer_norm.bias', 'opt_model.model.decoder.layers.17.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.17.fc1.weight', 'opt_model.model.decoder.layers.17.fc1.bias', 'opt_model.model.decoder.layers.17.fc2.weight', 'opt_model.model.decoder.layers.17.fc2.bias', 'opt_model.model.decoder.layers.17.final_layer_norm.weight', 'opt_model.model.decoder.layers.17.final_layer_norm.bias', 'opt_model.model.decoder.layers.18.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.18.fc1.weight', 'opt_model.model.decoder.layers.18.fc1.bias', 'opt_model.model.decoder.layers.18.fc2.weight', 'opt_model.model.decoder.layers.18.fc2.bias', 'opt_model.model.decoder.layers.18.final_layer_norm.weight', 'opt_model.model.decoder.layers.18.final_layer_norm.bias', 'opt_model.model.decoder.layers.19.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.19.fc1.weight', 'opt_model.model.decoder.layers.19.fc1.bias', 'opt_model.model.decoder.layers.19.fc2.weight', 'opt_model.model.decoder.layers.19.fc2.bias', 'opt_model.model.decoder.layers.19.final_layer_norm.weight', 'opt_model.model.decoder.layers.19.final_layer_norm.bias', 'opt_model.model.decoder.layers.20.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.20.fc1.weight', 'opt_model.model.decoder.layers.20.fc1.bias', 'opt_model.model.decoder.layers.20.fc2.weight', 'opt_model.model.decoder.layers.20.fc2.bias', 'opt_model.model.decoder.layers.20.final_layer_norm.weight', 'opt_model.model.decoder.layers.20.final_layer_norm.bias', 'opt_model.model.decoder.layers.21.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.21.fc1.weight', 'opt_model.model.decoder.layers.21.fc1.bias', 'opt_model.model.decoder.layers.21.fc2.weight', 'opt_model.model.decoder.layers.21.fc2.bias', 'opt_model.model.decoder.layers.21.final_layer_norm.weight', 'opt_model.model.decoder.layers.21.final_layer_norm.bias', 'opt_model.model.decoder.layers.22.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.22.fc1.weight', 'opt_model.model.decoder.layers.22.fc1.bias', 'opt_model.model.decoder.layers.22.fc2.weight', 'opt_model.model.decoder.layers.22.fc2.bias', 'opt_model.model.decoder.layers.22.final_layer_norm.weight', 'opt_model.model.decoder.layers.22.final_layer_norm.bias', 'opt_model.model.decoder.layers.23.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.23.fc1.weight', 'opt_model.model.decoder.layers.23.fc1.bias', 'opt_model.model.decoder.layers.23.fc2.weight', 'opt_model.model.decoder.layers.23.fc2.bias', 'opt_model.model.decoder.layers.23.final_layer_norm.weight', 'opt_model.model.decoder.layers.23.final_layer_norm.bias', 'opt_model.model.decoder.layers.24.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.24.fc1.weight', 'opt_model.model.decoder.layers.24.fc1.bias', 'opt_model.model.decoder.layers.24.fc2.weight', 'opt_model.model.decoder.layers.24.fc2.bias', 'opt_model.model.decoder.layers.24.final_layer_norm.weight', 'opt_model.model.decoder.layers.24.final_layer_norm.bias', 'opt_model.model.decoder.layers.25.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.25.fc1.weight', 'opt_model.model.decoder.layers.25.fc1.bias', 'opt_model.model.decoder.layers.25.fc2.weight', 'opt_model.model.decoder.layers.25.fc2.bias', 'opt_model.model.decoder.layers.25.final_layer_norm.weight', 'opt_model.model.decoder.layers.25.final_layer_norm.bias', 'opt_model.model.decoder.layers.26.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.26.fc1.weight', 'opt_model.model.decoder.layers.26.fc1.bias', 'opt_model.model.decoder.layers.26.fc2.weight', 'opt_model.model.decoder.layers.26.fc2.bias', 'opt_model.model.decoder.layers.26.final_layer_norm.weight', 'opt_model.model.decoder.layers.26.final_layer_norm.bias', 'opt_model.model.decoder.layers.27.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.27.fc1.weight', 'opt_model.model.decoder.layers.27.fc1.bias', 'opt_model.model.decoder.layers.27.fc2.weight', 'opt_model.model.decoder.layers.27.fc2.bias', 'opt_model.model.decoder.layers.27.final_layer_norm.weight', 'opt_model.model.decoder.layers.27.final_layer_norm.bias', 'opt_model.model.decoder.layers.28.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.28.fc1.weight', 'opt_model.model.decoder.layers.28.fc1.bias', 'opt_model.model.decoder.layers.28.fc2.weight', 'opt_model.model.decoder.layers.28.fc2.bias', 'opt_model.model.decoder.layers.28.final_layer_norm.weight', 'opt_model.model.decoder.layers.28.final_layer_norm.bias', 'opt_model.model.decoder.layers.29.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.29.fc1.weight', 'opt_model.model.decoder.layers.29.fc1.bias', 'opt_model.model.decoder.layers.29.fc2.weight', 'opt_model.model.decoder.layers.29.fc2.bias', 'opt_model.model.decoder.layers.29.final_layer_norm.weight', 'opt_model.model.decoder.layers.29.final_layer_norm.bias', 'opt_model.model.decoder.layers.30.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.30.fc1.weight', 'opt_model.model.decoder.layers.30.fc1.bias', 'opt_model.model.decoder.layers.30.fc2.weight', 'opt_model.model.decoder.layers.30.fc2.bias', 'opt_model.model.decoder.layers.30.final_layer_norm.weight', 'opt_model.model.decoder.layers.30.final_layer_norm.bias', 'opt_model.model.decoder.layers.31.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.31.fc1.weight', 'opt_model.model.decoder.layers.31.fc1.bias', 'opt_model.model.decoder.layers.31.fc2.weight', 'opt_model.model.decoder.layers.31.fc2.bias', 'opt_model.model.decoder.layers.31.final_layer_norm.weight', 'opt_model.model.decoder.layers.31.final_layer_norm.bias', 'opt_model.lm_head.weight', 'Darkformer.embeddings.word_embeddings.weight', 'Darkformer.embeddings.position_embeddings.weight', 'Darkformer.embeddings.token_type_embeddings.weight', 'Darkformer.embeddings.LayerNorm.weight', 'Darkformer.embeddings.LayerNorm.bias', 'Darkformer.encoder.layer.0.attention.self.query.weight', 'Darkformer.encoder.layer.0.attention.self.query.bias', 'Darkformer.encoder.layer.0.attention.self.key.weight', 'Darkformer.encoder.layer.0.attention.self.key.bias', 'Darkformer.encoder.layer.0.attention.self.value.weight', 'Darkformer.encoder.layer.0.attention.self.value.bias', 'Darkformer.encoder.layer.0.attention.output.dense.weight', 'Darkformer.encoder.layer.0.attention.output.dense.bias', 'Darkformer.encoder.layer.0.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.0.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.0.intermediate.dense.weight', 'Darkformer.encoder.layer.0.intermediate.dense.bias', 'Darkformer.encoder.layer.0.output.dense.weight', 'Darkformer.encoder.layer.0.output.dense.bias', 'Darkformer.encoder.layer.0.output.LayerNorm.weight', 'Darkformer.encoder.layer.0.output.LayerNorm.bias', 'Darkformer.encoder.layer.1.attention.self.query.weight', 'Darkformer.encoder.layer.1.attention.self.query.bias', 'Darkformer.encoder.layer.1.attention.self.key.weight', 'Darkformer.encoder.layer.1.attention.self.key.bias', 'Darkformer.encoder.layer.1.attention.self.value.weight', 'Darkformer.encoder.layer.1.attention.self.value.bias', 'Darkformer.encoder.layer.1.attention.output.dense.weight', 'Darkformer.encoder.layer.1.attention.output.dense.bias', 'Darkformer.encoder.layer.1.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.1.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.1.intermediate.dense.weight', 'Darkformer.encoder.layer.1.intermediate.dense.bias', 'Darkformer.encoder.layer.1.output.dense.weight', 'Darkformer.encoder.layer.1.output.dense.bias', 'Darkformer.encoder.layer.1.output.LayerNorm.weight', 'Darkformer.encoder.layer.1.output.LayerNorm.bias', 'Darkformer.encoder.layer.2.attention.self.query.weight', 'Darkformer.encoder.layer.2.attention.self.query.bias', 'Darkformer.encoder.layer.2.attention.self.key.weight', 'Darkformer.encoder.layer.2.attention.self.key.bias', 'Darkformer.encoder.layer.2.attention.self.value.weight', 'Darkformer.encoder.layer.2.attention.self.value.bias', 'Darkformer.encoder.layer.2.attention.output.dense.weight', 'Darkformer.encoder.layer.2.attention.output.dense.bias', 'Darkformer.encoder.layer.2.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.2.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.2.intermediate.dense.weight', 'Darkformer.encoder.layer.2.intermediate.dense.bias', 'Darkformer.encoder.layer.2.output.dense.weight', 'Darkformer.encoder.layer.2.output.dense.bias', 'Darkformer.encoder.layer.2.output.LayerNorm.weight', 'Darkformer.encoder.layer.2.output.LayerNorm.bias', 'Darkformer.encoder.layer.3.attention.self.query.weight', 'Darkformer.encoder.layer.3.attention.self.query.bias', 'Darkformer.encoder.layer.3.attention.self.key.weight', 'Darkformer.encoder.layer.3.attention.self.key.bias', 'Darkformer.encoder.layer.3.attention.self.value.weight', 'Darkformer.encoder.layer.3.attention.self.value.bias', 'Darkformer.encoder.layer.3.attention.output.dense.weight', 'Darkformer.encoder.layer.3.attention.output.dense.bias', 'Darkformer.encoder.layer.3.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.3.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.3.intermediate.dense.weight', 'Darkformer.encoder.layer.3.intermediate.dense.bias', 'Darkformer.encoder.layer.3.output.dense.weight', 'Darkformer.encoder.layer.3.output.dense.bias', 'Darkformer.encoder.layer.3.output.LayerNorm.weight', 'Darkformer.encoder.layer.3.output.LayerNorm.bias', 'Darkformer.encoder.layer.4.attention.self.query.weight', 'Darkformer.encoder.layer.4.attention.self.query.bias', 'Darkformer.encoder.layer.4.attention.self.key.weight', 'Darkformer.encoder.layer.4.attention.self.key.bias', 'Darkformer.encoder.layer.4.attention.self.value.weight', 'Darkformer.encoder.layer.4.attention.self.value.bias', 'Darkformer.encoder.layer.4.attention.output.dense.weight', 'Darkformer.encoder.layer.4.attention.output.dense.bias', 'Darkformer.encoder.layer.4.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.4.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.4.intermediate.dense.weight', 'Darkformer.encoder.layer.4.intermediate.dense.bias', 'Darkformer.encoder.layer.4.output.dense.weight', 'Darkformer.encoder.layer.4.output.dense.bias', 'Darkformer.encoder.layer.4.output.LayerNorm.weight', 'Darkformer.encoder.layer.4.output.LayerNorm.bias', 'Darkformer.encoder.layer.5.attention.self.query.weight', 'Darkformer.encoder.layer.5.attention.self.query.bias', 'Darkformer.encoder.layer.5.attention.self.key.weight', 'Darkformer.encoder.layer.5.attention.self.key.bias', 'Darkformer.encoder.layer.5.attention.self.value.weight', 'Darkformer.encoder.layer.5.attention.self.value.bias', 'Darkformer.encoder.layer.5.attention.output.dense.weight', 'Darkformer.encoder.layer.5.attention.output.dense.bias', 'Darkformer.encoder.layer.5.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.5.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.5.intermediate.dense.weight', 'Darkformer.encoder.layer.5.intermediate.dense.bias', 'Darkformer.encoder.layer.5.output.dense.weight', 'Darkformer.encoder.layer.5.output.dense.bias', 'Darkformer.encoder.layer.5.output.LayerNorm.weight', 'Darkformer.encoder.layer.5.output.LayerNorm.bias', 'Darkformer.encoder.layer.6.attention.self.query.weight', 'Darkformer.encoder.layer.6.attention.self.query.bias', 'Darkformer.encoder.layer.6.attention.self.key.weight', 'Darkformer.encoder.layer.6.attention.self.key.bias', 'Darkformer.encoder.layer.6.attention.self.value.weight', 'Darkformer.encoder.layer.6.attention.self.value.bias', 'Darkformer.encoder.layer.6.attention.output.dense.weight', 'Darkformer.encoder.layer.6.attention.output.dense.bias', 'Darkformer.encoder.layer.6.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.6.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.6.intermediate.dense.weight', 'Darkformer.encoder.layer.6.intermediate.dense.bias', 'Darkformer.encoder.layer.6.output.dense.weight', 'Darkformer.encoder.layer.6.output.dense.bias', 'Darkformer.encoder.layer.6.output.LayerNorm.weight', 'Darkformer.encoder.layer.6.output.LayerNorm.bias', 'Darkformer.encoder.layer.7.attention.self.query.weight', 'Darkformer.encoder.layer.7.attention.self.query.bias', 'Darkformer.encoder.layer.7.attention.self.key.weight', 'Darkformer.encoder.layer.7.attention.self.key.bias', 'Darkformer.encoder.layer.7.attention.self.value.weight', 'Darkformer.encoder.layer.7.attention.self.value.bias', 'Darkformer.encoder.layer.7.attention.output.dense.weight', 'Darkformer.encoder.layer.7.attention.output.dense.bias', 'Darkformer.encoder.layer.7.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.7.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.7.intermediate.dense.weight', 'Darkformer.encoder.layer.7.intermediate.dense.bias', 'Darkformer.encoder.layer.7.output.dense.weight', 'Darkformer.encoder.layer.7.output.dense.bias', 'Darkformer.encoder.layer.7.output.LayerNorm.weight', 'Darkformer.encoder.layer.7.output.LayerNorm.bias', 'Darkformer.encoder.layer.8.attention.self.query.weight', 'Darkformer.encoder.layer.8.attention.self.query.bias', 'Darkformer.encoder.layer.8.attention.self.key.weight', 'Darkformer.encoder.layer.8.attention.self.key.bias', 'Darkformer.encoder.layer.8.attention.self.value.weight', 'Darkformer.encoder.layer.8.attention.self.value.bias', 'Darkformer.encoder.layer.8.attention.output.dense.weight', 'Darkformer.encoder.layer.8.attention.output.dense.bias', 'Darkformer.encoder.layer.8.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.8.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.8.intermediate.dense.weight', 'Darkformer.encoder.layer.8.intermediate.dense.bias', 'Darkformer.encoder.layer.8.output.dense.weight', 'Darkformer.encoder.layer.8.output.dense.bias', 'Darkformer.encoder.layer.8.output.LayerNorm.weight', 'Darkformer.encoder.layer.8.output.LayerNorm.bias', 'Darkformer.encoder.layer.9.attention.self.query.weight', 'Darkformer.encoder.layer.9.attention.self.query.bias', 'Darkformer.encoder.layer.9.attention.self.key.weight', 'Darkformer.encoder.layer.9.attention.self.key.bias', 'Darkformer.encoder.layer.9.attention.self.value.weight', 'Darkformer.encoder.layer.9.attention.self.value.bias', 'Darkformer.encoder.layer.9.attention.output.dense.weight', 'Darkformer.encoder.layer.9.attention.output.dense.bias', 'Darkformer.encoder.layer.9.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.9.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.9.intermediate.dense.weight', 'Darkformer.encoder.layer.9.intermediate.dense.bias', 'Darkformer.encoder.layer.9.output.dense.weight', 'Darkformer.encoder.layer.9.output.dense.bias', 'Darkformer.encoder.layer.9.output.LayerNorm.weight', 'Darkformer.encoder.layer.9.output.LayerNorm.bias', 'Darkformer.encoder.layer.10.attention.self.query.weight', 'Darkformer.encoder.layer.10.attention.self.query.bias', 'Darkformer.encoder.layer.10.attention.self.key.weight', 'Darkformer.encoder.layer.10.attention.self.key.bias', 'Darkformer.encoder.layer.10.attention.self.value.weight', 'Darkformer.encoder.layer.10.attention.self.value.bias', 'Darkformer.encoder.layer.10.attention.output.dense.weight', 'Darkformer.encoder.layer.10.attention.output.dense.bias', 'Darkformer.encoder.layer.10.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.10.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.10.intermediate.dense.weight', 'Darkformer.encoder.layer.10.intermediate.dense.bias', 'Darkformer.encoder.layer.10.output.dense.weight', 'Darkformer.encoder.layer.10.output.dense.bias', 'Darkformer.encoder.layer.10.output.LayerNorm.weight', 'Darkformer.encoder.layer.10.output.LayerNorm.bias', 'Darkformer.encoder.layer.11.attention.self.query.weight', 'Darkformer.encoder.layer.11.attention.self.query.bias', 'Darkformer.encoder.layer.11.attention.self.key.weight', 'Darkformer.encoder.layer.11.attention.self.key.bias', 'Darkformer.encoder.layer.11.attention.self.value.weight', 'Darkformer.encoder.layer.11.attention.self.value.bias', 'Darkformer.encoder.layer.11.attention.output.dense.weight', 'Darkformer.encoder.layer.11.attention.output.dense.bias', 'Darkformer.encoder.layer.11.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.11.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.11.intermediate.dense.weight', 'Darkformer.encoder.layer.11.intermediate.dense.bias', 'Darkformer.encoder.layer.11.output.dense.weight', 'Darkformer.encoder.layer.11.output.dense.bias', 'Darkformer.encoder.layer.11.output.LayerNorm.weight', 'Darkformer.encoder.layer.11.output.LayerNorm.bias', 'Darkformer.cls_proj.weight', 'Darkformer.cls_proj.bias', 'Darkformer.pooler.0.weight', 'Darkformer.pooler.0.bias', 'Darkformer.opt_proj.weight', 'Darkformer.opt_proj.bias']
2023-04-20 22:12:32,546 [INFO] load checkpoint from /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage1/20230418231/checkpoint_9.pth
2023-04-20 22:12:32,890 [INFO] Missing keys ['query_tokens', 'visual_encoder.cls_token', 'visual_encoder.pos_embed', 'visual_encoder.patch_embed.proj.weight', 'visual_encoder.patch_embed.proj.bias', 'visual_encoder.blocks.0.norm1.weight', 'visual_encoder.blocks.0.norm1.bias', 'visual_encoder.blocks.0.attn.q_bias', 'visual_encoder.blocks.0.attn.v_bias', 'visual_encoder.blocks.0.attn.qkv.weight', 'visual_encoder.blocks.0.attn.proj.weight', 'visual_encoder.blocks.0.attn.proj.bias', 'visual_encoder.blocks.0.norm2.weight', 'visual_encoder.blocks.0.norm2.bias', 'visual_encoder.blocks.0.mlp.fc1.weight', 'visual_encoder.blocks.0.mlp.fc1.bias', 'visual_encoder.blocks.0.mlp.fc2.weight', 'visual_encoder.blocks.0.mlp.fc2.bias', 'visual_encoder.blocks.1.norm1.weight', 'visual_encoder.blocks.1.norm1.bias', 'visual_encoder.blocks.1.attn.q_bias', 'visual_encoder.blocks.1.attn.v_bias', 'visual_encoder.blocks.1.attn.qkv.weight', 'visual_encoder.blocks.1.attn.proj.weight', 'visual_encoder.blocks.1.attn.proj.bias', 'visual_encoder.blocks.1.norm2.weight', 'visual_encoder.blocks.1.norm2.bias', 'visual_encoder.blocks.1.mlp.fc1.weight', 'visual_encoder.blocks.1.mlp.fc1.bias', 'visual_encoder.blocks.1.mlp.fc2.weight', 'visual_encoder.blocks.1.mlp.fc2.bias', 'visual_encoder.blocks.2.norm1.weight', 'visual_encoder.blocks.2.norm1.bias', 'visual_encoder.blocks.2.attn.q_bias', 'visual_encoder.blocks.2.attn.v_bias', 'visual_encoder.blocks.2.attn.qkv.weight', 'visual_encoder.blocks.2.attn.proj.weight', 'visual_encoder.blocks.2.attn.proj.bias', 'visual_encoder.blocks.2.norm2.weight', 'visual_encoder.blocks.2.norm2.bias', 'visual_encoder.blocks.2.mlp.fc1.weight', 'visual_encoder.blocks.2.mlp.fc1.bias', 'visual_encoder.blocks.2.mlp.fc2.weight', 'visual_encoder.blocks.2.mlp.fc2.bias', 'visual_encoder.blocks.3.norm1.weight', 'visual_encoder.blocks.3.norm1.bias', 'visual_encoder.blocks.3.attn.q_bias', 'visual_encoder.blocks.3.attn.v_bias', 'visual_encoder.blocks.3.attn.qkv.weight', 'visual_encoder.blocks.3.attn.proj.weight', 'visual_encoder.blocks.3.attn.proj.bias', 'visual_encoder.blocks.3.norm2.weight', 'visual_encoder.blocks.3.norm2.bias', 'visual_encoder.blocks.3.mlp.fc1.weight', 'visual_encoder.blocks.3.mlp.fc1.bias', 'visual_encoder.blocks.3.mlp.fc2.weight', 'visual_encoder.blocks.3.mlp.fc2.bias', 'visual_encoder.blocks.4.norm1.weight', 'visual_encoder.blocks.4.norm1.bias', 'visual_encoder.blocks.4.attn.q_bias', 'visual_encoder.blocks.4.attn.v_bias', 'visual_encoder.blocks.4.attn.qkv.weight', 'visual_encoder.blocks.4.attn.proj.weight', 'visual_encoder.blocks.4.attn.proj.bias', 'visual_encoder.blocks.4.norm2.weight', 'visual_encoder.blocks.4.norm2.bias', 'visual_encoder.blocks.4.mlp.fc1.weight', 'visual_encoder.blocks.4.mlp.fc1.bias', 'visual_encoder.blocks.4.mlp.fc2.weight', 'visual_encoder.blocks.4.mlp.fc2.bias', 'visual_encoder.blocks.5.norm1.weight', 'visual_encoder.blocks.5.norm1.bias', 'visual_encoder.blocks.5.attn.q_bias', 'visual_encoder.blocks.5.attn.v_bias', 'visual_encoder.blocks.5.attn.qkv.weight', 'visual_encoder.blocks.5.attn.proj.weight', 'visual_encoder.blocks.5.attn.proj.bias', 'visual_encoder.blocks.5.norm2.weight', 'visual_encoder.blocks.5.norm2.bias', 'visual_encoder.blocks.5.mlp.fc1.weight', 'visual_encoder.blocks.5.mlp.fc1.bias', 'visual_encoder.blocks.5.mlp.fc2.weight', 'visual_encoder.blocks.5.mlp.fc2.bias', 'visual_encoder.blocks.6.norm1.weight', 'visual_encoder.blocks.6.norm1.bias', 'visual_encoder.blocks.6.attn.q_bias', 'visual_encoder.blocks.6.attn.v_bias', 'visual_encoder.blocks.6.attn.qkv.weight', 'visual_encoder.blocks.6.attn.proj.weight', 'visual_encoder.blocks.6.attn.proj.bias', 'visual_encoder.blocks.6.norm2.weight', 'visual_encoder.blocks.6.norm2.bias', 'visual_encoder.blocks.6.mlp.fc1.weight', 'visual_encoder.blocks.6.mlp.fc1.bias', 'visual_encoder.blocks.6.mlp.fc2.weight', 'visual_encoder.blocks.6.mlp.fc2.bias', 'visual_encoder.blocks.7.norm1.weight', 'visual_encoder.blocks.7.norm1.bias', 'visual_encoder.blocks.7.attn.q_bias', 'visual_encoder.blocks.7.attn.v_bias', 'visual_encoder.blocks.7.attn.qkv.weight', 'visual_encoder.blocks.7.attn.proj.weight', 'visual_encoder.blocks.7.attn.proj.bias', 'visual_encoder.blocks.7.norm2.weight', 'visual_encoder.blocks.7.norm2.bias', 'visual_encoder.blocks.7.mlp.fc1.weight', 'visual_encoder.blocks.7.mlp.fc1.bias', 'visual_encoder.blocks.7.mlp.fc2.weight', 'visual_encoder.blocks.7.mlp.fc2.bias', 'visual_encoder.blocks.8.norm1.weight', 'visual_encoder.blocks.8.norm1.bias', 'visual_encoder.blocks.8.attn.q_bias', 'visual_encoder.blocks.8.attn.v_bias', 'visual_encoder.blocks.8.attn.qkv.weight', 'visual_encoder.blocks.8.attn.proj.weight', 'visual_encoder.blocks.8.attn.proj.bias', 'visual_encoder.blocks.8.norm2.weight', 'visual_encoder.blocks.8.norm2.bias', 'visual_encoder.blocks.8.mlp.fc1.weight', 'visual_encoder.blocks.8.mlp.fc1.bias', 'visual_encoder.blocks.8.mlp.fc2.weight', 'visual_encoder.blocks.8.mlp.fc2.bias', 'visual_encoder.blocks.9.norm1.weight', 'visual_encoder.blocks.9.norm1.bias', 'visual_encoder.blocks.9.attn.q_bias', 'visual_encoder.blocks.9.attn.v_bias', 'visual_encoder.blocks.9.attn.qkv.weight', 'visual_encoder.blocks.9.attn.proj.weight', 'visual_encoder.blocks.9.attn.proj.bias', 'visual_encoder.blocks.9.norm2.weight', 'visual_encoder.blocks.9.norm2.bias', 'visual_encoder.blocks.9.mlp.fc1.weight', 'visual_encoder.blocks.9.mlp.fc1.bias', 'visual_encoder.blocks.9.mlp.fc2.weight', 'visual_encoder.blocks.9.mlp.fc2.bias', 'visual_encoder.blocks.10.norm1.weight', 'visual_encoder.blocks.10.norm1.bias', 'visual_encoder.blocks.10.attn.q_bias', 'visual_encoder.blocks.10.attn.v_bias', 'visual_encoder.blocks.10.attn.qkv.weight', 'visual_encoder.blocks.10.attn.proj.weight', 'visual_encoder.blocks.10.attn.proj.bias', 'visual_encoder.blocks.10.norm2.weight', 'visual_encoder.blocks.10.norm2.bias', 'visual_encoder.blocks.10.mlp.fc1.weight', 'visual_encoder.blocks.10.mlp.fc1.bias', 'visual_encoder.blocks.10.mlp.fc2.weight', 'visual_encoder.blocks.10.mlp.fc2.bias', 'visual_encoder.blocks.11.norm1.weight', 'visual_encoder.blocks.11.norm1.bias', 'visual_encoder.blocks.11.attn.q_bias', 'visual_encoder.blocks.11.attn.v_bias', 'visual_encoder.blocks.11.attn.qkv.weight', 'visual_encoder.blocks.11.attn.proj.weight', 'visual_encoder.blocks.11.attn.proj.bias', 'visual_encoder.blocks.11.norm2.weight', 'visual_encoder.blocks.11.norm2.bias', 'visual_encoder.blocks.11.mlp.fc1.weight', 'visual_encoder.blocks.11.mlp.fc1.bias', 'visual_encoder.blocks.11.mlp.fc2.weight', 'visual_encoder.blocks.11.mlp.fc2.bias', 'visual_encoder.blocks.12.norm1.weight', 'visual_encoder.blocks.12.norm1.bias', 'visual_encoder.blocks.12.attn.q_bias', 'visual_encoder.blocks.12.attn.v_bias', 'visual_encoder.blocks.12.attn.qkv.weight', 'visual_encoder.blocks.12.attn.proj.weight', 'visual_encoder.blocks.12.attn.proj.bias', 'visual_encoder.blocks.12.norm2.weight', 'visual_encoder.blocks.12.norm2.bias', 'visual_encoder.blocks.12.mlp.fc1.weight', 'visual_encoder.blocks.12.mlp.fc1.bias', 'visual_encoder.blocks.12.mlp.fc2.weight', 'visual_encoder.blocks.12.mlp.fc2.bias', 'visual_encoder.blocks.13.norm1.weight', 'visual_encoder.blocks.13.norm1.bias', 'visual_encoder.blocks.13.attn.q_bias', 'visual_encoder.blocks.13.attn.v_bias', 'visual_encoder.blocks.13.attn.qkv.weight', 'visual_encoder.blocks.13.attn.proj.weight', 'visual_encoder.blocks.13.attn.proj.bias', 'visual_encoder.blocks.13.norm2.weight', 'visual_encoder.blocks.13.norm2.bias', 'visual_encoder.blocks.13.mlp.fc1.weight', 'visual_encoder.blocks.13.mlp.fc1.bias', 'visual_encoder.blocks.13.mlp.fc2.weight', 'visual_encoder.blocks.13.mlp.fc2.bias', 'visual_encoder.blocks.14.norm1.weight', 'visual_encoder.blocks.14.norm1.bias', 'visual_encoder.blocks.14.attn.q_bias', 'visual_encoder.blocks.14.attn.v_bias', 'visual_encoder.blocks.14.attn.qkv.weight', 'visual_encoder.blocks.14.attn.proj.weight', 'visual_encoder.blocks.14.attn.proj.bias', 'visual_encoder.blocks.14.norm2.weight', 'visual_encoder.blocks.14.norm2.bias', 'visual_encoder.blocks.14.mlp.fc1.weight', 'visual_encoder.blocks.14.mlp.fc1.bias', 'visual_encoder.blocks.14.mlp.fc2.weight', 'visual_encoder.blocks.14.mlp.fc2.bias', 'visual_encoder.blocks.15.norm1.weight', 'visual_encoder.blocks.15.norm1.bias', 'visual_encoder.blocks.15.attn.q_bias', 'visual_encoder.blocks.15.attn.v_bias', 'visual_encoder.blocks.15.attn.qkv.weight', 'visual_encoder.blocks.15.attn.proj.weight', 'visual_encoder.blocks.15.attn.proj.bias', 'visual_encoder.blocks.15.norm2.weight', 'visual_encoder.blocks.15.norm2.bias', 'visual_encoder.blocks.15.mlp.fc1.weight', 'visual_encoder.blocks.15.mlp.fc1.bias', 'visual_encoder.blocks.15.mlp.fc2.weight', 'visual_encoder.blocks.15.mlp.fc2.bias', 'visual_encoder.blocks.16.norm1.weight', 'visual_encoder.blocks.16.norm1.bias', 'visual_encoder.blocks.16.attn.q_bias', 'visual_encoder.blocks.16.attn.v_bias', 'visual_encoder.blocks.16.attn.qkv.weight', 'visual_encoder.blocks.16.attn.proj.weight', 'visual_encoder.blocks.16.attn.proj.bias', 'visual_encoder.blocks.16.norm2.weight', 'visual_encoder.blocks.16.norm2.bias', 'visual_encoder.blocks.16.mlp.fc1.weight', 'visual_encoder.blocks.16.mlp.fc1.bias', 'visual_encoder.blocks.16.mlp.fc2.weight', 'visual_encoder.blocks.16.mlp.fc2.bias', 'visual_encoder.blocks.17.norm1.weight', 'visual_encoder.blocks.17.norm1.bias', 'visual_encoder.blocks.17.attn.q_bias', 'visual_encoder.blocks.17.attn.v_bias', 'visual_encoder.blocks.17.attn.qkv.weight', 'visual_encoder.blocks.17.attn.proj.weight', 'visual_encoder.blocks.17.attn.proj.bias', 'visual_encoder.blocks.17.norm2.weight', 'visual_encoder.blocks.17.norm2.bias', 'visual_encoder.blocks.17.mlp.fc1.weight', 'visual_encoder.blocks.17.mlp.fc1.bias', 'visual_encoder.blocks.17.mlp.fc2.weight', 'visual_encoder.blocks.17.mlp.fc2.bias', 'visual_encoder.blocks.18.norm1.weight', 'visual_encoder.blocks.18.norm1.bias', 'visual_encoder.blocks.18.attn.q_bias', 'visual_encoder.blocks.18.attn.v_bias', 'visual_encoder.blocks.18.attn.qkv.weight', 'visual_encoder.blocks.18.attn.proj.weight', 'visual_encoder.blocks.18.attn.proj.bias', 'visual_encoder.blocks.18.norm2.weight', 'visual_encoder.blocks.18.norm2.bias', 'visual_encoder.blocks.18.mlp.fc1.weight', 'visual_encoder.blocks.18.mlp.fc1.bias', 'visual_encoder.blocks.18.mlp.fc2.weight', 'visual_encoder.blocks.18.mlp.fc2.bias', 'visual_encoder.blocks.19.norm1.weight', 'visual_encoder.blocks.19.norm1.bias', 'visual_encoder.blocks.19.attn.q_bias', 'visual_encoder.blocks.19.attn.v_bias', 'visual_encoder.blocks.19.attn.qkv.weight', 'visual_encoder.blocks.19.attn.proj.weight', 'visual_encoder.blocks.19.attn.proj.bias', 'visual_encoder.blocks.19.norm2.weight', 'visual_encoder.blocks.19.norm2.bias', 'visual_encoder.blocks.19.mlp.fc1.weight', 'visual_encoder.blocks.19.mlp.fc1.bias', 'visual_encoder.blocks.19.mlp.fc2.weight', 'visual_encoder.blocks.19.mlp.fc2.bias', 'visual_encoder.blocks.20.norm1.weight', 'visual_encoder.blocks.20.norm1.bias', 'visual_encoder.blocks.20.attn.q_bias', 'visual_encoder.blocks.20.attn.v_bias', 'visual_encoder.blocks.20.attn.qkv.weight', 'visual_encoder.blocks.20.attn.proj.weight', 'visual_encoder.blocks.20.attn.proj.bias', 'visual_encoder.blocks.20.norm2.weight', 'visual_encoder.blocks.20.norm2.bias', 'visual_encoder.blocks.20.mlp.fc1.weight', 'visual_encoder.blocks.20.mlp.fc1.bias', 'visual_encoder.blocks.20.mlp.fc2.weight', 'visual_encoder.blocks.20.mlp.fc2.bias', 'visual_encoder.blocks.21.norm1.weight', 'visual_encoder.blocks.21.norm1.bias', 'visual_encoder.blocks.21.attn.q_bias', 'visual_encoder.blocks.21.attn.v_bias', 'visual_encoder.blocks.21.attn.qkv.weight', 'visual_encoder.blocks.21.attn.proj.weight', 'visual_encoder.blocks.21.attn.proj.bias', 'visual_encoder.blocks.21.norm2.weight', 'visual_encoder.blocks.21.norm2.bias', 'visual_encoder.blocks.21.mlp.fc1.weight', 'visual_encoder.blocks.21.mlp.fc1.bias', 'visual_encoder.blocks.21.mlp.fc2.weight', 'visual_encoder.blocks.21.mlp.fc2.bias', 'visual_encoder.blocks.22.norm1.weight', 'visual_encoder.blocks.22.norm1.bias', 'visual_encoder.blocks.22.attn.q_bias', 'visual_encoder.blocks.22.attn.v_bias', 'visual_encoder.blocks.22.attn.qkv.weight', 'visual_encoder.blocks.22.attn.proj.weight', 'visual_encoder.blocks.22.attn.proj.bias', 'visual_encoder.blocks.22.norm2.weight', 'visual_encoder.blocks.22.norm2.bias', 'visual_encoder.blocks.22.mlp.fc1.weight', 'visual_encoder.blocks.22.mlp.fc1.bias', 'visual_encoder.blocks.22.mlp.fc2.weight', 'visual_encoder.blocks.22.mlp.fc2.bias', 'visual_encoder.blocks.23.norm1.weight', 'visual_encoder.blocks.23.norm1.bias', 'visual_encoder.blocks.23.attn.q_bias', 'visual_encoder.blocks.23.attn.v_bias', 'visual_encoder.blocks.23.attn.qkv.weight', 'visual_encoder.blocks.23.attn.proj.weight', 'visual_encoder.blocks.23.attn.proj.bias', 'visual_encoder.blocks.23.norm2.weight', 'visual_encoder.blocks.23.norm2.bias', 'visual_encoder.blocks.23.mlp.fc1.weight', 'visual_encoder.blocks.23.mlp.fc1.bias', 'visual_encoder.blocks.23.mlp.fc2.weight', 'visual_encoder.blocks.23.mlp.fc2.bias', 'visual_encoder.blocks.24.norm1.weight', 'visual_encoder.blocks.24.norm1.bias', 'visual_encoder.blocks.24.attn.q_bias', 'visual_encoder.blocks.24.attn.v_bias', 'visual_encoder.blocks.24.attn.qkv.weight', 'visual_encoder.blocks.24.attn.proj.weight', 'visual_encoder.blocks.24.attn.proj.bias', 'visual_encoder.blocks.24.norm2.weight', 'visual_encoder.blocks.24.norm2.bias', 'visual_encoder.blocks.24.mlp.fc1.weight', 'visual_encoder.blocks.24.mlp.fc1.bias', 'visual_encoder.blocks.24.mlp.fc2.weight', 'visual_encoder.blocks.24.mlp.fc2.bias', 'visual_encoder.blocks.25.norm1.weight', 'visual_encoder.blocks.25.norm1.bias', 'visual_encoder.blocks.25.attn.q_bias', 'visual_encoder.blocks.25.attn.v_bias', 'visual_encoder.blocks.25.attn.qkv.weight', 'visual_encoder.blocks.25.attn.proj.weight', 'visual_encoder.blocks.25.attn.proj.bias', 'visual_encoder.blocks.25.norm2.weight', 'visual_encoder.blocks.25.norm2.bias', 'visual_encoder.blocks.25.mlp.fc1.weight', 'visual_encoder.blocks.25.mlp.fc1.bias', 'visual_encoder.blocks.25.mlp.fc2.weight', 'visual_encoder.blocks.25.mlp.fc2.bias', 'visual_encoder.blocks.26.norm1.weight', 'visual_encoder.blocks.26.norm1.bias', 'visual_encoder.blocks.26.attn.q_bias', 'visual_encoder.blocks.26.attn.v_bias', 'visual_encoder.blocks.26.attn.qkv.weight', 'visual_encoder.blocks.26.attn.proj.weight', 'visual_encoder.blocks.26.attn.proj.bias', 'visual_encoder.blocks.26.norm2.weight', 'visual_encoder.blocks.26.norm2.bias', 'visual_encoder.blocks.26.mlp.fc1.weight', 'visual_encoder.blocks.26.mlp.fc1.bias', 'visual_encoder.blocks.26.mlp.fc2.weight', 'visual_encoder.blocks.26.mlp.fc2.bias', 'visual_encoder.blocks.27.norm1.weight', 'visual_encoder.blocks.27.norm1.bias', 'visual_encoder.blocks.27.attn.q_bias', 'visual_encoder.blocks.27.attn.v_bias', 'visual_encoder.blocks.27.attn.qkv.weight', 'visual_encoder.blocks.27.attn.proj.weight', 'visual_encoder.blocks.27.attn.proj.bias', 'visual_encoder.blocks.27.norm2.weight', 'visual_encoder.blocks.27.norm2.bias', 'visual_encoder.blocks.27.mlp.fc1.weight', 'visual_encoder.blocks.27.mlp.fc1.bias', 'visual_encoder.blocks.27.mlp.fc2.weight', 'visual_encoder.blocks.27.mlp.fc2.bias', 'visual_encoder.blocks.28.norm1.weight', 'visual_encoder.blocks.28.norm1.bias', 'visual_encoder.blocks.28.attn.q_bias', 'visual_encoder.blocks.28.attn.v_bias', 'visual_encoder.blocks.28.attn.qkv.weight', 'visual_encoder.blocks.28.attn.proj.weight', 'visual_encoder.blocks.28.attn.proj.bias', 'visual_encoder.blocks.28.norm2.weight', 'visual_encoder.blocks.28.norm2.bias', 'visual_encoder.blocks.28.mlp.fc1.weight', 'visual_encoder.blocks.28.mlp.fc1.bias', 'visual_encoder.blocks.28.mlp.fc2.weight', 'visual_encoder.blocks.28.mlp.fc2.bias', 'visual_encoder.blocks.29.norm1.weight', 'visual_encoder.blocks.29.norm1.bias', 'visual_encoder.blocks.29.attn.q_bias', 'visual_encoder.blocks.29.attn.v_bias', 'visual_encoder.blocks.29.attn.qkv.weight', 'visual_encoder.blocks.29.attn.proj.weight', 'visual_encoder.blocks.29.attn.proj.bias', 'visual_encoder.blocks.29.norm2.weight', 'visual_encoder.blocks.29.norm2.bias', 'visual_encoder.blocks.29.mlp.fc1.weight', 'visual_encoder.blocks.29.mlp.fc1.bias', 'visual_encoder.blocks.29.mlp.fc2.weight', 'visual_encoder.blocks.29.mlp.fc2.bias', 'visual_encoder.blocks.30.norm1.weight', 'visual_encoder.blocks.30.norm1.bias', 'visual_encoder.blocks.30.attn.q_bias', 'visual_encoder.blocks.30.attn.v_bias', 'visual_encoder.blocks.30.attn.qkv.weight', 'visual_encoder.blocks.30.attn.proj.weight', 'visual_encoder.blocks.30.attn.proj.bias', 'visual_encoder.blocks.30.norm2.weight', 'visual_encoder.blocks.30.norm2.bias', 'visual_encoder.blocks.30.mlp.fc1.weight', 'visual_encoder.blocks.30.mlp.fc1.bias', 'visual_encoder.blocks.30.mlp.fc2.weight', 'visual_encoder.blocks.30.mlp.fc2.bias', 'visual_encoder.blocks.31.norm1.weight', 'visual_encoder.blocks.31.norm1.bias', 'visual_encoder.blocks.31.attn.q_bias', 'visual_encoder.blocks.31.attn.v_bias', 'visual_encoder.blocks.31.attn.qkv.weight', 'visual_encoder.blocks.31.attn.proj.weight', 'visual_encoder.blocks.31.attn.proj.bias', 'visual_encoder.blocks.31.norm2.weight', 'visual_encoder.blocks.31.norm2.bias', 'visual_encoder.blocks.31.mlp.fc1.weight', 'visual_encoder.blocks.31.mlp.fc1.bias', 'visual_encoder.blocks.31.mlp.fc2.weight', 'visual_encoder.blocks.31.mlp.fc2.bias', 'visual_encoder.blocks.32.norm1.weight', 'visual_encoder.blocks.32.norm1.bias', 'visual_encoder.blocks.32.attn.q_bias', 'visual_encoder.blocks.32.attn.v_bias', 'visual_encoder.blocks.32.attn.qkv.weight', 'visual_encoder.blocks.32.attn.proj.weight', 'visual_encoder.blocks.32.attn.proj.bias', 'visual_encoder.blocks.32.norm2.weight', 'visual_encoder.blocks.32.norm2.bias', 'visual_encoder.blocks.32.mlp.fc1.weight', 'visual_encoder.blocks.32.mlp.fc1.bias', 'visual_encoder.blocks.32.mlp.fc2.weight', 'visual_encoder.blocks.32.mlp.fc2.bias', 'visual_encoder.blocks.33.norm1.weight', 'visual_encoder.blocks.33.norm1.bias', 'visual_encoder.blocks.33.attn.q_bias', 'visual_encoder.blocks.33.attn.v_bias', 'visual_encoder.blocks.33.attn.qkv.weight', 'visual_encoder.blocks.33.attn.proj.weight', 'visual_encoder.blocks.33.attn.proj.bias', 'visual_encoder.blocks.33.norm2.weight', 'visual_encoder.blocks.33.norm2.bias', 'visual_encoder.blocks.33.mlp.fc1.weight', 'visual_encoder.blocks.33.mlp.fc1.bias', 'visual_encoder.blocks.33.mlp.fc2.weight', 'visual_encoder.blocks.33.mlp.fc2.bias', 'visual_encoder.blocks.34.norm1.weight', 'visual_encoder.blocks.34.norm1.bias', 'visual_encoder.blocks.34.attn.q_bias', 'visual_encoder.blocks.34.attn.v_bias', 'visual_encoder.blocks.34.attn.qkv.weight', 'visual_encoder.blocks.34.attn.proj.weight', 'visual_encoder.blocks.34.attn.proj.bias', 'visual_encoder.blocks.34.norm2.weight', 'visual_encoder.blocks.34.norm2.bias', 'visual_encoder.blocks.34.mlp.fc1.weight', 'visual_encoder.blocks.34.mlp.fc1.bias', 'visual_encoder.blocks.34.mlp.fc2.weight', 'visual_encoder.blocks.34.mlp.fc2.bias', 'visual_encoder.blocks.35.norm1.weight', 'visual_encoder.blocks.35.norm1.bias', 'visual_encoder.blocks.35.attn.q_bias', 'visual_encoder.blocks.35.attn.v_bias', 'visual_encoder.blocks.35.attn.qkv.weight', 'visual_encoder.blocks.35.attn.proj.weight', 'visual_encoder.blocks.35.attn.proj.bias', 'visual_encoder.blocks.35.norm2.weight', 'visual_encoder.blocks.35.norm2.bias', 'visual_encoder.blocks.35.mlp.fc1.weight', 'visual_encoder.blocks.35.mlp.fc1.bias', 'visual_encoder.blocks.35.mlp.fc2.weight', 'visual_encoder.blocks.35.mlp.fc2.bias', 'visual_encoder.blocks.36.norm1.weight', 'visual_encoder.blocks.36.norm1.bias', 'visual_encoder.blocks.36.attn.q_bias', 'visual_encoder.blocks.36.attn.v_bias', 'visual_encoder.blocks.36.attn.qkv.weight', 'visual_encoder.blocks.36.attn.proj.weight', 'visual_encoder.blocks.36.attn.proj.bias', 'visual_encoder.blocks.36.norm2.weight', 'visual_encoder.blocks.36.norm2.bias', 'visual_encoder.blocks.36.mlp.fc1.weight', 'visual_encoder.blocks.36.mlp.fc1.bias', 'visual_encoder.blocks.36.mlp.fc2.weight', 'visual_encoder.blocks.36.mlp.fc2.bias', 'visual_encoder.blocks.37.norm1.weight', 'visual_encoder.blocks.37.norm1.bias', 'visual_encoder.blocks.37.attn.q_bias', 'visual_encoder.blocks.37.attn.v_bias', 'visual_encoder.blocks.37.attn.qkv.weight', 'visual_encoder.blocks.37.attn.proj.weight', 'visual_encoder.blocks.37.attn.proj.bias', 'visual_encoder.blocks.37.norm2.weight', 'visual_encoder.blocks.37.norm2.bias', 'visual_encoder.blocks.37.mlp.fc1.weight', 'visual_encoder.blocks.37.mlp.fc1.bias', 'visual_encoder.blocks.37.mlp.fc2.weight', 'visual_encoder.blocks.37.mlp.fc2.bias', 'visual_encoder.blocks.38.norm1.weight', 'visual_encoder.blocks.38.norm1.bias', 'visual_encoder.blocks.38.attn.q_bias', 'visual_encoder.blocks.38.attn.v_bias', 'visual_encoder.blocks.38.attn.qkv.weight', 'visual_encoder.blocks.38.attn.proj.weight', 'visual_encoder.blocks.38.attn.proj.bias', 'visual_encoder.blocks.38.norm2.weight', 'visual_encoder.blocks.38.norm2.bias', 'visual_encoder.blocks.38.mlp.fc1.weight', 'visual_encoder.blocks.38.mlp.fc1.bias', 'visual_encoder.blocks.38.mlp.fc2.weight', 'visual_encoder.blocks.38.mlp.fc2.bias', 'ln_vision.weight', 'ln_vision.bias', 'Qformer.bert.embeddings.position_ids', 'Qformer.bert.embeddings.LayerNorm.weight', 'Qformer.bert.embeddings.LayerNorm.bias', 'Qformer.bert.encoder.layer.0.attention.self.query.weight', 'Qformer.bert.encoder.layer.0.attention.self.query.bias', 'Qformer.bert.encoder.layer.0.attention.self.key.weight', 'Qformer.bert.encoder.layer.0.attention.self.key.bias', 'Qformer.bert.encoder.layer.0.attention.self.value.weight', 'Qformer.bert.encoder.layer.0.attention.self.value.bias', 'Qformer.bert.encoder.layer.0.attention.output.dense.weight', 'Qformer.bert.encoder.layer.0.attention.output.dense.bias', 'Qformer.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.0.crossattention.self.query.weight', 'Qformer.bert.encoder.layer.0.crossattention.self.query.bias', 'Qformer.bert.encoder.layer.0.crossattention.self.key.weight', 'Qformer.bert.encoder.layer.0.crossattention.self.key.bias', 'Qformer.bert.encoder.layer.0.crossattention.self.value.weight', 'Qformer.bert.encoder.layer.0.crossattention.self.value.bias', 'Qformer.bert.encoder.layer.0.crossattention.output.dense.weight', 'Qformer.bert.encoder.layer.0.crossattention.output.dense.bias', 'Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.0.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.0.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.0.output_query.dense.weight', 'Qformer.bert.encoder.layer.0.output_query.dense.bias', 'Qformer.bert.encoder.layer.0.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.0.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.1.attention.self.query.weight', 'Qformer.bert.encoder.layer.1.attention.self.query.bias', 'Qformer.bert.encoder.layer.1.attention.self.key.weight', 'Qformer.bert.encoder.layer.1.attention.self.key.bias', 'Qformer.bert.encoder.layer.1.attention.self.value.weight', 'Qformer.bert.encoder.layer.1.attention.self.value.bias', 'Qformer.bert.encoder.layer.1.attention.output.dense.weight', 'Qformer.bert.encoder.layer.1.attention.output.dense.bias', 'Qformer.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.1.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.1.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.1.output_query.dense.weight', 'Qformer.bert.encoder.layer.1.output_query.dense.bias', 'Qformer.bert.encoder.layer.1.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.1.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.2.attention.self.query.weight', 'Qformer.bert.encoder.layer.2.attention.self.query.bias', 'Qformer.bert.encoder.layer.2.attention.self.key.weight', 'Qformer.bert.encoder.layer.2.attention.self.key.bias', 'Qformer.bert.encoder.layer.2.attention.self.value.weight', 'Qformer.bert.encoder.layer.2.attention.self.value.bias', 'Qformer.bert.encoder.layer.2.attention.output.dense.weight', 'Qformer.bert.encoder.layer.2.attention.output.dense.bias', 'Qformer.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.2.crossattention.self.query.weight', 'Qformer.bert.encoder.layer.2.crossattention.self.query.bias', 'Qformer.bert.encoder.layer.2.crossattention.self.key.weight', 'Qformer.bert.encoder.layer.2.crossattention.self.key.bias', 'Qformer.bert.encoder.layer.2.crossattention.self.value.weight', 'Qformer.bert.encoder.layer.2.crossattention.self.value.bias', 'Qformer.bert.encoder.layer.2.crossattention.output.dense.weight', 'Qformer.bert.encoder.layer.2.crossattention.output.dense.bias', 'Qformer.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.2.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.2.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.2.output_query.dense.weight', 'Qformer.bert.encoder.layer.2.output_query.dense.bias', 'Qformer.bert.encoder.layer.2.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.2.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.3.attention.self.query.weight', 'Qformer.bert.encoder.layer.3.attention.self.query.bias', 'Qformer.bert.encoder.layer.3.attention.self.key.weight', 'Qformer.bert.encoder.layer.3.attention.self.key.bias', 'Qformer.bert.encoder.layer.3.attention.self.value.weight', 'Qformer.bert.encoder.layer.3.attention.self.value.bias', 'Qformer.bert.encoder.layer.3.attention.output.dense.weight', 'Qformer.bert.encoder.layer.3.attention.output.dense.bias', 'Qformer.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.3.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.3.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.3.output_query.dense.weight', 'Qformer.bert.encoder.layer.3.output_query.dense.bias', 'Qformer.bert.encoder.layer.3.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.3.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.4.attention.self.query.weight', 'Qformer.bert.encoder.layer.4.attention.self.query.bias', 'Qformer.bert.encoder.layer.4.attention.self.key.weight', 'Qformer.bert.encoder.layer.4.attention.self.key.bias', 'Qformer.bert.encoder.layer.4.attention.self.value.weight', 'Qformer.bert.encoder.layer.4.attention.self.value.bias', 'Qformer.bert.encoder.layer.4.attention.output.dense.weight', 'Qformer.bert.encoder.layer.4.attention.output.dense.bias', 'Qformer.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.4.crossattention.self.query.weight', 'Qformer.bert.encoder.layer.4.crossattention.self.query.bias', 'Qformer.bert.encoder.layer.4.crossattention.self.key.weight', 'Qformer.bert.encoder.layer.4.crossattention.self.key.bias', 'Qformer.bert.encoder.layer.4.crossattention.self.value.weight', 'Qformer.bert.encoder.layer.4.crossattention.self.value.bias', 'Qformer.bert.encoder.layer.4.crossattention.output.dense.weight', 'Qformer.bert.encoder.layer.4.crossattention.output.dense.bias', 'Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.4.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.4.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.4.output_query.dense.weight', 'Qformer.bert.encoder.layer.4.output_query.dense.bias', 'Qformer.bert.encoder.layer.4.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.4.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.5.attention.self.query.weight', 'Qformer.bert.encoder.layer.5.attention.self.query.bias', 'Qformer.bert.encoder.layer.5.attention.self.key.weight', 'Qformer.bert.encoder.layer.5.attention.self.key.bias', 'Qformer.bert.encoder.layer.5.attention.self.value.weight', 'Qformer.bert.encoder.layer.5.attention.self.value.bias', 'Qformer.bert.encoder.layer.5.attention.output.dense.weight', 'Qformer.bert.encoder.layer.5.attention.output.dense.bias', 'Qformer.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.5.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.5.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.5.output_query.dense.weight', 'Qformer.bert.encoder.layer.5.output_query.dense.bias', 'Qformer.bert.encoder.layer.5.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.5.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.6.attention.self.query.weight', 'Qformer.bert.encoder.layer.6.attention.self.query.bias', 'Qformer.bert.encoder.layer.6.attention.self.key.weight', 'Qformer.bert.encoder.layer.6.attention.self.key.bias', 'Qformer.bert.encoder.layer.6.attention.self.value.weight', 'Qformer.bert.encoder.layer.6.attention.self.value.bias', 'Qformer.bert.encoder.layer.6.attention.output.dense.weight', 'Qformer.bert.encoder.layer.6.attention.output.dense.bias', 'Qformer.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.6.crossattention.self.query.weight', 'Qformer.bert.encoder.layer.6.crossattention.self.query.bias', 'Qformer.bert.encoder.layer.6.crossattention.self.key.weight', 'Qformer.bert.encoder.layer.6.crossattention.self.key.bias', 'Qformer.bert.encoder.layer.6.crossattention.self.value.weight', 'Qformer.bert.encoder.layer.6.crossattention.self.value.bias', 'Qformer.bert.encoder.layer.6.crossattention.output.dense.weight', 'Qformer.bert.encoder.layer.6.crossattention.output.dense.bias', 'Qformer.bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.6.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.6.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.6.output_query.dense.weight', 'Qformer.bert.encoder.layer.6.output_query.dense.bias', 'Qformer.bert.encoder.layer.6.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.6.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.7.attention.self.query.weight', 'Qformer.bert.encoder.layer.7.attention.self.query.bias', 'Qformer.bert.encoder.layer.7.attention.self.key.weight', 'Qformer.bert.encoder.layer.7.attention.self.key.bias', 'Qformer.bert.encoder.layer.7.attention.self.value.weight', 'Qformer.bert.encoder.layer.7.attention.self.value.bias', 'Qformer.bert.encoder.layer.7.attention.output.dense.weight', 'Qformer.bert.encoder.layer.7.attention.output.dense.bias', 'Qformer.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.7.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.7.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.7.output_query.dense.weight', 'Qformer.bert.encoder.layer.7.output_query.dense.bias', 'Qformer.bert.encoder.layer.7.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.7.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.8.attention.self.query.weight', 'Qformer.bert.encoder.layer.8.attention.self.query.bias', 'Qformer.bert.encoder.layer.8.attention.self.key.weight', 'Qformer.bert.encoder.layer.8.attention.self.key.bias', 'Qformer.bert.encoder.layer.8.attention.self.value.weight', 'Qformer.bert.encoder.layer.8.attention.self.value.bias', 'Qformer.bert.encoder.layer.8.attention.output.dense.weight', 'Qformer.bert.encoder.layer.8.attention.output.dense.bias', 'Qformer.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.8.crossattention.self.query.weight', 'Qformer.bert.encoder.layer.8.crossattention.self.query.bias', 'Qformer.bert.encoder.layer.8.crossattention.self.key.weight', 'Qformer.bert.encoder.layer.8.crossattention.self.key.bias', 'Qformer.bert.encoder.layer.8.crossattention.self.value.weight', 'Qformer.bert.encoder.layer.8.crossattention.self.value.bias', 'Qformer.bert.encoder.layer.8.crossattention.output.dense.weight', 'Qformer.bert.encoder.layer.8.crossattention.output.dense.bias', 'Qformer.bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.8.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.8.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.8.output_query.dense.weight', 'Qformer.bert.encoder.layer.8.output_query.dense.bias', 'Qformer.bert.encoder.layer.8.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.8.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.9.attention.self.query.weight', 'Qformer.bert.encoder.layer.9.attention.self.query.bias', 'Qformer.bert.encoder.layer.9.attention.self.key.weight', 'Qformer.bert.encoder.layer.9.attention.self.key.bias', 'Qformer.bert.encoder.layer.9.attention.self.value.weight', 'Qformer.bert.encoder.layer.9.attention.self.value.bias', 'Qformer.bert.encoder.layer.9.attention.output.dense.weight', 'Qformer.bert.encoder.layer.9.attention.output.dense.bias', 'Qformer.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.9.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.9.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.9.output_query.dense.weight', 'Qformer.bert.encoder.layer.9.output_query.dense.bias', 'Qformer.bert.encoder.layer.9.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.9.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.10.attention.self.query.weight', 'Qformer.bert.encoder.layer.10.attention.self.query.bias', 'Qformer.bert.encoder.layer.10.attention.self.key.weight', 'Qformer.bert.encoder.layer.10.attention.self.key.bias', 'Qformer.bert.encoder.layer.10.attention.self.value.weight', 'Qformer.bert.encoder.layer.10.attention.self.value.bias', 'Qformer.bert.encoder.layer.10.attention.output.dense.weight', 'Qformer.bert.encoder.layer.10.attention.output.dense.bias', 'Qformer.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.10.crossattention.self.query.weight', 'Qformer.bert.encoder.layer.10.crossattention.self.query.bias', 'Qformer.bert.encoder.layer.10.crossattention.self.key.weight', 'Qformer.bert.encoder.layer.10.crossattention.self.key.bias', 'Qformer.bert.encoder.layer.10.crossattention.self.value.weight', 'Qformer.bert.encoder.layer.10.crossattention.self.value.bias', 'Qformer.bert.encoder.layer.10.crossattention.output.dense.weight', 'Qformer.bert.encoder.layer.10.crossattention.output.dense.bias', 'Qformer.bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.10.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.10.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.10.output_query.dense.weight', 'Qformer.bert.encoder.layer.10.output_query.dense.bias', 'Qformer.bert.encoder.layer.10.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.10.output_query.LayerNorm.bias', 'Qformer.bert.encoder.layer.11.attention.self.query.weight', 'Qformer.bert.encoder.layer.11.attention.self.query.bias', 'Qformer.bert.encoder.layer.11.attention.self.key.weight', 'Qformer.bert.encoder.layer.11.attention.self.key.bias', 'Qformer.bert.encoder.layer.11.attention.self.value.weight', 'Qformer.bert.encoder.layer.11.attention.self.value.bias', 'Qformer.bert.encoder.layer.11.attention.output.dense.weight', 'Qformer.bert.encoder.layer.11.attention.output.dense.bias', 'Qformer.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.11.intermediate_query.dense.weight', 'Qformer.bert.encoder.layer.11.intermediate_query.dense.bias', 'Qformer.bert.encoder.layer.11.output_query.dense.weight', 'Qformer.bert.encoder.layer.11.output_query.dense.bias', 'Qformer.bert.encoder.layer.11.output_query.LayerNorm.weight', 'Qformer.bert.encoder.layer.11.output_query.LayerNorm.bias', 'opt_model.model.decoder.embed_tokens.weight', 'opt_model.model.decoder.embed_positions.weight', 'opt_model.model.decoder.final_layer_norm.weight', 'opt_model.model.decoder.final_layer_norm.bias', 'opt_model.model.decoder.layers.0.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.0.fc1.weight', 'opt_model.model.decoder.layers.0.fc1.bias', 'opt_model.model.decoder.layers.0.fc2.weight', 'opt_model.model.decoder.layers.0.fc2.bias', 'opt_model.model.decoder.layers.0.final_layer_norm.weight', 'opt_model.model.decoder.layers.0.final_layer_norm.bias', 'opt_model.model.decoder.layers.1.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.1.fc1.weight', 'opt_model.model.decoder.layers.1.fc1.bias', 'opt_model.model.decoder.layers.1.fc2.weight', 'opt_model.model.decoder.layers.1.fc2.bias', 'opt_model.model.decoder.layers.1.final_layer_norm.weight', 'opt_model.model.decoder.layers.1.final_layer_norm.bias', 'opt_model.model.decoder.layers.2.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.2.fc1.weight', 'opt_model.model.decoder.layers.2.fc1.bias', 'opt_model.model.decoder.layers.2.fc2.weight', 'opt_model.model.decoder.layers.2.fc2.bias', 'opt_model.model.decoder.layers.2.final_layer_norm.weight', 'opt_model.model.decoder.layers.2.final_layer_norm.bias', 'opt_model.model.decoder.layers.3.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.3.fc1.weight', 'opt_model.model.decoder.layers.3.fc1.bias', 'opt_model.model.decoder.layers.3.fc2.weight', 'opt_model.model.decoder.layers.3.fc2.bias', 'opt_model.model.decoder.layers.3.final_layer_norm.weight', 'opt_model.model.decoder.layers.3.final_layer_norm.bias', 'opt_model.model.decoder.layers.4.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.4.fc1.weight', 'opt_model.model.decoder.layers.4.fc1.bias', 'opt_model.model.decoder.layers.4.fc2.weight', 'opt_model.model.decoder.layers.4.fc2.bias', 'opt_model.model.decoder.layers.4.final_layer_norm.weight', 'opt_model.model.decoder.layers.4.final_layer_norm.bias', 'opt_model.model.decoder.layers.5.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.5.fc1.weight', 'opt_model.model.decoder.layers.5.fc1.bias', 'opt_model.model.decoder.layers.5.fc2.weight', 'opt_model.model.decoder.layers.5.fc2.bias', 'opt_model.model.decoder.layers.5.final_layer_norm.weight', 'opt_model.model.decoder.layers.5.final_layer_norm.bias', 'opt_model.model.decoder.layers.6.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.6.fc1.weight', 'opt_model.model.decoder.layers.6.fc1.bias', 'opt_model.model.decoder.layers.6.fc2.weight', 'opt_model.model.decoder.layers.6.fc2.bias', 'opt_model.model.decoder.layers.6.final_layer_norm.weight', 'opt_model.model.decoder.layers.6.final_layer_norm.bias', 'opt_model.model.decoder.layers.7.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.7.fc1.weight', 'opt_model.model.decoder.layers.7.fc1.bias', 'opt_model.model.decoder.layers.7.fc2.weight', 'opt_model.model.decoder.layers.7.fc2.bias', 'opt_model.model.decoder.layers.7.final_layer_norm.weight', 'opt_model.model.decoder.layers.7.final_layer_norm.bias', 'opt_model.model.decoder.layers.8.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.8.fc1.weight', 'opt_model.model.decoder.layers.8.fc1.bias', 'opt_model.model.decoder.layers.8.fc2.weight', 'opt_model.model.decoder.layers.8.fc2.bias', 'opt_model.model.decoder.layers.8.final_layer_norm.weight', 'opt_model.model.decoder.layers.8.final_layer_norm.bias', 'opt_model.model.decoder.layers.9.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.9.fc1.weight', 'opt_model.model.decoder.layers.9.fc1.bias', 'opt_model.model.decoder.layers.9.fc2.weight', 'opt_model.model.decoder.layers.9.fc2.bias', 'opt_model.model.decoder.layers.9.final_layer_norm.weight', 'opt_model.model.decoder.layers.9.final_layer_norm.bias', 'opt_model.model.decoder.layers.10.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.10.fc1.weight', 'opt_model.model.decoder.layers.10.fc1.bias', 'opt_model.model.decoder.layers.10.fc2.weight', 'opt_model.model.decoder.layers.10.fc2.bias', 'opt_model.model.decoder.layers.10.final_layer_norm.weight', 'opt_model.model.decoder.layers.10.final_layer_norm.bias', 'opt_model.model.decoder.layers.11.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.11.fc1.weight', 'opt_model.model.decoder.layers.11.fc1.bias', 'opt_model.model.decoder.layers.11.fc2.weight', 'opt_model.model.decoder.layers.11.fc2.bias', 'opt_model.model.decoder.layers.11.final_layer_norm.weight', 'opt_model.model.decoder.layers.11.final_layer_norm.bias', 'opt_model.model.decoder.layers.12.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.12.fc1.weight', 'opt_model.model.decoder.layers.12.fc1.bias', 'opt_model.model.decoder.layers.12.fc2.weight', 'opt_model.model.decoder.layers.12.fc2.bias', 'opt_model.model.decoder.layers.12.final_layer_norm.weight', 'opt_model.model.decoder.layers.12.final_layer_norm.bias', 'opt_model.model.decoder.layers.13.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.13.fc1.weight', 'opt_model.model.decoder.layers.13.fc1.bias', 'opt_model.model.decoder.layers.13.fc2.weight', 'opt_model.model.decoder.layers.13.fc2.bias', 'opt_model.model.decoder.layers.13.final_layer_norm.weight', 'opt_model.model.decoder.layers.13.final_layer_norm.bias', 'opt_model.model.decoder.layers.14.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.14.fc1.weight', 'opt_model.model.decoder.layers.14.fc1.bias', 'opt_model.model.decoder.layers.14.fc2.weight', 'opt_model.model.decoder.layers.14.fc2.bias', 'opt_model.model.decoder.layers.14.final_layer_norm.weight', 'opt_model.model.decoder.layers.14.final_layer_norm.bias', 'opt_model.model.decoder.layers.15.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.15.fc1.weight', 'opt_model.model.decoder.layers.15.fc1.bias', 'opt_model.model.decoder.layers.15.fc2.weight', 'opt_model.model.decoder.layers.15.fc2.bias', 'opt_model.model.decoder.layers.15.final_layer_norm.weight', 'opt_model.model.decoder.layers.15.final_layer_norm.bias', 'opt_model.model.decoder.layers.16.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.16.fc1.weight', 'opt_model.model.decoder.layers.16.fc1.bias', 'opt_model.model.decoder.layers.16.fc2.weight', 'opt_model.model.decoder.layers.16.fc2.bias', 'opt_model.model.decoder.layers.16.final_layer_norm.weight', 'opt_model.model.decoder.layers.16.final_layer_norm.bias', 'opt_model.model.decoder.layers.17.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.17.fc1.weight', 'opt_model.model.decoder.layers.17.fc1.bias', 'opt_model.model.decoder.layers.17.fc2.weight', 'opt_model.model.decoder.layers.17.fc2.bias', 'opt_model.model.decoder.layers.17.final_layer_norm.weight', 'opt_model.model.decoder.layers.17.final_layer_norm.bias', 'opt_model.model.decoder.layers.18.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.18.fc1.weight', 'opt_model.model.decoder.layers.18.fc1.bias', 'opt_model.model.decoder.layers.18.fc2.weight', 'opt_model.model.decoder.layers.18.fc2.bias', 'opt_model.model.decoder.layers.18.final_layer_norm.weight', 'opt_model.model.decoder.layers.18.final_layer_norm.bias', 'opt_model.model.decoder.layers.19.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.19.fc1.weight', 'opt_model.model.decoder.layers.19.fc1.bias', 'opt_model.model.decoder.layers.19.fc2.weight', 'opt_model.model.decoder.layers.19.fc2.bias', 'opt_model.model.decoder.layers.19.final_layer_norm.weight', 'opt_model.model.decoder.layers.19.final_layer_norm.bias', 'opt_model.model.decoder.layers.20.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.20.fc1.weight', 'opt_model.model.decoder.layers.20.fc1.bias', 'opt_model.model.decoder.layers.20.fc2.weight', 'opt_model.model.decoder.layers.20.fc2.bias', 'opt_model.model.decoder.layers.20.final_layer_norm.weight', 'opt_model.model.decoder.layers.20.final_layer_norm.bias', 'opt_model.model.decoder.layers.21.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.21.fc1.weight', 'opt_model.model.decoder.layers.21.fc1.bias', 'opt_model.model.decoder.layers.21.fc2.weight', 'opt_model.model.decoder.layers.21.fc2.bias', 'opt_model.model.decoder.layers.21.final_layer_norm.weight', 'opt_model.model.decoder.layers.21.final_layer_norm.bias', 'opt_model.model.decoder.layers.22.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.22.fc1.weight', 'opt_model.model.decoder.layers.22.fc1.bias', 'opt_model.model.decoder.layers.22.fc2.weight', 'opt_model.model.decoder.layers.22.fc2.bias', 'opt_model.model.decoder.layers.22.final_layer_norm.weight', 'opt_model.model.decoder.layers.22.final_layer_norm.bias', 'opt_model.model.decoder.layers.23.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.23.fc1.weight', 'opt_model.model.decoder.layers.23.fc1.bias', 'opt_model.model.decoder.layers.23.fc2.weight', 'opt_model.model.decoder.layers.23.fc2.bias', 'opt_model.model.decoder.layers.23.final_layer_norm.weight', 'opt_model.model.decoder.layers.23.final_layer_norm.bias', 'opt_model.model.decoder.layers.24.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.24.fc1.weight', 'opt_model.model.decoder.layers.24.fc1.bias', 'opt_model.model.decoder.layers.24.fc2.weight', 'opt_model.model.decoder.layers.24.fc2.bias', 'opt_model.model.decoder.layers.24.final_layer_norm.weight', 'opt_model.model.decoder.layers.24.final_layer_norm.bias', 'opt_model.model.decoder.layers.25.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.25.fc1.weight', 'opt_model.model.decoder.layers.25.fc1.bias', 'opt_model.model.decoder.layers.25.fc2.weight', 'opt_model.model.decoder.layers.25.fc2.bias', 'opt_model.model.decoder.layers.25.final_layer_norm.weight', 'opt_model.model.decoder.layers.25.final_layer_norm.bias', 'opt_model.model.decoder.layers.26.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.26.fc1.weight', 'opt_model.model.decoder.layers.26.fc1.bias', 'opt_model.model.decoder.layers.26.fc2.weight', 'opt_model.model.decoder.layers.26.fc2.bias', 'opt_model.model.decoder.layers.26.final_layer_norm.weight', 'opt_model.model.decoder.layers.26.final_layer_norm.bias', 'opt_model.model.decoder.layers.27.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.27.fc1.weight', 'opt_model.model.decoder.layers.27.fc1.bias', 'opt_model.model.decoder.layers.27.fc2.weight', 'opt_model.model.decoder.layers.27.fc2.bias', 'opt_model.model.decoder.layers.27.final_layer_norm.weight', 'opt_model.model.decoder.layers.27.final_layer_norm.bias', 'opt_model.model.decoder.layers.28.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.28.fc1.weight', 'opt_model.model.decoder.layers.28.fc1.bias', 'opt_model.model.decoder.layers.28.fc2.weight', 'opt_model.model.decoder.layers.28.fc2.bias', 'opt_model.model.decoder.layers.28.final_layer_norm.weight', 'opt_model.model.decoder.layers.28.final_layer_norm.bias', 'opt_model.model.decoder.layers.29.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.29.fc1.weight', 'opt_model.model.decoder.layers.29.fc1.bias', 'opt_model.model.decoder.layers.29.fc2.weight', 'opt_model.model.decoder.layers.29.fc2.bias', 'opt_model.model.decoder.layers.29.final_layer_norm.weight', 'opt_model.model.decoder.layers.29.final_layer_norm.bias', 'opt_model.model.decoder.layers.30.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.30.fc1.weight', 'opt_model.model.decoder.layers.30.fc1.bias', 'opt_model.model.decoder.layers.30.fc2.weight', 'opt_model.model.decoder.layers.30.fc2.bias', 'opt_model.model.decoder.layers.30.final_layer_norm.weight', 'opt_model.model.decoder.layers.30.final_layer_norm.bias', 'opt_model.model.decoder.layers.31.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.31.fc1.weight', 'opt_model.model.decoder.layers.31.fc1.bias', 'opt_model.model.decoder.layers.31.fc2.weight', 'opt_model.model.decoder.layers.31.fc2.bias', 'opt_model.model.decoder.layers.31.final_layer_norm.weight', 'opt_model.model.decoder.layers.31.final_layer_norm.bias', 'opt_proj.weight', 'opt_proj.bias']
2023-04-20 22:12:32,890 [INFO] load checkpoint from /home/yiren/PreBLIP2_results/12m-5/checkpoint_4.pth
2023-04-20 22:12:32,893 [INFO] Start training
2023-04-20 22:12:37,190 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-04-20 22:12:37,190 [INFO] Loaded 4606464 records for train split from the dataset.
2023-04-20 22:12:37,190 [INFO] Loaded 5000 records for val split from the dataset.
2023-04-20 22:12:37,190 [INFO] Loaded 5000 records for test split from the dataset.
2023-04-20 22:12:37,201 [INFO] number of trainable parameters: 107133696
2023-04-20 22:12:37,202 [INFO] Start training epoch 0, 4498 iters per inner epoch.
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Train: data epoch: [0]  [   0/4498]  eta: 8:16:02  lr: 0.000001  loss: 5.4624  time: 6.6168  data: 0.0000  max mem: 36697
2023-04-20 22:12:43,830 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [  50/4498]  eta: 3:10:26  lr: 0.000003  loss: 4.4641  time: 2.5219  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 100/4498]  eta: 3:05:55  lr: 0.000006  loss: 4.2235  time: 2.5006  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 150/4498]  eta: 3:03:03  lr: 0.000008  loss: 3.7854  time: 2.5005  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 200/4498]  eta: 3:00:39  lr: 0.000011  loss: 3.7855  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 250/4498]  eta: 2:58:18  lr: 0.000013  loss: 3.3847  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 300/4498]  eta: 2:56:05  lr: 0.000016  loss: 3.5590  time: 2.5094  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 350/4498]  eta: 2:53:50  lr: 0.000018  loss: 3.4657  time: 2.5021  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 400/4498]  eta: 2:51:36  lr: 0.000021  loss: 3.3145  time: 2.5005  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 450/4498]  eta: 2:49:28  lr: 0.000023  loss: 3.3031  time: 2.5079  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 500/4498]  eta: 2:47:17  lr: 0.000026  loss: 3.1487  time: 2.4910  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 550/4498]  eta: 2:45:08  lr: 0.000028  loss: 3.3182  time: 2.5074  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 600/4498]  eta: 2:43:02  lr: 0.000031  loss: 3.1208  time: 2.5040  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 650/4498]  eta: 2:40:56  lr: 0.000033  loss: 3.4922  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 700/4498]  eta: 2:38:49  lr: 0.000036  loss: 2.9416  time: 2.5005  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 750/4498]  eta: 2:36:40  lr: 0.000038  loss: 3.1967  time: 2.4970  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 800/4498]  eta: 2:34:33  lr: 0.000041  loss: 3.2878  time: 2.5012  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 850/4498]  eta: 2:32:25  lr: 0.000043  loss: 3.1096  time: 2.4906  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 900/4498]  eta: 2:30:19  lr: 0.000046  loss: 3.1915  time: 2.4959  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [ 950/4498]  eta: 2:28:12  lr: 0.000048  loss: 3.0407  time: 2.4877  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1000/4498]  eta: 2:26:06  lr: 0.000051  loss: 3.1720  time: 2.5037  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1050/4498]  eta: 2:24:01  lr: 0.000053  loss: 3.2583  time: 2.5128  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1100/4498]  eta: 2:21:55  lr: 0.000055  loss: 3.0817  time: 2.5035  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1150/4498]  eta: 2:19:48  lr: 0.000058  loss: 3.1055  time: 2.4883  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1200/4498]  eta: 2:17:42  lr: 0.000060  loss: 3.0218  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1250/4498]  eta: 2:15:37  lr: 0.000063  loss: 3.0761  time: 2.4965  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1300/4498]  eta: 2:13:32  lr: 0.000065  loss: 2.9277  time: 2.5032  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1350/4498]  eta: 2:11:26  lr: 0.000068  loss: 2.9680  time: 2.5147  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1400/4498]  eta: 2:09:21  lr: 0.000070  loss: 3.0561  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1450/4498]  eta: 2:07:16  lr: 0.000073  loss: 3.0840  time: 2.5149  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1500/4498]  eta: 2:05:11  lr: 0.000075  loss: 3.3036  time: 2.5074  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1550/4498]  eta: 2:03:06  lr: 0.000078  loss: 2.8639  time: 2.5086  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1600/4498]  eta: 2:01:01  lr: 0.000080  loss: 2.9180  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1650/4498]  eta: 1:58:55  lr: 0.000083  loss: 3.1113  time: 2.5052  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1700/4498]  eta: 1:56:50  lr: 0.000085  loss: 3.0896  time: 2.4979  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1750/4498]  eta: 1:54:45  lr: 0.000088  loss: 3.0063  time: 2.5003  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1800/4498]  eta: 1:52:39  lr: 0.000090  loss: 2.9855  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1850/4498]  eta: 1:50:35  lr: 0.000093  loss: 3.0293  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1900/4498]  eta: 1:48:30  lr: 0.000095  loss: 3.0550  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [1950/4498]  eta: 1:46:24  lr: 0.000098  loss: 2.9747  time: 2.5118  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2000/4498]  eta: 1:44:19  lr: 0.000100  loss: 2.8733  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2050/4498]  eta: 1:42:13  lr: 0.000100  loss: 2.9836  time: 2.5089  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2100/4498]  eta: 1:40:08  lr: 0.000100  loss: 2.7259  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2150/4498]  eta: 1:38:03  lr: 0.000100  loss: 2.7955  time: 2.5040  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2200/4498]  eta: 1:35:58  lr: 0.000100  loss: 2.8990  time: 2.5121  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2250/4498]  eta: 1:33:52  lr: 0.000100  loss: 2.7980  time: 2.5046  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2300/4498]  eta: 1:31:47  lr: 0.000100  loss: 3.0399  time: 2.4973  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2350/4498]  eta: 1:29:41  lr: 0.000100  loss: 2.9746  time: 2.5050  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2400/4498]  eta: 1:27:36  lr: 0.000100  loss: 2.9225  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2450/4498]  eta: 1:25:30  lr: 0.000100  loss: 2.8632  time: 2.4999  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2500/4498]  eta: 1:23:25  lr: 0.000100  loss: 2.7607  time: 2.5100  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2550/4498]  eta: 1:21:20  lr: 0.000100  loss: 2.8616  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2600/4498]  eta: 1:19:14  lr: 0.000100  loss: 2.9040  time: 2.4963  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2650/4498]  eta: 1:17:09  lr: 0.000100  loss: 2.9782  time: 2.4988  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2700/4498]  eta: 1:15:04  lr: 0.000100  loss: 2.9972  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2750/4498]  eta: 1:12:59  lr: 0.000100  loss: 2.8970  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2800/4498]  eta: 1:10:53  lr: 0.000100  loss: 2.7722  time: 2.5063  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2850/4498]  eta: 1:08:48  lr: 0.000100  loss: 3.2948  time: 2.5022  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2900/4498]  eta: 1:06:43  lr: 0.000100  loss: 3.1680  time: 2.5157  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [2950/4498]  eta: 1:04:38  lr: 0.000100  loss: 3.0263  time: 2.5058  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3000/4498]  eta: 1:02:33  lr: 0.000100  loss: 2.9196  time: 2.5097  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3050/4498]  eta: 1:00:27  lr: 0.000100  loss: 2.8151  time: 2.5096  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3100/4498]  eta: 0:58:22  lr: 0.000100  loss: 2.8641  time: 2.5068  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3150/4498]  eta: 0:56:17  lr: 0.000100  loss: 2.8328  time: 2.5137  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3200/4498]  eta: 0:54:12  lr: 0.000100  loss: 2.8917  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3250/4498]  eta: 0:52:06  lr: 0.000100  loss: 2.8630  time: 2.5010  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3300/4498]  eta: 0:50:01  lr: 0.000100  loss: 2.8475  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3350/4498]  eta: 0:47:56  lr: 0.000100  loss: 2.9275  time: 2.5096  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3400/4498]  eta: 0:45:51  lr: 0.000100  loss: 2.9342  time: 2.5087  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3450/4498]  eta: 0:43:45  lr: 0.000100  loss: 3.0103  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3500/4498]  eta: 0:41:40  lr: 0.000100  loss: 2.9428  time: 2.5152  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3550/4498]  eta: 0:39:35  lr: 0.000100  loss: 2.7321  time: 2.5049  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3600/4498]  eta: 0:37:30  lr: 0.000100  loss: 3.1215  time: 2.5182  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3650/4498]  eta: 0:35:24  lr: 0.000100  loss: 2.8987  time: 2.5074  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3700/4498]  eta: 0:33:19  lr: 0.000100  loss: 2.8433  time: 2.5090  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3750/4498]  eta: 0:31:14  lr: 0.000100  loss: 2.9233  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3800/4498]  eta: 0:29:08  lr: 0.000100  loss: 2.7967  time: 2.4923  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3850/4498]  eta: 0:27:03  lr: 0.000100  loss: 2.7461  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3900/4498]  eta: 0:24:58  lr: 0.000100  loss: 2.8585  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [3950/4498]  eta: 0:22:53  lr: 0.000100  loss: 2.7164  time: 2.4986  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4000/4498]  eta: 0:20:47  lr: 0.000100  loss: 2.7835  time: 2.4993  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4050/4498]  eta: 0:18:42  lr: 0.000100  loss: 2.9221  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4100/4498]  eta: 0:16:37  lr: 0.000100  loss: 2.7608  time: 2.4959  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4150/4498]  eta: 0:14:31  lr: 0.000100  loss: 2.8438  time: 2.4895  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4200/4498]  eta: 0:12:26  lr: 0.000100  loss: 2.7638  time: 2.4988  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4250/4498]  eta: 0:10:21  lr: 0.000100  loss: 2.8612  time: 2.5042  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4300/4498]  eta: 0:08:16  lr: 0.000100  loss: 2.9663  time: 2.5043  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4350/4498]  eta: 0:06:10  lr: 0.000100  loss: 2.9699  time: 2.4866  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4400/4498]  eta: 0:04:05  lr: 0.000100  loss: 2.8625  time: 2.5031  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4450/4498]  eta: 0:02:00  lr: 0.000100  loss: 2.7301  time: 2.4930  data: 0.0000  max mem: 37981
Train: data epoch: [0]  [4497/4498]  eta: 0:00:02  lr: 0.000100  loss: 3.0184  time: 2.5664  data: 0.0000  max mem: 37981
Train: data epoch: [0] Total time: 3:07:48 (2.5053 s / it)
2023-04-21 01:20:26,044 [INFO] Averaged stats: lr: 0.0001  loss: 3.0541
2023-04-21 01:20:26,045 [INFO] No validation splits found.
2023-04-21 01:20:26,062 [INFO] Saving checkpoint at epoch 0 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_0.pth.
2023-04-21 01:20:27,664 [INFO] Start training
2023-04-21 01:20:27,684 [INFO] Start training epoch 1, 4498 iters per inner epoch.
Train: data epoch: [1]  [   0/4498]  eta: 7:28:59  lr: 0.000098  loss: 2.7050  time: 5.9892  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [  50/4498]  eta: 3:10:23  lr: 0.000098  loss: 3.1633  time: 2.5025  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 100/4498]  eta: 3:06:09  lr: 0.000098  loss: 2.9861  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 150/4498]  eta: 3:03:22  lr: 0.000098  loss: 2.8340  time: 2.5142  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 200/4498]  eta: 3:00:57  lr: 0.000098  loss: 2.8744  time: 2.5189  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 250/4498]  eta: 2:58:35  lr: 0.000098  loss: 3.0944  time: 2.5063  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 300/4498]  eta: 2:56:15  lr: 0.000098  loss: 2.5678  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 350/4498]  eta: 2:54:03  lr: 0.000098  loss: 2.8965  time: 2.5151  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 400/4498]  eta: 2:51:49  lr: 0.000098  loss: 2.8564  time: 2.4950  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 450/4498]  eta: 2:49:44  lr: 0.000098  loss: 2.7446  time: 2.5202  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 500/4498]  eta: 2:47:35  lr: 0.000098  loss: 2.8194  time: 2.5105  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 550/4498]  eta: 2:45:27  lr: 0.000098  loss: 2.7132  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 600/4498]  eta: 2:43:18  lr: 0.000098  loss: 2.6855  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 650/4498]  eta: 2:41:12  lr: 0.000098  loss: 2.7681  time: 2.5021  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 700/4498]  eta: 2:39:04  lr: 0.000098  loss: 2.8143  time: 2.5143  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 750/4498]  eta: 2:36:57  lr: 0.000098  loss: 2.9752  time: 2.5012  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 800/4498]  eta: 2:34:48  lr: 0.000098  loss: 2.9276  time: 2.5027  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 850/4498]  eta: 2:32:41  lr: 0.000098  loss: 2.9313  time: 2.5009  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 900/4498]  eta: 2:30:36  lr: 0.000098  loss: 2.6703  time: 2.5162  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [ 950/4498]  eta: 2:28:30  lr: 0.000098  loss: 2.9038  time: 2.5002  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1000/4498]  eta: 2:26:22  lr: 0.000098  loss: 2.7533  time: 2.4975  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1050/4498]  eta: 2:24:14  lr: 0.000098  loss: 2.9629  time: 2.5018  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1100/4498]  eta: 2:22:08  lr: 0.000098  loss: 2.8662  time: 2.4993  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1150/4498]  eta: 2:20:01  lr: 0.000098  loss: 2.9082  time: 2.5007  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1200/4498]  eta: 2:17:54  lr: 0.000098  loss: 2.7537  time: 2.5037  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1250/4498]  eta: 2:15:48  lr: 0.000098  loss: 2.9013  time: 2.5113  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1300/4498]  eta: 2:13:42  lr: 0.000098  loss: 2.9009  time: 2.4996  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1350/4498]  eta: 2:11:36  lr: 0.000098  loss: 2.8484  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1400/4498]  eta: 2:09:29  lr: 0.000098  loss: 2.9882  time: 2.5003  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1450/4498]  eta: 2:07:23  lr: 0.000098  loss: 2.6386  time: 2.4985  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1500/4498]  eta: 2:05:18  lr: 0.000098  loss: 2.9032  time: 2.5124  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1550/4498]  eta: 2:03:12  lr: 0.000098  loss: 2.7567  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1600/4498]  eta: 2:01:07  lr: 0.000098  loss: 2.5803  time: 2.5085  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1650/4498]  eta: 1:59:02  lr: 0.000098  loss: 2.7208  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1700/4498]  eta: 1:56:56  lr: 0.000098  loss: 2.9009  time: 2.5115  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1750/4498]  eta: 1:54:51  lr: 0.000098  loss: 2.9191  time: 2.5058  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1800/4498]  eta: 1:52:46  lr: 0.000098  loss: 2.6228  time: 2.5006  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1850/4498]  eta: 1:50:41  lr: 0.000098  loss: 2.6412  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1900/4498]  eta: 1:48:35  lr: 0.000098  loss: 2.7965  time: 2.5136  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [1950/4498]  eta: 1:46:30  lr: 0.000098  loss: 2.8187  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2000/4498]  eta: 1:44:25  lr: 0.000098  loss: 2.8966  time: 2.5109  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2050/4498]  eta: 1:42:19  lr: 0.000098  loss: 2.9983  time: 2.5142  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2100/4498]  eta: 1:40:14  lr: 0.000098  loss: 2.9148  time: 2.5008  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2150/4498]  eta: 1:38:08  lr: 0.000098  loss: 2.8300  time: 2.5040  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2200/4498]  eta: 1:36:03  lr: 0.000098  loss: 2.8600  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2250/4498]  eta: 1:33:57  lr: 0.000098  loss: 2.4354  time: 2.4977  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2300/4498]  eta: 1:31:52  lr: 0.000098  loss: 2.9275  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2350/4498]  eta: 1:29:46  lr: 0.000098  loss: 2.8235  time: 2.5017  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2400/4498]  eta: 1:27:40  lr: 0.000098  loss: 2.8003  time: 2.4962  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2450/4498]  eta: 1:25:35  lr: 0.000098  loss: 2.9687  time: 2.4992  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2500/4498]  eta: 1:23:29  lr: 0.000098  loss: 2.7936  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2550/4498]  eta: 1:21:24  lr: 0.000098  loss: 2.8129  time: 2.5041  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2600/4498]  eta: 1:19:18  lr: 0.000098  loss: 2.4484  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2650/4498]  eta: 1:17:13  lr: 0.000098  loss: 2.7699  time: 2.5134  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2700/4498]  eta: 1:15:07  lr: 0.000098  loss: 2.6456  time: 2.4935  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2750/4498]  eta: 1:13:02  lr: 0.000098  loss: 2.7960  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2800/4498]  eta: 1:10:56  lr: 0.000098  loss: 2.8005  time: 2.5004  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2850/4498]  eta: 1:08:51  lr: 0.000098  loss: 2.6297  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2900/4498]  eta: 1:06:45  lr: 0.000098  loss: 2.7412  time: 2.5035  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [2950/4498]  eta: 1:04:40  lr: 0.000098  loss: 2.9162  time: 2.5079  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3000/4498]  eta: 1:02:35  lr: 0.000098  loss: 2.7778  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3050/4498]  eta: 1:00:29  lr: 0.000098  loss: 2.8912  time: 2.5083  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3100/4498]  eta: 0:58:24  lr: 0.000098  loss: 2.6278  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3150/4498]  eta: 0:56:19  lr: 0.000098  loss: 2.7050  time: 2.5196  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3200/4498]  eta: 0:54:14  lr: 0.000098  loss: 2.8031  time: 2.5220  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3250/4498]  eta: 0:52:09  lr: 0.000098  loss: 3.0589  time: 2.5125  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3300/4498]  eta: 0:50:03  lr: 0.000098  loss: 2.7538  time: 2.5256  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3350/4498]  eta: 0:47:58  lr: 0.000098  loss: 2.8147  time: 2.5099  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3400/4498]  eta: 0:45:53  lr: 0.000098  loss: 2.8452  time: 2.5099  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3450/4498]  eta: 0:43:48  lr: 0.000098  loss: 2.7963  time: 2.5147  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3500/4498]  eta: 0:41:42  lr: 0.000098  loss: 2.7978  time: 2.5182  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3550/4498]  eta: 0:39:37  lr: 0.000098  loss: 2.6702  time: 2.5292  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3600/4498]  eta: 0:37:32  lr: 0.000098  loss: 2.7799  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3650/4498]  eta: 0:35:26  lr: 0.000098  loss: 2.7584  time: 2.5032  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3700/4498]  eta: 0:33:21  lr: 0.000098  loss: 2.8351  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3750/4498]  eta: 0:31:16  lr: 0.000098  loss: 2.6425  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3800/4498]  eta: 0:29:10  lr: 0.000098  loss: 2.7637  time: 2.5049  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3850/4498]  eta: 0:27:05  lr: 0.000098  loss: 2.8478  time: 2.4918  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3900/4498]  eta: 0:24:59  lr: 0.000098  loss: 2.5147  time: 2.5030  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [3950/4498]  eta: 0:22:54  lr: 0.000098  loss: 2.7747  time: 2.5041  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4000/4498]  eta: 0:20:48  lr: 0.000098  loss: 2.6133  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4050/4498]  eta: 0:18:43  lr: 0.000098  loss: 2.6474  time: 2.4997  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4100/4498]  eta: 0:16:38  lr: 0.000098  loss: 2.7337  time: 2.5048  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4150/4498]  eta: 0:14:32  lr: 0.000098  loss: 2.7224  time: 2.5038  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4200/4498]  eta: 0:12:27  lr: 0.000098  loss: 2.5872  time: 2.4973  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4250/4498]  eta: 0:10:21  lr: 0.000098  loss: 3.0292  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4300/4498]  eta: 0:08:16  lr: 0.000098  loss: 2.7794  time: 2.4859  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4350/4498]  eta: 0:06:11  lr: 0.000098  loss: 2.7831  time: 2.5023  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4400/4498]  eta: 0:04:05  lr: 0.000098  loss: 2.8814  time: 2.4979  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4450/4498]  eta: 0:02:00  lr: 0.000098  loss: 2.6204  time: 2.5065  data: 0.0000  max mem: 37981
Train: data epoch: [1]  [4497/4498]  eta: 0:00:02  lr: 0.000098  loss: 2.7712  time: 2.5441  data: 0.0000  max mem: 37981
Train: data epoch: [1] Total time: 3:07:58 (2.5074 s / it)
2023-04-21 04:28:26,054 [INFO] Averaged stats: lr: 0.0001  loss: 2.8059
2023-04-21 04:28:26,057 [INFO] No validation splits found.
2023-04-21 04:28:26,076 [INFO] Saving checkpoint at epoch 1 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_1.pth.
2023-04-21 04:28:27,855 [INFO] Start training
2023-04-21 04:28:27,876 [INFO] Start training epoch 2, 4498 iters per inner epoch.
Train: data epoch: [2]  [   0/4498]  eta: 7:35:03  lr: 0.000091  loss: 2.6515  time: 6.0702  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [  50/4498]  eta: 3:10:27  lr: 0.000091  loss: 2.7603  time: 2.4945  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 100/4498]  eta: 3:06:02  lr: 0.000091  loss: 2.8451  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 150/4498]  eta: 3:03:10  lr: 0.000091  loss: 2.9151  time: 2.5020  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 200/4498]  eta: 3:00:41  lr: 0.000091  loss: 2.6875  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 250/4498]  eta: 2:58:23  lr: 0.000091  loss: 2.8121  time: 2.5014  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 300/4498]  eta: 2:56:12  lr: 0.000091  loss: 2.8659  time: 2.5091  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 350/4498]  eta: 2:54:03  lr: 0.000091  loss: 2.5181  time: 2.5138  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 400/4498]  eta: 2:51:56  lr: 0.000091  loss: 3.0524  time: 2.5119  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 450/4498]  eta: 2:49:47  lr: 0.000091  loss: 3.0395  time: 2.5137  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 500/4498]  eta: 2:47:36  lr: 0.000091  loss: 2.4774  time: 2.5046  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 550/4498]  eta: 2:45:29  lr: 0.000091  loss: 2.6839  time: 2.5138  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 600/4498]  eta: 2:43:20  lr: 0.000091  loss: 3.0037  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 650/4498]  eta: 2:41:12  lr: 0.000091  loss: 2.8760  time: 2.5142  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 700/4498]  eta: 2:39:07  lr: 0.000091  loss: 2.8618  time: 2.5206  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 750/4498]  eta: 2:37:01  lr: 0.000091  loss: 2.9156  time: 2.5083  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 800/4498]  eta: 2:34:56  lr: 0.000091  loss: 2.7143  time: 2.5257  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 850/4498]  eta: 2:32:50  lr: 0.000091  loss: 2.7552  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 900/4498]  eta: 2:30:43  lr: 0.000091  loss: 2.6466  time: 2.4970  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [ 950/4498]  eta: 2:28:36  lr: 0.000091  loss: 2.9154  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1000/4498]  eta: 2:26:28  lr: 0.000091  loss: 2.7566  time: 2.5044  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1050/4498]  eta: 2:24:20  lr: 0.000091  loss: 2.6764  time: 2.5068  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1100/4498]  eta: 2:22:13  lr: 0.000091  loss: 2.6913  time: 2.5092  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1150/4498]  eta: 2:20:07  lr: 0.000091  loss: 2.7147  time: 2.5044  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1200/4498]  eta: 2:18:00  lr: 0.000091  loss: 2.7310  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1250/4498]  eta: 2:15:54  lr: 0.000091  loss: 2.6956  time: 2.5037  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1300/4498]  eta: 2:13:48  lr: 0.000091  loss: 2.8856  time: 2.5040  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1350/4498]  eta: 2:11:42  lr: 0.000091  loss: 2.7441  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1400/4498]  eta: 2:09:36  lr: 0.000091  loss: 2.7474  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1450/4498]  eta: 2:07:30  lr: 0.000091  loss: 2.7082  time: 2.5177  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1500/4498]  eta: 2:05:24  lr: 0.000091  loss: 2.7709  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1550/4498]  eta: 2:03:18  lr: 0.000091  loss: 2.6572  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1600/4498]  eta: 2:01:13  lr: 0.000091  loss: 2.6178  time: 2.5153  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1650/4498]  eta: 1:59:07  lr: 0.000091  loss: 2.5612  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1700/4498]  eta: 1:57:01  lr: 0.000091  loss: 2.7404  time: 2.5340  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1750/4498]  eta: 1:54:55  lr: 0.000091  loss: 2.5423  time: 2.5086  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1800/4498]  eta: 1:52:49  lr: 0.000091  loss: 2.7036  time: 2.4945  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1850/4498]  eta: 1:50:43  lr: 0.000091  loss: 2.5366  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1900/4498]  eta: 1:48:37  lr: 0.000091  loss: 2.8412  time: 2.4974  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [1950/4498]  eta: 1:46:31  lr: 0.000091  loss: 2.7502  time: 2.4985  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2000/4498]  eta: 1:44:25  lr: 0.000091  loss: 2.9749  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2050/4498]  eta: 1:42:20  lr: 0.000091  loss: 2.6667  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2100/4498]  eta: 1:40:14  lr: 0.000091  loss: 2.8299  time: 2.4983  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2150/4498]  eta: 1:38:09  lr: 0.000091  loss: 2.6439  time: 2.4936  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2200/4498]  eta: 1:36:03  lr: 0.000091  loss: 2.8056  time: 2.5082  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2250/4498]  eta: 1:33:58  lr: 0.000091  loss: 2.7827  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2300/4498]  eta: 1:31:52  lr: 0.000091  loss: 2.6928  time: 2.5123  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2350/4498]  eta: 1:29:47  lr: 0.000091  loss: 2.6500  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2400/4498]  eta: 1:27:41  lr: 0.000091  loss: 2.6610  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2450/4498]  eta: 1:25:36  lr: 0.000091  loss: 2.7352  time: 2.5114  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2500/4498]  eta: 1:23:31  lr: 0.000091  loss: 2.8848  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2550/4498]  eta: 1:21:25  lr: 0.000091  loss: 2.7735  time: 2.4954  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2600/4498]  eta: 1:19:20  lr: 0.000091  loss: 2.8525  time: 2.5240  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2650/4498]  eta: 1:17:15  lr: 0.000091  loss: 2.8204  time: 2.5134  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2700/4498]  eta: 1:15:10  lr: 0.000091  loss: 2.6839  time: 2.5151  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2750/4498]  eta: 1:13:04  lr: 0.000091  loss: 2.8650  time: 2.5103  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2800/4498]  eta: 1:10:59  lr: 0.000091  loss: 2.6368  time: 2.5162  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2850/4498]  eta: 1:08:53  lr: 0.000091  loss: 2.7520  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2900/4498]  eta: 1:06:48  lr: 0.000091  loss: 2.7651  time: 2.4974  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [2950/4498]  eta: 1:04:43  lr: 0.000091  loss: 2.7198  time: 2.5195  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3000/4498]  eta: 1:02:37  lr: 0.000091  loss: 2.6976  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3050/4498]  eta: 1:00:31  lr: 0.000091  loss: 2.7027  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3100/4498]  eta: 0:58:26  lr: 0.000091  loss: 2.4776  time: 2.5144  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3150/4498]  eta: 0:56:21  lr: 0.000091  loss: 2.7133  time: 2.5200  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3200/4498]  eta: 0:54:15  lr: 0.000091  loss: 2.8042  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3250/4498]  eta: 0:52:10  lr: 0.000091  loss: 2.9579  time: 2.5033  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3300/4498]  eta: 0:50:04  lr: 0.000091  loss: 2.6659  time: 2.5055  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3350/4498]  eta: 0:47:59  lr: 0.000091  loss: 2.7553  time: 2.5038  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3400/4498]  eta: 0:45:53  lr: 0.000091  loss: 2.7362  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3450/4498]  eta: 0:43:48  lr: 0.000091  loss: 2.5504  time: 2.5043  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3500/4498]  eta: 0:41:43  lr: 0.000091  loss: 3.1309  time: 2.5109  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3550/4498]  eta: 0:39:37  lr: 0.000091  loss: 2.8538  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3600/4498]  eta: 0:37:32  lr: 0.000091  loss: 2.8122  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3650/4498]  eta: 0:35:26  lr: 0.000091  loss: 2.7656  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3700/4498]  eta: 0:33:21  lr: 0.000091  loss: 2.6911  time: 2.5021  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3750/4498]  eta: 0:31:16  lr: 0.000091  loss: 2.8894  time: 2.5020  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3800/4498]  eta: 0:29:10  lr: 0.000091  loss: 2.5817  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3850/4498]  eta: 0:27:05  lr: 0.000091  loss: 2.7207  time: 2.5036  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3900/4498]  eta: 0:24:59  lr: 0.000091  loss: 2.7224  time: 2.5100  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [3950/4498]  eta: 0:22:54  lr: 0.000091  loss: 3.0183  time: 2.5063  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4000/4498]  eta: 0:20:48  lr: 0.000091  loss: 2.5838  time: 2.5196  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4050/4498]  eta: 0:18:43  lr: 0.000091  loss: 2.7470  time: 2.5085  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4100/4498]  eta: 0:16:38  lr: 0.000091  loss: 2.6780  time: 2.5083  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4150/4498]  eta: 0:14:32  lr: 0.000091  loss: 2.6231  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4200/4498]  eta: 0:12:27  lr: 0.000091  loss: 2.9653  time: 2.5050  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4250/4498]  eta: 0:10:21  lr: 0.000091  loss: 2.4930  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4300/4498]  eta: 0:08:16  lr: 0.000091  loss: 2.6217  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4350/4498]  eta: 0:06:11  lr: 0.000091  loss: 2.8649  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4400/4498]  eta: 0:04:05  lr: 0.000091  loss: 2.6549  time: 2.5038  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4450/4498]  eta: 0:02:00  lr: 0.000091  loss: 2.4690  time: 2.5100  data: 0.0000  max mem: 37981
Train: data epoch: [2]  [4497/4498]  eta: 0:00:02  lr: 0.000091  loss: 2.7759  time: 2.5475  data: 0.0000  max mem: 37981
Train: data epoch: [2] Total time: 3:08:01 (2.5081 s / it)
2023-04-21 07:36:29,089 [INFO] Averaged stats: lr: 0.0001  loss: 2.7395
2023-04-21 07:36:29,091 [INFO] No validation splits found.
2023-04-21 07:36:29,109 [INFO] Saving checkpoint at epoch 2 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_2.pth.
2023-04-21 07:36:30,724 [INFO] Start training
2023-04-21 07:36:30,744 [INFO] Start training epoch 3, 4498 iters per inner epoch.
Train: data epoch: [3]  [   0/4498]  eta: 7:37:15  lr: 0.000081  loss: 2.7894  time: 6.0995  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [  50/4498]  eta: 3:11:26  lr: 0.000081  loss: 2.6093  time: 2.5141  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 100/4498]  eta: 3:06:29  lr: 0.000081  loss: 2.6609  time: 2.5006  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 150/4498]  eta: 3:03:29  lr: 0.000081  loss: 2.7072  time: 2.5136  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 200/4498]  eta: 3:00:57  lr: 0.000081  loss: 2.6854  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 250/4498]  eta: 2:58:37  lr: 0.000081  loss: 2.7459  time: 2.5161  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 300/4498]  eta: 2:56:24  lr: 0.000081  loss: 2.6852  time: 2.5118  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 350/4498]  eta: 2:54:11  lr: 0.000081  loss: 2.6488  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 400/4498]  eta: 2:51:57  lr: 0.000081  loss: 2.4678  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 450/4498]  eta: 2:49:46  lr: 0.000081  loss: 2.7864  time: 2.4970  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 500/4498]  eta: 2:47:37  lr: 0.000081  loss: 2.6883  time: 2.5145  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 550/4498]  eta: 2:45:31  lr: 0.000081  loss: 2.6177  time: 2.5099  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 600/4498]  eta: 2:43:24  lr: 0.000081  loss: 2.7599  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 650/4498]  eta: 2:41:16  lr: 0.000081  loss: 2.5856  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 700/4498]  eta: 2:39:09  lr: 0.000081  loss: 2.7553  time: 2.5124  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 750/4498]  eta: 2:37:04  lr: 0.000081  loss: 2.7567  time: 2.5218  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 800/4498]  eta: 2:34:58  lr: 0.000081  loss: 2.6238  time: 2.5167  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 850/4498]  eta: 2:32:51  lr: 0.000081  loss: 2.5499  time: 2.5108  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 900/4498]  eta: 2:30:45  lr: 0.000081  loss: 2.5294  time: 2.5008  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [ 950/4498]  eta: 2:28:37  lr: 0.000081  loss: 2.9002  time: 2.4971  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1000/4498]  eta: 2:26:30  lr: 0.000081  loss: 2.7588  time: 2.5156  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1050/4498]  eta: 2:24:24  lr: 0.000081  loss: 2.6477  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1100/4498]  eta: 2:22:18  lr: 0.000081  loss: 2.7364  time: 2.5136  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1150/4498]  eta: 2:20:11  lr: 0.000081  loss: 2.6675  time: 2.5029  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1200/4498]  eta: 2:18:06  lr: 0.000081  loss: 2.9219  time: 2.5111  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1250/4498]  eta: 2:16:00  lr: 0.000081  loss: 2.5519  time: 2.5109  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1300/4498]  eta: 2:13:54  lr: 0.000081  loss: 2.5964  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1350/4498]  eta: 2:11:47  lr: 0.000081  loss: 2.5843  time: 2.4993  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1400/4498]  eta: 2:09:41  lr: 0.000081  loss: 2.6081  time: 2.5084  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1450/4498]  eta: 2:07:35  lr: 0.000081  loss: 2.8162  time: 2.4989  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1500/4498]  eta: 2:05:28  lr: 0.000081  loss: 2.8625  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1550/4498]  eta: 2:03:22  lr: 0.000081  loss: 2.7756  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1600/4498]  eta: 2:01:15  lr: 0.000081  loss: 2.5939  time: 2.4945  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1650/4498]  eta: 1:59:10  lr: 0.000081  loss: 2.6924  time: 2.5224  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1700/4498]  eta: 1:57:04  lr: 0.000081  loss: 2.6748  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1750/4498]  eta: 1:54:58  lr: 0.000081  loss: 2.7641  time: 2.4979  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1800/4498]  eta: 1:52:52  lr: 0.000081  loss: 2.7855  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1850/4498]  eta: 1:50:46  lr: 0.000081  loss: 2.8429  time: 2.5179  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1900/4498]  eta: 1:48:41  lr: 0.000081  loss: 2.7156  time: 2.5119  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [1950/4498]  eta: 1:46:35  lr: 0.000081  loss: 2.7417  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2000/4498]  eta: 1:44:30  lr: 0.000081  loss: 2.8901  time: 2.5069  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2050/4498]  eta: 1:42:24  lr: 0.000081  loss: 2.6161  time: 2.5038  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2100/4498]  eta: 1:40:18  lr: 0.000081  loss: 2.6833  time: 2.4995  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2150/4498]  eta: 1:38:13  lr: 0.000081  loss: 2.7219  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2200/4498]  eta: 1:36:07  lr: 0.000081  loss: 2.9301  time: 2.5133  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2250/4498]  eta: 1:34:02  lr: 0.000081  loss: 2.7485  time: 2.5153  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2300/4498]  eta: 1:31:57  lr: 0.000081  loss: 2.7900  time: 2.5192  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2350/4498]  eta: 1:29:51  lr: 0.000081  loss: 2.6025  time: 2.5145  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2400/4498]  eta: 1:27:46  lr: 0.000081  loss: 2.4514  time: 2.5157  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2450/4498]  eta: 1:25:41  lr: 0.000081  loss: 2.7247  time: 2.5097  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2500/4498]  eta: 1:23:35  lr: 0.000081  loss: 2.6516  time: 2.4991  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2550/4498]  eta: 1:21:30  lr: 0.000081  loss: 2.7563  time: 2.5252  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2600/4498]  eta: 1:19:24  lr: 0.000081  loss: 2.6535  time: 2.5156  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2650/4498]  eta: 1:17:19  lr: 0.000081  loss: 2.5857  time: 2.5182  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2700/4498]  eta: 1:15:14  lr: 0.000081  loss: 2.7145  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2750/4498]  eta: 1:13:08  lr: 0.000081  loss: 2.6118  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2800/4498]  eta: 1:11:03  lr: 0.000081  loss: 2.8071  time: 2.5139  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2850/4498]  eta: 1:08:57  lr: 0.000081  loss: 2.8612  time: 2.5174  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2900/4498]  eta: 1:06:52  lr: 0.000081  loss: 2.5881  time: 2.5022  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [2950/4498]  eta: 1:04:46  lr: 0.000081  loss: 2.3388  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3000/4498]  eta: 1:02:41  lr: 0.000081  loss: 2.6189  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3050/4498]  eta: 1:00:35  lr: 0.000081  loss: 2.6215  time: 2.5233  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3100/4498]  eta: 0:58:30  lr: 0.000081  loss: 2.6556  time: 2.5158  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3150/4498]  eta: 0:56:24  lr: 0.000081  loss: 2.9109  time: 2.5042  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3200/4498]  eta: 0:54:19  lr: 0.000081  loss: 2.6219  time: 2.5117  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3250/4498]  eta: 0:52:13  lr: 0.000081  loss: 2.6821  time: 2.5177  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3300/4498]  eta: 0:50:08  lr: 0.000081  loss: 2.8430  time: 2.5156  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3350/4498]  eta: 0:48:02  lr: 0.000081  loss: 2.6741  time: 2.5108  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3400/4498]  eta: 0:45:57  lr: 0.000081  loss: 2.7124  time: 2.5018  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3450/4498]  eta: 0:43:51  lr: 0.000081  loss: 2.6698  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3500/4498]  eta: 0:41:45  lr: 0.000081  loss: 2.6892  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3550/4498]  eta: 0:39:40  lr: 0.000081  loss: 2.6918  time: 2.5062  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3600/4498]  eta: 0:37:34  lr: 0.000081  loss: 2.5909  time: 2.5023  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3650/4498]  eta: 0:35:29  lr: 0.000081  loss: 2.6306  time: 2.4926  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3700/4498]  eta: 0:33:23  lr: 0.000081  loss: 2.5361  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3750/4498]  eta: 0:31:17  lr: 0.000081  loss: 2.6571  time: 2.4992  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3800/4498]  eta: 0:29:12  lr: 0.000081  loss: 2.6325  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3850/4498]  eta: 0:27:06  lr: 0.000081  loss: 2.5222  time: 2.5121  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3900/4498]  eta: 0:25:01  lr: 0.000081  loss: 2.7611  time: 2.4976  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [3950/4498]  eta: 0:22:55  lr: 0.000081  loss: 2.8888  time: 2.5022  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4000/4498]  eta: 0:20:50  lr: 0.000081  loss: 2.7319  time: 2.5042  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4050/4498]  eta: 0:18:44  lr: 0.000081  loss: 2.8323  time: 2.5130  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4100/4498]  eta: 0:16:39  lr: 0.000081  loss: 2.6389  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4150/4498]  eta: 0:14:33  lr: 0.000081  loss: 2.5552  time: 2.5095  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4200/4498]  eta: 0:12:27  lr: 0.000081  loss: 2.5900  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4250/4498]  eta: 0:10:22  lr: 0.000081  loss: 2.7133  time: 2.4988  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4300/4498]  eta: 0:08:16  lr: 0.000081  loss: 2.8028  time: 2.5049  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4350/4498]  eta: 0:06:11  lr: 0.000081  loss: 2.6513  time: 2.5051  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4400/4498]  eta: 0:04:05  lr: 0.000081  loss: 2.9216  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4450/4498]  eta: 0:02:00  lr: 0.000081  loss: 2.5784  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [3]  [4497/4498]  eta: 0:00:02  lr: 0.000081  loss: 2.6604  time: 2.5457  data: 0.0000  max mem: 37981
Train: data epoch: [3] Total time: 3:08:09 (2.5099 s / it)
2023-04-21 10:44:40,185 [INFO] Averaged stats: lr: 0.0001  loss: 2.6919
2023-04-21 10:44:40,187 [INFO] No validation splits found.
2023-04-21 10:44:40,206 [INFO] Saving checkpoint at epoch 3 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_3.pth.
2023-04-21 10:44:41,733 [INFO] Start training
2023-04-21 10:44:41,753 [INFO] Start training epoch 4, 4498 iters per inner epoch.
Train: data epoch: [4]  [   0/4498]  eta: 7:32:06  lr: 0.000069  loss: 2.5819  time: 6.0308  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [  50/4498]  eta: 3:10:36  lr: 0.000069  loss: 2.6603  time: 2.5062  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 100/4498]  eta: 3:06:18  lr: 0.000069  loss: 2.5630  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 150/4498]  eta: 3:03:27  lr: 0.000069  loss: 2.5767  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 200/4498]  eta: 3:00:54  lr: 0.000069  loss: 2.8039  time: 2.5128  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 250/4498]  eta: 2:58:31  lr: 0.000069  loss: 2.7442  time: 2.5031  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 300/4498]  eta: 2:56:11  lr: 0.000069  loss: 2.8731  time: 2.5002  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 350/4498]  eta: 2:54:00  lr: 0.000069  loss: 2.7697  time: 2.5119  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 400/4498]  eta: 2:51:52  lr: 0.000069  loss: 2.6861  time: 2.5124  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 450/4498]  eta: 2:49:43  lr: 0.000069  loss: 2.6952  time: 2.5109  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 500/4498]  eta: 2:47:33  lr: 0.000069  loss: 2.7538  time: 2.5041  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 550/4498]  eta: 2:45:25  lr: 0.000069  loss: 2.5833  time: 2.5055  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 600/4498]  eta: 2:43:18  lr: 0.000069  loss: 2.4937  time: 2.5127  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 650/4498]  eta: 2:41:11  lr: 0.000069  loss: 2.6380  time: 2.5065  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 700/4498]  eta: 2:39:07  lr: 0.000069  loss: 2.6113  time: 2.5152  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 750/4498]  eta: 2:37:00  lr: 0.000069  loss: 2.6919  time: 2.5079  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 800/4498]  eta: 2:34:53  lr: 0.000069  loss: 2.4659  time: 2.5127  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 850/4498]  eta: 2:32:47  lr: 0.000069  loss: 2.6965  time: 2.5223  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 900/4498]  eta: 2:30:39  lr: 0.000069  loss: 2.8753  time: 2.5023  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [ 950/4498]  eta: 2:28:34  lr: 0.000069  loss: 2.3639  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1000/4498]  eta: 2:26:28  lr: 0.000069  loss: 2.6072  time: 2.5095  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1050/4498]  eta: 2:24:22  lr: 0.000069  loss: 2.5469  time: 2.5000  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1100/4498]  eta: 2:22:16  lr: 0.000069  loss: 2.8649  time: 2.5192  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1150/4498]  eta: 2:20:10  lr: 0.000069  loss: 2.7051  time: 2.5129  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1200/4498]  eta: 2:18:04  lr: 0.000069  loss: 2.7843  time: 2.5078  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1250/4498]  eta: 2:15:58  lr: 0.000069  loss: 2.6127  time: 2.5083  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1300/4498]  eta: 2:13:52  lr: 0.000069  loss: 2.6665  time: 2.5126  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1350/4498]  eta: 2:11:45  lr: 0.000069  loss: 2.4721  time: 2.5008  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1400/4498]  eta: 2:09:40  lr: 0.000069  loss: 2.4532  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1450/4498]  eta: 2:07:33  lr: 0.000069  loss: 2.5740  time: 2.4993  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1500/4498]  eta: 2:05:27  lr: 0.000069  loss: 2.8005  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1550/4498]  eta: 2:03:21  lr: 0.000069  loss: 2.5878  time: 2.4879  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1600/4498]  eta: 2:01:15  lr: 0.000069  loss: 2.7103  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1650/4498]  eta: 1:59:09  lr: 0.000069  loss: 2.5606  time: 2.5092  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1700/4498]  eta: 1:57:04  lr: 0.000069  loss: 2.6637  time: 2.5090  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1750/4498]  eta: 1:54:58  lr: 0.000069  loss: 2.7044  time: 2.5058  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1800/4498]  eta: 1:52:52  lr: 0.000069  loss: 2.5884  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1850/4498]  eta: 1:50:46  lr: 0.000069  loss: 2.7266  time: 2.5036  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1900/4498]  eta: 1:48:40  lr: 0.000069  loss: 2.7001  time: 2.5018  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [1950/4498]  eta: 1:46:34  lr: 0.000069  loss: 2.4236  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2000/4498]  eta: 1:44:29  lr: 0.000069  loss: 2.8432  time: 2.5137  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2050/4498]  eta: 1:42:23  lr: 0.000069  loss: 2.2820  time: 2.5068  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2100/4498]  eta: 1:40:18  lr: 0.000069  loss: 2.8386  time: 2.5052  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2150/4498]  eta: 1:38:12  lr: 0.000069  loss: 2.5938  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2200/4498]  eta: 1:36:06  lr: 0.000069  loss: 2.8799  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2250/4498]  eta: 1:34:01  lr: 0.000069  loss: 2.3887  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2300/4498]  eta: 1:31:55  lr: 0.000069  loss: 2.6801  time: 2.5086  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2350/4498]  eta: 1:29:49  lr: 0.000069  loss: 2.6050  time: 2.5044  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2400/4498]  eta: 1:27:43  lr: 0.000069  loss: 2.6688  time: 2.5020  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2450/4498]  eta: 1:25:38  lr: 0.000069  loss: 2.6089  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2500/4498]  eta: 1:23:32  lr: 0.000069  loss: 2.6727  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2550/4498]  eta: 1:21:27  lr: 0.000069  loss: 2.4784  time: 2.5080  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2600/4498]  eta: 1:19:22  lr: 0.000069  loss: 2.8692  time: 2.5134  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2650/4498]  eta: 1:17:16  lr: 0.000069  loss: 2.7670  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2700/4498]  eta: 1:15:11  lr: 0.000069  loss: 2.5275  time: 2.5057  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2750/4498]  eta: 1:13:06  lr: 0.000069  loss: 2.5939  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2800/4498]  eta: 1:11:00  lr: 0.000069  loss: 2.5140  time: 2.5133  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2850/4498]  eta: 1:08:55  lr: 0.000069  loss: 2.5750  time: 2.5122  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2900/4498]  eta: 1:06:49  lr: 0.000069  loss: 2.5614  time: 2.5082  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [2950/4498]  eta: 1:04:44  lr: 0.000069  loss: 2.4493  time: 2.5141  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3000/4498]  eta: 1:02:38  lr: 0.000069  loss: 2.6296  time: 2.5087  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3050/4498]  eta: 1:00:33  lr: 0.000069  loss: 2.5220  time: 2.5135  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3100/4498]  eta: 0:58:28  lr: 0.000069  loss: 2.6204  time: 2.5149  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3150/4498]  eta: 0:56:22  lr: 0.000069  loss: 2.7190  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3200/4498]  eta: 0:54:17  lr: 0.000069  loss: 2.6488  time: 2.5299  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3250/4498]  eta: 0:52:11  lr: 0.000069  loss: 2.5345  time: 2.5051  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3300/4498]  eta: 0:50:06  lr: 0.000069  loss: 2.6344  time: 2.5143  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3350/4498]  eta: 0:48:00  lr: 0.000069  loss: 2.7161  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3400/4498]  eta: 0:45:55  lr: 0.000069  loss: 2.5146  time: 2.5154  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3450/4498]  eta: 0:43:50  lr: 0.000069  loss: 2.4449  time: 2.5171  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3500/4498]  eta: 0:41:44  lr: 0.000069  loss: 2.7881  time: 2.5169  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3550/4498]  eta: 0:39:39  lr: 0.000069  loss: 2.7171  time: 2.5090  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3600/4498]  eta: 0:37:33  lr: 0.000069  loss: 2.5915  time: 2.5133  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3650/4498]  eta: 0:35:28  lr: 0.000069  loss: 2.6155  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3700/4498]  eta: 0:33:22  lr: 0.000069  loss: 2.5383  time: 2.5018  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3750/4498]  eta: 0:31:17  lr: 0.000069  loss: 2.5579  time: 2.5038  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3800/4498]  eta: 0:29:11  lr: 0.000069  loss: 2.5573  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3850/4498]  eta: 0:27:06  lr: 0.000069  loss: 2.6410  time: 2.5029  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3900/4498]  eta: 0:25:00  lr: 0.000069  loss: 2.6315  time: 2.5116  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [3950/4498]  eta: 0:22:55  lr: 0.000069  loss: 2.6827  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4000/4498]  eta: 0:20:49  lr: 0.000069  loss: 2.7916  time: 2.5006  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4050/4498]  eta: 0:18:44  lr: 0.000069  loss: 2.5632  time: 2.5079  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4100/4498]  eta: 0:16:38  lr: 0.000069  loss: 2.6782  time: 2.5055  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4150/4498]  eta: 0:14:33  lr: 0.000069  loss: 2.4990  time: 2.4974  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4200/4498]  eta: 0:12:27  lr: 0.000069  loss: 2.5693  time: 2.5096  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4250/4498]  eta: 0:10:22  lr: 0.000069  loss: 2.6077  time: 2.5198  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4300/4498]  eta: 0:08:16  lr: 0.000069  loss: 2.6605  time: 2.5046  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4350/4498]  eta: 0:06:11  lr: 0.000069  loss: 2.6997  time: 2.5104  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4400/4498]  eta: 0:04:05  lr: 0.000069  loss: 2.5666  time: 2.5093  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4450/4498]  eta: 0:02:00  lr: 0.000069  loss: 2.6715  time: 2.5094  data: 0.0000  max mem: 37981
Train: data epoch: [4]  [4497/4498]  eta: 0:00:02  lr: 0.000069  loss: 2.8442  time: 2.5430  data: 0.0000  max mem: 37981
Train: data epoch: [4] Total time: 3:08:06 (2.5092 s / it)
2023-04-21 13:52:48,077 [INFO] Averaged stats: lr: 0.0001  loss: 2.6542
2023-04-21 13:52:48,079 [INFO] No validation splits found.
2023-04-21 13:52:48,097 [INFO] Saving checkpoint at epoch 4 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_4.pth.
2023-04-21 13:52:49,595 [INFO] Start training
2023-04-21 13:52:49,615 [INFO] Start training epoch 5, 4498 iters per inner epoch.
Train: data epoch: [5]  [   0/4498]  eta: 7:34:53  lr: 0.000055  loss: 2.5222  time: 6.0678  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [  50/4498]  eta: 3:10:16  lr: 0.000055  loss: 2.4572  time: 2.4986  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 100/4498]  eta: 3:05:57  lr: 0.000055  loss: 2.8538  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 150/4498]  eta: 3:03:02  lr: 0.000055  loss: 2.6903  time: 2.5023  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 200/4498]  eta: 3:00:38  lr: 0.000055  loss: 2.6201  time: 2.5113  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 250/4498]  eta: 2:58:22  lr: 0.000055  loss: 2.8456  time: 2.5141  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 300/4498]  eta: 2:56:07  lr: 0.000055  loss: 2.9190  time: 2.5000  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 350/4498]  eta: 2:53:54  lr: 0.000055  loss: 2.8420  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 400/4498]  eta: 2:51:45  lr: 0.000055  loss: 2.6541  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 450/4498]  eta: 2:49:36  lr: 0.000055  loss: 2.6952  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 500/4498]  eta: 2:47:28  lr: 0.000055  loss: 2.5903  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 550/4498]  eta: 2:45:19  lr: 0.000055  loss: 2.8596  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 600/4498]  eta: 2:43:10  lr: 0.000055  loss: 2.5484  time: 2.4993  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 650/4498]  eta: 2:41:05  lr: 0.000055  loss: 2.5994  time: 2.5127  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 700/4498]  eta: 2:38:58  lr: 0.000055  loss: 2.5191  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 750/4498]  eta: 2:36:52  lr: 0.000055  loss: 2.6336  time: 2.5012  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 800/4498]  eta: 2:34:45  lr: 0.000055  loss: 2.6096  time: 2.5080  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 850/4498]  eta: 2:32:40  lr: 0.000055  loss: 2.6691  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 900/4498]  eta: 2:30:34  lr: 0.000055  loss: 2.6561  time: 2.5102  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [ 950/4498]  eta: 2:28:27  lr: 0.000055  loss: 2.6219  time: 2.5084  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1000/4498]  eta: 2:26:20  lr: 0.000055  loss: 2.4310  time: 2.4994  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1050/4498]  eta: 2:24:14  lr: 0.000055  loss: 2.3940  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1100/4498]  eta: 2:22:07  lr: 0.000055  loss: 2.8400  time: 2.4941  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1150/4498]  eta: 2:20:02  lr: 0.000055  loss: 2.6011  time: 2.5091  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1200/4498]  eta: 2:17:56  lr: 0.000055  loss: 2.8129  time: 2.5158  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1250/4498]  eta: 2:15:51  lr: 0.000055  loss: 2.7857  time: 2.5099  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1300/4498]  eta: 2:13:45  lr: 0.000055  loss: 2.9239  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1350/4498]  eta: 2:11:39  lr: 0.000055  loss: 2.5329  time: 2.4997  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1400/4498]  eta: 2:09:33  lr: 0.000055  loss: 2.4368  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1450/4498]  eta: 2:07:27  lr: 0.000055  loss: 2.6978  time: 2.4985  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1500/4498]  eta: 2:05:22  lr: 0.000055  loss: 2.6379  time: 2.5096  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1550/4498]  eta: 2:03:17  lr: 0.000055  loss: 2.7199  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1600/4498]  eta: 2:01:11  lr: 0.000055  loss: 2.5176  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1650/4498]  eta: 1:59:04  lr: 0.000055  loss: 2.6733  time: 2.5013  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1700/4498]  eta: 1:56:59  lr: 0.000055  loss: 2.9840  time: 2.5026  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1750/4498]  eta: 1:54:52  lr: 0.000055  loss: 2.8235  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1800/4498]  eta: 1:52:47  lr: 0.000055  loss: 2.4839  time: 2.5100  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1850/4498]  eta: 1:50:42  lr: 0.000055  loss: 2.5593  time: 2.5094  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1900/4498]  eta: 1:48:36  lr: 0.000055  loss: 2.5769  time: 2.5075  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [1950/4498]  eta: 1:46:30  lr: 0.000055  loss: 2.5944  time: 2.5052  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2000/4498]  eta: 1:44:25  lr: 0.000055  loss: 2.5923  time: 2.5040  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2050/4498]  eta: 1:42:19  lr: 0.000055  loss: 2.7701  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2100/4498]  eta: 1:40:14  lr: 0.000055  loss: 2.5933  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2150/4498]  eta: 1:38:08  lr: 0.000055  loss: 2.5899  time: 2.5005  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2200/4498]  eta: 1:36:02  lr: 0.000055  loss: 2.7049  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2250/4498]  eta: 1:33:57  lr: 0.000055  loss: 2.4352  time: 2.5105  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2300/4498]  eta: 1:31:51  lr: 0.000055  loss: 2.6845  time: 2.5109  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2350/4498]  eta: 1:29:46  lr: 0.000055  loss: 2.4421  time: 2.4954  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2400/4498]  eta: 1:27:40  lr: 0.000055  loss: 2.2712  time: 2.5041  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2450/4498]  eta: 1:25:35  lr: 0.000055  loss: 2.5114  time: 2.5051  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2500/4498]  eta: 1:23:29  lr: 0.000055  loss: 2.6096  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2550/4498]  eta: 1:21:24  lr: 0.000055  loss: 2.6717  time: 2.5094  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2600/4498]  eta: 1:19:19  lr: 0.000055  loss: 2.6079  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2650/4498]  eta: 1:17:13  lr: 0.000055  loss: 2.7326  time: 2.5107  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2700/4498]  eta: 1:15:08  lr: 0.000055  loss: 2.4511  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2750/4498]  eta: 1:13:02  lr: 0.000055  loss: 2.7689  time: 2.4977  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2800/4498]  eta: 1:10:57  lr: 0.000055  loss: 2.7231  time: 2.5087  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2850/4498]  eta: 1:08:51  lr: 0.000055  loss: 2.5413  time: 2.5133  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2900/4498]  eta: 1:06:46  lr: 0.000055  loss: 2.7146  time: 2.5029  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [2950/4498]  eta: 1:04:41  lr: 0.000055  loss: 2.8530  time: 2.5007  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3000/4498]  eta: 1:02:35  lr: 0.000055  loss: 2.6827  time: 2.5083  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3050/4498]  eta: 1:00:30  lr: 0.000055  loss: 2.5564  time: 2.5122  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3100/4498]  eta: 0:58:25  lr: 0.000055  loss: 2.8051  time: 2.5130  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3150/4498]  eta: 0:56:19  lr: 0.000055  loss: 2.6361  time: 2.5158  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3200/4498]  eta: 0:54:14  lr: 0.000055  loss: 2.4695  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3250/4498]  eta: 0:52:09  lr: 0.000055  loss: 2.6107  time: 2.5063  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3300/4498]  eta: 0:50:03  lr: 0.000055  loss: 2.4796  time: 2.5152  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3350/4498]  eta: 0:47:58  lr: 0.000055  loss: 2.6992  time: 2.5130  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3400/4498]  eta: 0:45:53  lr: 0.000055  loss: 3.0043  time: 2.5113  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3450/4498]  eta: 0:43:47  lr: 0.000055  loss: 2.5612  time: 2.5031  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3500/4498]  eta: 0:41:42  lr: 0.000055  loss: 2.5702  time: 2.5123  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3550/4498]  eta: 0:39:37  lr: 0.000055  loss: 2.9424  time: 2.4976  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3600/4498]  eta: 0:37:31  lr: 0.000055  loss: 2.5842  time: 2.5011  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3650/4498]  eta: 0:35:26  lr: 0.000055  loss: 2.5766  time: 2.4986  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3700/4498]  eta: 0:33:20  lr: 0.000055  loss: 2.7775  time: 2.4978  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3750/4498]  eta: 0:31:15  lr: 0.000055  loss: 2.5359  time: 2.4998  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3800/4498]  eta: 0:29:10  lr: 0.000055  loss: 2.6457  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3850/4498]  eta: 0:27:04  lr: 0.000055  loss: 2.6166  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3900/4498]  eta: 0:24:59  lr: 0.000055  loss: 2.5842  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [3950/4498]  eta: 0:22:53  lr: 0.000055  loss: 2.5180  time: 2.4999  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4000/4498]  eta: 0:20:48  lr: 0.000055  loss: 2.4854  time: 2.5162  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4050/4498]  eta: 0:18:43  lr: 0.000055  loss: 2.3513  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4100/4498]  eta: 0:16:37  lr: 0.000055  loss: 2.6466  time: 2.5082  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4150/4498]  eta: 0:14:32  lr: 0.000055  loss: 2.5966  time: 2.5011  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4200/4498]  eta: 0:12:27  lr: 0.000055  loss: 2.6871  time: 2.5242  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4250/4498]  eta: 0:10:21  lr: 0.000055  loss: 2.6046  time: 2.5074  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4300/4498]  eta: 0:08:16  lr: 0.000055  loss: 2.7052  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4350/4498]  eta: 0:06:11  lr: 0.000055  loss: 2.6695  time: 2.5017  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4400/4498]  eta: 0:04:05  lr: 0.000055  loss: 2.6262  time: 2.5096  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4450/4498]  eta: 0:02:00  lr: 0.000055  loss: 2.3845  time: 2.5119  data: 0.0000  max mem: 37981
Train: data epoch: [5]  [4497/4498]  eta: 0:00:02  lr: 0.000055  loss: 2.4249  time: 2.5474  data: 0.0000  max mem: 37981
Train: data epoch: [5] Total time: 3:07:58 (2.5075 s / it)
2023-04-21 17:00:48,568 [INFO] Averaged stats: lr: 0.0001  loss: 2.6211
2023-04-21 17:00:48,570 [INFO] No validation splits found.
2023-04-21 17:00:48,589 [INFO] Saving checkpoint at epoch 5 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_5.pth.
2023-04-21 17:00:50,304 [INFO] Start training
2023-04-21 17:00:50,324 [INFO] Start training epoch 6, 4498 iters per inner epoch.
Train: data epoch: [6]  [   0/4498]  eta: 7:29:38  lr: 0.000041  loss: 2.4691  time: 5.9979  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [  50/4498]  eta: 3:10:41  lr: 0.000041  loss: 2.6021  time: 2.5051  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 100/4498]  eta: 3:06:13  lr: 0.000041  loss: 2.6486  time: 2.5085  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 150/4498]  eta: 3:03:19  lr: 0.000041  loss: 2.5581  time: 2.5079  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 200/4498]  eta: 3:01:00  lr: 0.000041  loss: 2.5530  time: 2.5193  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 250/4498]  eta: 2:58:38  lr: 0.000041  loss: 2.4204  time: 2.5168  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 300/4498]  eta: 2:56:25  lr: 0.000041  loss: 2.6680  time: 2.5161  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 350/4498]  eta: 2:54:10  lr: 0.000041  loss: 2.4990  time: 2.5103  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 400/4498]  eta: 2:51:59  lr: 0.000041  loss: 2.6150  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 450/4498]  eta: 2:49:50  lr: 0.000041  loss: 2.8531  time: 2.5108  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 500/4498]  eta: 2:47:42  lr: 0.000041  loss: 2.4542  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 550/4498]  eta: 2:45:32  lr: 0.000041  loss: 2.6292  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 600/4498]  eta: 2:43:29  lr: 0.000041  loss: 2.8053  time: 2.5187  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 650/4498]  eta: 2:41:21  lr: 0.000041  loss: 2.5684  time: 2.5119  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 700/4498]  eta: 2:39:12  lr: 0.000041  loss: 2.9559  time: 2.4992  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 750/4498]  eta: 2:37:06  lr: 0.000041  loss: 2.7650  time: 2.5155  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 800/4498]  eta: 2:35:01  lr: 0.000041  loss: 2.6724  time: 2.5197  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 850/4498]  eta: 2:32:54  lr: 0.000041  loss: 2.7271  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 900/4498]  eta: 2:30:47  lr: 0.000041  loss: 2.7072  time: 2.5035  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [ 950/4498]  eta: 2:28:40  lr: 0.000041  loss: 2.4409  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1000/4498]  eta: 2:26:33  lr: 0.000041  loss: 2.8469  time: 2.5123  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1050/4498]  eta: 2:24:26  lr: 0.000041  loss: 2.5107  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1100/4498]  eta: 2:22:18  lr: 0.000041  loss: 2.8274  time: 2.4950  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1150/4498]  eta: 2:20:11  lr: 0.000041  loss: 2.5124  time: 2.5030  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1200/4498]  eta: 2:18:05  lr: 0.000041  loss: 2.5881  time: 2.5052  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1250/4498]  eta: 2:15:59  lr: 0.000041  loss: 2.5262  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1300/4498]  eta: 2:13:53  lr: 0.000041  loss: 2.5406  time: 2.5052  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1350/4498]  eta: 2:11:46  lr: 0.000041  loss: 2.4919  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1400/4498]  eta: 2:09:40  lr: 0.000041  loss: 2.5554  time: 2.5130  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1450/4498]  eta: 2:07:33  lr: 0.000041  loss: 2.2817  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1500/4498]  eta: 2:05:27  lr: 0.000041  loss: 2.9303  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1550/4498]  eta: 2:03:21  lr: 0.000041  loss: 2.8245  time: 2.5123  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1600/4498]  eta: 2:01:16  lr: 0.000041  loss: 2.4137  time: 2.5063  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1650/4498]  eta: 1:59:10  lr: 0.000041  loss: 2.7748  time: 2.5042  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1700/4498]  eta: 1:57:04  lr: 0.000041  loss: 2.6726  time: 2.5099  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1750/4498]  eta: 1:54:58  lr: 0.000041  loss: 2.7250  time: 2.5124  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1800/4498]  eta: 1:52:53  lr: 0.000041  loss: 2.7590  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1850/4498]  eta: 1:50:47  lr: 0.000041  loss: 2.6352  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1900/4498]  eta: 1:48:41  lr: 0.000041  loss: 2.6257  time: 2.5115  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [1950/4498]  eta: 1:46:36  lr: 0.000041  loss: 2.7382  time: 2.5058  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2000/4498]  eta: 1:44:30  lr: 0.000041  loss: 2.7362  time: 2.5065  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2050/4498]  eta: 1:42:25  lr: 0.000041  loss: 2.6295  time: 2.5144  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2100/4498]  eta: 1:40:19  lr: 0.000041  loss: 2.5767  time: 2.5042  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2150/4498]  eta: 1:38:14  lr: 0.000041  loss: 2.5992  time: 2.5255  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2200/4498]  eta: 1:36:08  lr: 0.000041  loss: 2.7158  time: 2.5115  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2250/4498]  eta: 1:34:03  lr: 0.000041  loss: 2.5794  time: 2.5138  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2300/4498]  eta: 1:31:57  lr: 0.000041  loss: 2.4636  time: 2.5146  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2350/4498]  eta: 1:29:52  lr: 0.000041  loss: 2.7832  time: 2.5199  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2400/4498]  eta: 1:27:47  lr: 0.000041  loss: 2.5166  time: 2.5150  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2450/4498]  eta: 1:25:41  lr: 0.000041  loss: 2.5949  time: 2.5173  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2500/4498]  eta: 1:23:36  lr: 0.000041  loss: 2.7875  time: 2.5189  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2550/4498]  eta: 1:21:30  lr: 0.000041  loss: 2.7759  time: 2.5033  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2600/4498]  eta: 1:19:25  lr: 0.000041  loss: 2.6954  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2650/4498]  eta: 1:17:19  lr: 0.000041  loss: 2.5673  time: 2.5098  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2700/4498]  eta: 1:15:13  lr: 0.000041  loss: 2.5862  time: 2.5062  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2750/4498]  eta: 1:13:08  lr: 0.000041  loss: 2.6071  time: 2.5122  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2800/4498]  eta: 1:11:02  lr: 0.000041  loss: 2.6700  time: 2.5125  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2850/4498]  eta: 1:08:57  lr: 0.000041  loss: 2.3738  time: 2.5169  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2900/4498]  eta: 1:06:51  lr: 0.000041  loss: 2.4802  time: 2.5053  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [2950/4498]  eta: 1:04:46  lr: 0.000041  loss: 2.6959  time: 2.5108  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3000/4498]  eta: 1:02:40  lr: 0.000041  loss: 2.3873  time: 2.5022  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3050/4498]  eta: 1:00:35  lr: 0.000041  loss: 2.5808  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3100/4498]  eta: 0:58:29  lr: 0.000041  loss: 2.5281  time: 2.5095  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3150/4498]  eta: 0:56:24  lr: 0.000041  loss: 2.4475  time: 2.5127  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3200/4498]  eta: 0:54:18  lr: 0.000041  loss: 2.6896  time: 2.5115  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3250/4498]  eta: 0:52:13  lr: 0.000041  loss: 2.4827  time: 2.5092  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3300/4498]  eta: 0:50:07  lr: 0.000041  loss: 2.4113  time: 2.5121  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3350/4498]  eta: 0:48:02  lr: 0.000041  loss: 2.6759  time: 2.5033  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3400/4498]  eta: 0:45:56  lr: 0.000041  loss: 2.5989  time: 2.4992  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3450/4498]  eta: 0:43:50  lr: 0.000041  loss: 2.7015  time: 2.5045  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3500/4498]  eta: 0:41:45  lr: 0.000041  loss: 2.7360  time: 2.5105  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3550/4498]  eta: 0:39:39  lr: 0.000041  loss: 2.3611  time: 2.4916  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3600/4498]  eta: 0:37:34  lr: 0.000041  loss: 2.5815  time: 2.4997  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3650/4498]  eta: 0:35:28  lr: 0.000041  loss: 2.5847  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3700/4498]  eta: 0:33:23  lr: 0.000041  loss: 2.7234  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3750/4498]  eta: 0:31:17  lr: 0.000041  loss: 2.5557  time: 2.5096  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3800/4498]  eta: 0:29:12  lr: 0.000041  loss: 2.4798  time: 2.4966  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3850/4498]  eta: 0:27:06  lr: 0.000041  loss: 2.5142  time: 2.5068  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3900/4498]  eta: 0:25:01  lr: 0.000041  loss: 2.7431  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [3950/4498]  eta: 0:22:55  lr: 0.000041  loss: 2.4870  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4000/4498]  eta: 0:20:50  lr: 0.000041  loss: 2.6452  time: 2.5112  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4050/4498]  eta: 0:18:44  lr: 0.000041  loss: 2.4939  time: 2.5126  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4100/4498]  eta: 0:16:39  lr: 0.000041  loss: 2.6030  time: 2.5179  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4150/4498]  eta: 0:14:33  lr: 0.000041  loss: 2.4790  time: 2.5192  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4200/4498]  eta: 0:12:28  lr: 0.000041  loss: 2.5381  time: 2.5162  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4250/4498]  eta: 0:10:22  lr: 0.000041  loss: 2.7041  time: 2.5171  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4300/4498]  eta: 0:08:17  lr: 0.000041  loss: 2.4850  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4350/4498]  eta: 0:06:11  lr: 0.000041  loss: 2.6139  time: 2.5152  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4400/4498]  eta: 0:04:06  lr: 0.000041  loss: 2.8569  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4450/4498]  eta: 0:02:00  lr: 0.000041  loss: 2.6960  time: 2.5057  data: 0.0000  max mem: 37981
Train: data epoch: [6]  [4497/4498]  eta: 0:00:02  lr: 0.000041  loss: 2.4900  time: 2.5487  data: 0.0000  max mem: 37981
Train: data epoch: [6] Total time: 3:08:13 (2.5107 s / it)
2023-04-21 20:09:03,488 [INFO] Averaged stats: lr: 0.0000  loss: 2.5916
2023-04-21 20:09:03,491 [INFO] No validation splits found.
2023-04-21 20:09:03,510 [INFO] Saving checkpoint at epoch 6 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_6.pth.
2023-04-21 20:09:05,016 [INFO] Start training
2023-04-21 20:09:05,037 [INFO] Start training epoch 7, 4498 iters per inner epoch.
Train: data epoch: [7]  [   0/4498]  eta: 7:25:25  lr: 0.000029  loss: 2.7341  time: 5.9415  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [  50/4498]  eta: 3:10:58  lr: 0.000029  loss: 2.6248  time: 2.5127  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 100/4498]  eta: 3:06:20  lr: 0.000029  loss: 2.6615  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 150/4498]  eta: 3:03:23  lr: 0.000029  loss: 2.2059  time: 2.5086  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 200/4498]  eta: 3:00:55  lr: 0.000029  loss: 2.5150  time: 2.5198  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 250/4498]  eta: 2:58:33  lr: 0.000029  loss: 2.6941  time: 2.5080  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 300/4498]  eta: 2:56:21  lr: 0.000029  loss: 2.6733  time: 2.5190  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 350/4498]  eta: 2:54:10  lr: 0.000029  loss: 2.4793  time: 2.5127  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 400/4498]  eta: 2:51:59  lr: 0.000029  loss: 2.6618  time: 2.5122  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 450/4498]  eta: 2:49:46  lr: 0.000029  loss: 2.5851  time: 2.5022  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 500/4498]  eta: 2:47:42  lr: 0.000029  loss: 2.2538  time: 2.5291  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 550/4498]  eta: 2:45:35  lr: 0.000029  loss: 2.6721  time: 2.5141  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 600/4498]  eta: 2:43:28  lr: 0.000029  loss: 2.5581  time: 2.5115  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 650/4498]  eta: 2:41:19  lr: 0.000029  loss: 2.5425  time: 2.5114  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 700/4498]  eta: 2:39:11  lr: 0.000029  loss: 2.5161  time: 2.5013  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 750/4498]  eta: 2:37:03  lr: 0.000029  loss: 2.4012  time: 2.5008  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 800/4498]  eta: 2:34:57  lr: 0.000029  loss: 2.3490  time: 2.5074  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 850/4498]  eta: 2:32:51  lr: 0.000029  loss: 2.6271  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 900/4498]  eta: 2:30:44  lr: 0.000029  loss: 2.5044  time: 2.5122  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [ 950/4498]  eta: 2:28:37  lr: 0.000029  loss: 2.4283  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1000/4498]  eta: 2:26:31  lr: 0.000029  loss: 2.5300  time: 2.5144  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1050/4498]  eta: 2:24:24  lr: 0.000029  loss: 2.4111  time: 2.5087  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1100/4498]  eta: 2:22:17  lr: 0.000029  loss: 2.5273  time: 2.5017  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1150/4498]  eta: 2:20:11  lr: 0.000029  loss: 2.7652  time: 2.5166  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1200/4498]  eta: 2:18:05  lr: 0.000029  loss: 2.6429  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1250/4498]  eta: 2:15:59  lr: 0.000029  loss: 2.7687  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1300/4498]  eta: 2:13:54  lr: 0.000029  loss: 2.5509  time: 2.5139  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1350/4498]  eta: 2:11:48  lr: 0.000029  loss: 2.2750  time: 2.5105  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1400/4498]  eta: 2:09:41  lr: 0.000029  loss: 2.8178  time: 2.5031  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1450/4498]  eta: 2:07:35  lr: 0.000029  loss: 2.3544  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1500/4498]  eta: 2:05:28  lr: 0.000029  loss: 2.5856  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1550/4498]  eta: 2:03:22  lr: 0.000029  loss: 2.4115  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1600/4498]  eta: 2:01:16  lr: 0.000029  loss: 2.5010  time: 2.4959  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1650/4498]  eta: 1:59:10  lr: 0.000029  loss: 2.5094  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1700/4498]  eta: 1:57:04  lr: 0.000029  loss: 2.3364  time: 2.5011  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1750/4498]  eta: 1:54:58  lr: 0.000029  loss: 2.6651  time: 2.4973  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1800/4498]  eta: 1:52:52  lr: 0.000029  loss: 2.4471  time: 2.5021  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1850/4498]  eta: 1:50:46  lr: 0.000029  loss: 2.5398  time: 2.5110  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1900/4498]  eta: 1:48:40  lr: 0.000029  loss: 2.6470  time: 2.5125  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [1950/4498]  eta: 1:46:35  lr: 0.000029  loss: 2.9179  time: 2.5142  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2000/4498]  eta: 1:44:30  lr: 0.000029  loss: 2.5424  time: 2.5144  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2050/4498]  eta: 1:42:25  lr: 0.000029  loss: 2.5305  time: 2.5101  data: 0.0000  max mem: 37981

cdcTrain: data epoch: [7]  [2100/4498]  eta: 1:40:19  lr: 0.000029  loss: 2.3618  time: 2.5120  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2150/4498]  eta: 1:38:14  lr: 0.000029  loss: 2.5383  time: 2.5278  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2200/4498]  eta: 1:36:08  lr: 0.000029  loss: 2.5768  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2250/4498]  eta: 1:34:03  lr: 0.000029  loss: 2.4841  time: 2.5092  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2300/4498]  eta: 1:31:58  lr: 0.000029  loss: 2.6392  time: 2.5221  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2350/4498]  eta: 1:29:52  lr: 0.000029  loss: 2.6740  time: 2.5057  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2400/4498]  eta: 1:27:46  lr: 0.000029  loss: 2.7049  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2450/4498]  eta: 1:25:41  lr: 0.000029  loss: 2.4083  time: 2.5125  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2500/4498]  eta: 1:23:35  lr: 0.000029  loss: 2.5328  time: 2.5057  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2550/4498]  eta: 1:21:29  lr: 0.000029  loss: 2.6248  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2600/4498]  eta: 1:19:24  lr: 0.000029  loss: 2.6418  time: 2.5161  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2650/4498]  eta: 1:17:19  lr: 0.000029  loss: 2.6708  time: 2.5250  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2700/4498]  eta: 1:15:13  lr: 0.000029  loss: 2.5575  time: 2.5186  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2750/4498]  eta: 1:13:08  lr: 0.000029  loss: 2.8937  time: 2.5017  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2800/4498]  eta: 1:11:02  lr: 0.000029  loss: 2.3814  time: 2.5154  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2850/4498]  eta: 1:08:57  lr: 0.000029  loss: 2.5242  time: 2.5091  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2900/4498]  eta: 1:06:51  lr: 0.000029  loss: 2.5414  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [2950/4498]  eta: 1:04:46  lr: 0.000029  loss: 2.6276  time: 2.5146  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3000/4498]  eta: 1:02:40  lr: 0.000029  loss: 2.7721  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3050/4498]  eta: 1:00:34  lr: 0.000029  loss: 2.6769  time: 2.5116  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3100/4498]  eta: 0:58:29  lr: 0.000029  loss: 2.7210  time: 2.5136  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3150/4498]  eta: 0:56:23  lr: 0.000029  loss: 2.6527  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3200/4498]  eta: 0:54:18  lr: 0.000029  loss: 2.7428  time: 2.5067  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3250/4498]  eta: 0:52:12  lr: 0.000029  loss: 2.5980  time: 2.5079  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3300/4498]  eta: 0:50:07  lr: 0.000029  loss: 2.4607  time: 2.5001  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3350/4498]  eta: 0:48:01  lr: 0.000029  loss: 2.6609  time: 2.5063  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3400/4498]  eta: 0:45:56  lr: 0.000029  loss: 2.3717  time: 2.5050  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3450/4498]  eta: 0:43:50  lr: 0.000029  loss: 2.7877  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3500/4498]  eta: 0:41:45  lr: 0.000029  loss: 2.4933  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3550/4498]  eta: 0:39:39  lr: 0.000029  loss: 2.5681  time: 2.5020  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3600/4498]  eta: 0:37:33  lr: 0.000029  loss: 2.5213  time: 2.5078  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3650/4498]  eta: 0:35:28  lr: 0.000029  loss: 2.4434  time: 2.5097  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3700/4498]  eta: 0:33:22  lr: 0.000029  loss: 2.4921  time: 2.5102  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3750/4498]  eta: 0:31:17  lr: 0.000029  loss: 2.4268  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3800/4498]  eta: 0:29:11  lr: 0.000029  loss: 2.6076  time: 2.5088  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3850/4498]  eta: 0:27:06  lr: 0.000029  loss: 2.5027  time: 2.5161  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3900/4498]  eta: 0:25:00  lr: 0.000029  loss: 2.6625  time: 2.5027  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [3950/4498]  eta: 0:22:55  lr: 0.000029  loss: 2.6785  time: 2.5136  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4000/4498]  eta: 0:20:49  lr: 0.000029  loss: 2.5718  time: 2.5111  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4050/4498]  eta: 0:18:44  lr: 0.000029  loss: 2.4560  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4100/4498]  eta: 0:16:38  lr: 0.000029  loss: 2.5227  time: 2.4996  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4150/4498]  eta: 0:14:33  lr: 0.000029  loss: 2.3874  time: 2.5153  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4200/4498]  eta: 0:12:27  lr: 0.000029  loss: 2.6767  time: 2.5035  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4250/4498]  eta: 0:10:22  lr: 0.000029  loss: 2.6317  time: 2.5091  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4300/4498]  eta: 0:08:16  lr: 0.000029  loss: 2.7516  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4350/4498]  eta: 0:06:11  lr: 0.000029  loss: 2.5678  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4400/4498]  eta: 0:04:05  lr: 0.000029  loss: 2.4106  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4450/4498]  eta: 0:02:00  lr: 0.000029  loss: 2.7966  time: 2.5085  data: 0.0000  max mem: 37981
Train: data epoch: [7]  [4497/4498]  eta: 0:00:02  lr: 0.000029  loss: 2.6302  time: 2.5508  data: 0.0000  max mem: 37981
Train: data epoch: [7] Total time: 3:08:07 (2.5096 s / it)
2023-04-21 23:17:13,037 [INFO] Averaged stats: lr: 0.0000  loss: 2.5661
2023-04-21 23:17:13,039 [INFO] No validation splits found.
2023-04-21 23:17:13,057 [INFO] Saving checkpoint at epoch 7 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_7.pth.
2023-04-21 23:17:14,567 [INFO] Start training
2023-04-21 23:17:14,587 [INFO] Start training epoch 8, 4498 iters per inner epoch.
Train: data epoch: [8]  [   0/4498]  eta: 7:28:35  lr: 0.000019  loss: 2.6690  time: 5.9838  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [  50/4498]  eta: 3:10:40  lr: 0.000019  loss: 2.5911  time: 2.5106  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 100/4498]  eta: 3:06:14  lr: 0.000019  loss: 2.7238  time: 2.5092  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 150/4498]  eta: 3:03:21  lr: 0.000019  loss: 2.6653  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 200/4498]  eta: 3:00:47  lr: 0.000019  loss: 2.7253  time: 2.4908  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 250/4498]  eta: 2:58:24  lr: 0.000019  loss: 2.5486  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 300/4498]  eta: 2:56:08  lr: 0.000019  loss: 2.5113  time: 2.5030  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 350/4498]  eta: 2:53:51  lr: 0.000019  loss: 2.6084  time: 2.5022  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 400/4498]  eta: 2:51:40  lr: 0.000019  loss: 2.7224  time: 2.5104  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 450/4498]  eta: 2:49:33  lr: 0.000019  loss: 2.5052  time: 2.5169  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 500/4498]  eta: 2:47:25  lr: 0.000019  loss: 2.3775  time: 2.5126  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 550/4498]  eta: 2:45:16  lr: 0.000019  loss: 2.3664  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 600/4498]  eta: 2:43:07  lr: 0.000019  loss: 2.4967  time: 2.4978  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 650/4498]  eta: 2:41:01  lr: 0.000019  loss: 2.5107  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 700/4498]  eta: 2:38:53  lr: 0.000019  loss: 2.6060  time: 2.4980  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 750/4498]  eta: 2:36:46  lr: 0.000019  loss: 2.5121  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 800/4498]  eta: 2:34:39  lr: 0.000019  loss: 2.5616  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 850/4498]  eta: 2:32:33  lr: 0.000019  loss: 2.5611  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 900/4498]  eta: 2:30:26  lr: 0.000019  loss: 2.4752  time: 2.5116  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [ 950/4498]  eta: 2:28:19  lr: 0.000019  loss: 2.5658  time: 2.4944  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1000/4498]  eta: 2:26:12  lr: 0.000019  loss: 2.5374  time: 2.5010  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1050/4498]  eta: 2:24:06  lr: 0.000019  loss: 2.7568  time: 2.5030  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1100/4498]  eta: 2:22:00  lr: 0.000019  loss: 2.3292  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1150/4498]  eta: 2:19:54  lr: 0.000019  loss: 2.5714  time: 2.5073  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1200/4498]  eta: 2:17:48  lr: 0.000019  loss: 2.5358  time: 2.5054  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1250/4498]  eta: 2:15:42  lr: 0.000019  loss: 2.4199  time: 2.4986  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1300/4498]  eta: 2:13:36  lr: 0.000019  loss: 2.3051  time: 2.5013  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1350/4498]  eta: 2:11:32  lr: 0.000019  loss: 2.6190  time: 2.5180  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1400/4498]  eta: 2:09:26  lr: 0.000019  loss: 2.6361  time: 2.4981  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1450/4498]  eta: 2:07:20  lr: 0.000019  loss: 2.3535  time: 2.5066  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1500/4498]  eta: 2:05:14  lr: 0.000019  loss: 2.4383  time: 2.4981  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1550/4498]  eta: 2:03:09  lr: 0.000019  loss: 2.6303  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1600/4498]  eta: 2:01:03  lr: 0.000019  loss: 2.4953  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1650/4498]  eta: 1:58:57  lr: 0.000019  loss: 2.3147  time: 2.5007  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1700/4498]  eta: 1:56:51  lr: 0.000019  loss: 2.7868  time: 2.4990  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1750/4498]  eta: 1:54:46  lr: 0.000019  loss: 2.4581  time: 2.5024  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1800/4498]  eta: 1:52:40  lr: 0.000019  loss: 2.6761  time: 2.5062  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1850/4498]  eta: 1:50:34  lr: 0.000019  loss: 2.6541  time: 2.4991  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1900/4498]  eta: 1:48:29  lr: 0.000019  loss: 2.6364  time: 2.5035  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [1950/4498]  eta: 1:46:24  lr: 0.000019  loss: 2.4110  time: 2.5105  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2000/4498]  eta: 1:44:19  lr: 0.000019  loss: 2.6835  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2050/4498]  eta: 1:42:13  lr: 0.000019  loss: 2.5928  time: 2.5046  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2100/4498]  eta: 1:40:08  lr: 0.000019  loss: 2.5312  time: 2.4948  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2150/4498]  eta: 1:38:02  lr: 0.000019  loss: 2.5900  time: 2.5012  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2200/4498]  eta: 1:35:56  lr: 0.000019  loss: 2.2756  time: 2.4984  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2250/4498]  eta: 1:33:51  lr: 0.000019  loss: 2.6289  time: 2.5118  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2300/4498]  eta: 1:31:46  lr: 0.000019  loss: 2.3913  time: 2.5049  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2350/4498]  eta: 1:29:41  lr: 0.000019  loss: 2.4297  time: 2.4947  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2400/4498]  eta: 1:27:35  lr: 0.000019  loss: 2.5250  time: 2.4982  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2450/4498]  eta: 1:25:30  lr: 0.000019  loss: 2.3172  time: 2.4996  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2500/4498]  eta: 1:23:24  lr: 0.000019  loss: 2.5241  time: 2.4985  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2550/4498]  eta: 1:21:19  lr: 0.000019  loss: 2.4390  time: 2.5023  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2600/4498]  eta: 1:19:13  lr: 0.000019  loss: 2.8327  time: 2.5036  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2650/4498]  eta: 1:17:08  lr: 0.000019  loss: 2.5857  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2700/4498]  eta: 1:15:03  lr: 0.000019  loss: 2.4523  time: 2.5097  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2750/4498]  eta: 1:12:57  lr: 0.000019  loss: 2.6053  time: 2.4925  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2800/4498]  eta: 1:10:52  lr: 0.000019  loss: 2.3986  time: 2.4990  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2850/4498]  eta: 1:08:47  lr: 0.000019  loss: 2.4936  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2900/4498]  eta: 1:06:42  lr: 0.000019  loss: 2.4409  time: 2.4927  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [2950/4498]  eta: 1:04:36  lr: 0.000019  loss: 2.4661  time: 2.5060  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3000/4498]  eta: 1:02:31  lr: 0.000019  loss: 2.5505  time: 2.5020  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3050/4498]  eta: 1:00:26  lr: 0.000019  loss: 2.4121  time: 2.5093  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3100/4498]  eta: 0:58:21  lr: 0.000019  loss: 2.4540  time: 2.5008  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3150/4498]  eta: 0:56:16  lr: 0.000019  loss: 2.5461  time: 2.5042  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3200/4498]  eta: 0:54:10  lr: 0.000019  loss: 2.4893  time: 2.5080  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3250/4498]  eta: 0:52:05  lr: 0.000019  loss: 2.5416  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3300/4498]  eta: 0:50:00  lr: 0.000019  loss: 2.5339  time: 2.5037  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3350/4498]  eta: 0:47:55  lr: 0.000019  loss: 2.5696  time: 2.4992  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3400/4498]  eta: 0:45:49  lr: 0.000019  loss: 2.4795  time: 2.4951  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3450/4498]  eta: 0:43:44  lr: 0.000019  loss: 2.2969  time: 2.5009  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3500/4498]  eta: 0:41:39  lr: 0.000019  loss: 2.6909  time: 2.4988  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3550/4498]  eta: 0:39:34  lr: 0.000019  loss: 2.6551  time: 2.4959  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3600/4498]  eta: 0:37:28  lr: 0.000019  loss: 2.3891  time: 2.5043  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3650/4498]  eta: 0:35:23  lr: 0.000019  loss: 2.4077  time: 2.5047  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3700/4498]  eta: 0:33:18  lr: 0.000019  loss: 2.5071  time: 2.5058  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3750/4498]  eta: 0:31:13  lr: 0.000019  loss: 2.2704  time: 2.5084  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3800/4498]  eta: 0:29:07  lr: 0.000019  loss: 2.5374  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3850/4498]  eta: 0:27:02  lr: 0.000019  loss: 2.6361  time: 2.5050  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3900/4498]  eta: 0:24:57  lr: 0.000019  loss: 2.5020  time: 2.5074  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [3950/4498]  eta: 0:22:52  lr: 0.000019  loss: 2.3020  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4000/4498]  eta: 0:20:47  lr: 0.000019  loss: 2.4750  time: 2.5033  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4050/4498]  eta: 0:18:41  lr: 0.000019  loss: 2.8995  time: 2.4975  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4100/4498]  eta: 0:16:36  lr: 0.000019  loss: 2.5528  time: 2.4936  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4150/4498]  eta: 0:14:31  lr: 0.000019  loss: 2.7492  time: 2.5101  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4200/4498]  eta: 0:12:26  lr: 0.000019  loss: 2.5491  time: 2.5139  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4250/4498]  eta: 0:10:20  lr: 0.000019  loss: 2.6609  time: 2.4969  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4300/4498]  eta: 0:08:15  lr: 0.000019  loss: 2.5404  time: 2.5009  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4350/4498]  eta: 0:06:10  lr: 0.000019  loss: 2.7081  time: 2.5026  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4400/4498]  eta: 0:04:05  lr: 0.000019  loss: 2.5920  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4450/4498]  eta: 0:02:00  lr: 0.000019  loss: 2.5691  time: 2.5007  data: 0.0000  max mem: 37981
Train: data epoch: [8]  [4497/4498]  eta: 0:00:02  lr: 0.000019  loss: 2.7284  time: 2.5343  data: 0.0000  max mem: 37981
Train: data epoch: [8] Total time: 3:07:42 (2.5040 s / it)
2023-04-22 02:24:57,365 [INFO] Averaged stats: lr: 0.0000  loss: 2.5449
2023-04-22 02:24:57,367 [INFO] No validation splits found.
2023-04-22 02:24:57,385 [INFO] Saving checkpoint at epoch 8 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_8.pth.
2023-04-22 02:24:59,015 [INFO] Start training
2023-04-22 02:24:59,036 [INFO] Start training epoch 9, 4498 iters per inner epoch.
Train: data epoch: [9]  [   0/4498]  eta: 7:29:59  lr: 0.000012  loss: 2.4554  time: 6.0026  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [  50/4498]  eta: 3:10:20  lr: 0.000012  loss: 2.7814  time: 2.4990  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 100/4498]  eta: 3:05:53  lr: 0.000012  loss: 2.3300  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 150/4498]  eta: 3:02:58  lr: 0.000012  loss: 2.6225  time: 2.4985  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 200/4498]  eta: 3:00:22  lr: 0.000012  loss: 2.5580  time: 2.4989  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 250/4498]  eta: 2:57:58  lr: 0.000012  loss: 2.5962  time: 2.4962  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 300/4498]  eta: 2:55:45  lr: 0.000012  loss: 2.5795  time: 2.4939  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 350/4498]  eta: 2:53:36  lr: 0.000012  loss: 2.5964  time: 2.5053  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 400/4498]  eta: 2:51:31  lr: 0.000012  loss: 2.3585  time: 2.5111  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 450/4498]  eta: 2:49:22  lr: 0.000012  loss: 2.6923  time: 2.4993  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 500/4498]  eta: 2:47:14  lr: 0.000012  loss: 2.3754  time: 2.5007  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 550/4498]  eta: 2:45:04  lr: 0.000012  loss: 2.3422  time: 2.4963  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 600/4498]  eta: 2:42:56  lr: 0.000012  loss: 2.2589  time: 2.5057  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 650/4498]  eta: 2:40:49  lr: 0.000012  loss: 2.4831  time: 2.4983  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 700/4498]  eta: 2:38:42  lr: 0.000012  loss: 2.5917  time: 2.5021  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 750/4498]  eta: 2:36:35  lr: 0.000012  loss: 2.5400  time: 2.5061  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 800/4498]  eta: 2:34:27  lr: 0.000012  loss: 2.4614  time: 2.4949  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 850/4498]  eta: 2:32:21  lr: 0.000012  loss: 2.2780  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 900/4498]  eta: 2:30:16  lr: 0.000012  loss: 2.6517  time: 2.5123  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [ 950/4498]  eta: 2:28:09  lr: 0.000012  loss: 2.5461  time: 2.4961  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1000/4498]  eta: 2:26:04  lr: 0.000012  loss: 2.8028  time: 2.5078  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1050/4498]  eta: 2:23:58  lr: 0.000012  loss: 2.6961  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1100/4498]  eta: 2:21:52  lr: 0.000012  loss: 2.5400  time: 2.5059  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1150/4498]  eta: 2:19:47  lr: 0.000012  loss: 2.5941  time: 2.4988  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1200/4498]  eta: 2:17:40  lr: 0.000012  loss: 2.3873  time: 2.4986  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1250/4498]  eta: 2:15:35  lr: 0.000012  loss: 2.5690  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1300/4498]  eta: 2:13:31  lr: 0.000012  loss: 2.7426  time: 2.4962  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1350/4498]  eta: 2:11:26  lr: 0.000012  loss: 2.4035  time: 2.5105  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1400/4498]  eta: 2:09:21  lr: 0.000012  loss: 2.5491  time: 2.5149  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1450/4498]  eta: 2:07:15  lr: 0.000012  loss: 2.6178  time: 2.4936  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1500/4498]  eta: 2:05:09  lr: 0.000012  loss: 2.4307  time: 2.4961  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1550/4498]  eta: 2:03:03  lr: 0.000012  loss: 2.6066  time: 2.5071  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1600/4498]  eta: 2:00:57  lr: 0.000012  loss: 2.6028  time: 2.4950  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1650/4498]  eta: 1:58:51  lr: 0.000012  loss: 2.8540  time: 2.4964  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1700/4498]  eta: 1:56:46  lr: 0.000012  loss: 2.5704  time: 2.4998  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1750/4498]  eta: 1:54:41  lr: 0.000012  loss: 2.4952  time: 2.5021  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1800/4498]  eta: 1:52:35  lr: 0.000012  loss: 2.3198  time: 2.4874  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1850/4498]  eta: 1:50:29  lr: 0.000012  loss: 2.4856  time: 2.4911  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1900/4498]  eta: 1:48:24  lr: 0.000012  loss: 2.5642  time: 2.4973  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [1950/4498]  eta: 1:46:19  lr: 0.000012  loss: 2.2859  time: 2.4958  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2000/4498]  eta: 1:44:13  lr: 0.000012  loss: 2.4455  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2050/4498]  eta: 1:42:08  lr: 0.000012  loss: 2.4142  time: 2.5076  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2100/4498]  eta: 1:40:02  lr: 0.000012  loss: 2.5156  time: 2.4919  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2150/4498]  eta: 1:37:57  lr: 0.000012  loss: 2.4191  time: 2.5092  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2200/4498]  eta: 1:35:53  lr: 0.000012  loss: 2.4774  time: 2.5007  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2250/4498]  eta: 1:33:47  lr: 0.000012  loss: 2.4758  time: 2.5135  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2300/4498]  eta: 1:31:42  lr: 0.000012  loss: 2.5917  time: 2.5089  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2350/4498]  eta: 1:29:37  lr: 0.000012  loss: 2.6284  time: 2.5016  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2400/4498]  eta: 1:27:32  lr: 0.000012  loss: 2.5235  time: 2.4990  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2450/4498]  eta: 1:25:27  lr: 0.000012  loss: 2.5161  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2500/4498]  eta: 1:23:21  lr: 0.000012  loss: 2.3291  time: 2.4996  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2550/4498]  eta: 1:21:16  lr: 0.000012  loss: 2.6686  time: 2.5006  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2600/4498]  eta: 1:19:11  lr: 0.000012  loss: 2.4011  time: 2.5003  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2650/4498]  eta: 1:17:06  lr: 0.000012  loss: 2.5745  time: 2.4898  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2700/4498]  eta: 1:15:00  lr: 0.000012  loss: 2.5306  time: 2.4997  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2750/4498]  eta: 1:12:55  lr: 0.000012  loss: 2.4912  time: 2.4996  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2800/4498]  eta: 1:10:50  lr: 0.000012  loss: 2.5416  time: 2.5077  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2850/4498]  eta: 1:08:45  lr: 0.000012  loss: 2.5930  time: 2.5056  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2900/4498]  eta: 1:06:40  lr: 0.000012  loss: 2.3480  time: 2.5014  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [2950/4498]  eta: 1:04:34  lr: 0.000012  loss: 2.5498  time: 2.4947  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3000/4498]  eta: 1:02:29  lr: 0.000012  loss: 2.5396  time: 2.4986  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3050/4498]  eta: 1:00:24  lr: 0.000012  loss: 2.4815  time: 2.5111  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3100/4498]  eta: 0:58:19  lr: 0.000012  loss: 2.6541  time: 2.5050  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3150/4498]  eta: 0:56:14  lr: 0.000012  loss: 2.3139  time: 2.4992  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3200/4498]  eta: 0:54:09  lr: 0.000012  loss: 2.5600  time: 2.5070  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3250/4498]  eta: 0:52:03  lr: 0.000012  loss: 2.3820  time: 2.5064  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3300/4498]  eta: 0:49:58  lr: 0.000012  loss: 2.3719  time: 2.4997  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3350/4498]  eta: 0:47:53  lr: 0.000012  loss: 2.7950  time: 2.5086  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3400/4498]  eta: 0:45:48  lr: 0.000012  loss: 2.4923  time: 2.5081  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3450/4498]  eta: 0:43:43  lr: 0.000012  loss: 2.4435  time: 2.5090  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3500/4498]  eta: 0:41:38  lr: 0.000012  loss: 2.2954  time: 2.5003  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3550/4498]  eta: 0:39:33  lr: 0.000012  loss: 2.5539  time: 2.5132  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3600/4498]  eta: 0:37:27  lr: 0.000012  loss: 2.4328  time: 2.5030  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3650/4498]  eta: 0:35:22  lr: 0.000012  loss: 2.4249  time: 2.5053  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3700/4498]  eta: 0:33:17  lr: 0.000012  loss: 2.3867  time: 2.4985  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3750/4498]  eta: 0:31:12  lr: 0.000012  loss: 2.5008  time: 2.4990  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3800/4498]  eta: 0:29:07  lr: 0.000012  loss: 2.6867  time: 2.5015  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3850/4498]  eta: 0:27:02  lr: 0.000012  loss: 2.5724  time: 2.5041  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3900/4498]  eta: 0:24:56  lr: 0.000012  loss: 2.5014  time: 2.5017  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [3950/4498]  eta: 0:22:51  lr: 0.000012  loss: 2.3774  time: 2.5231  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4000/4498]  eta: 0:20:46  lr: 0.000012  loss: 2.6264  time: 2.5013  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4050/4498]  eta: 0:18:41  lr: 0.000012  loss: 2.4005  time: 2.5072  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4100/4498]  eta: 0:16:36  lr: 0.000012  loss: 2.6202  time: 2.5039  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4150/4498]  eta: 0:14:31  lr: 0.000012  loss: 2.5069  time: 2.5001  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4200/4498]  eta: 0:12:25  lr: 0.000012  loss: 2.5174  time: 2.4970  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4250/4498]  eta: 0:10:20  lr: 0.000012  loss: 2.4930  time: 2.4897  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4300/4498]  eta: 0:08:15  lr: 0.000012  loss: 2.6601  time: 2.4938  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4350/4498]  eta: 0:06:10  lr: 0.000012  loss: 2.5002  time: 2.5028  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4400/4498]  eta: 0:04:05  lr: 0.000012  loss: 2.3542  time: 2.5034  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4450/4498]  eta: 0:02:00  lr: 0.000012  loss: 2.5498  time: 2.5107  data: 0.0000  max mem: 37981
Train: data epoch: [9]  [4497/4498]  eta: 0:00:02  lr: 0.000012  loss: 2.6872  time: 2.5463  data: 0.0000  max mem: 37981
Train: data epoch: [9] Total time: 3:07:39 (2.5032 s / it)
2023-04-22 05:32:38,240 [INFO] Averaged stats: lr: 0.0000  loss: 2.5296
2023-04-22 05:32:38,242 [INFO] No validation splits found.
2023-04-22 05:32:38,260 [INFO] Saving checkpoint at epoch 9 to /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage2/20230420221/checkpoint_9.pth.
2023-04-22 05:32:39,864 [INFO] No validation splits found.
2023-04-22 05:32:39,864 [INFO] Training time 1 day, 7:20:06
(lavis) yiren@mms-large-2:~/LAVIS$
(lavis) yiren@mms-large-2:~/LAVIS$
(lavis) yiren@mms-large-2:~/LAVIS$
